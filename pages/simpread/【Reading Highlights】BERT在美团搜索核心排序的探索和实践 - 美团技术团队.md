title:: 【Reading Highlights】BERT在美团搜索核心排序的探索和实践 - 美团技术团队
source:: https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html
summary:: 
tags:: [[简悦]] [[nlp]]  [[搜索技术]]  [[美团技术]]   [[reading_highlights]]
date:: 20220622  

- > 理解用户 Query，将用户最想要的结果排在靠前的位置，是搜索引擎最核心的两大步骤。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E7%90%86%E8%A7%A3%E7%94%A8%E6%88%B7%20Query%EF%BC%8C%E5%B0%86%E7%94%A8%E6%88%B7%E6%9C%80%E6%83%B3%E8%A6%81%E7%9A%84%E7%BB%93%E6%9E%9C%E6%8E%92%E5%9C%A8%E9%9D%A0%E5%89%8D%E7%9A%84%E4%BD%8D%E7%BD%AE%EF%BC%8C%E6%98%AF%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%9C%80%E6%A0%B8%E5%BF%83%E7%9A%84%E4%B8%A4%E5%A4%A7%E6%AD%A5%E9%AA%A4%E3%80%82))

- > 基于 Term 匹配的传统相关性特征可以较好地判断 Query 和候选 Doc 的字面相关性，但在字面相差较大时，则难以刻画出两者的相关性  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%9F%BA%E4%BA%8E%20Term%20%E5%8C%B9%E9%85%8D%E7%9A%84%E4%BC%A0%E7%BB%9F%E7%9B%B8%E5%85%B3%E6%80%A7%E7%89%B9%E5%BE%81%E5%8F%AF%E4%BB%A5%E8%BE%83%E5%A5%BD%E5%9C%B0%E5%88%A4%E6%96%AD%20Query%20%E5%92%8C%E5%80%99%E9%80%89%20Doc%20%E7%9A%84%E5%AD%97%E9%9D%A2%E7%9B%B8%E5%85%B3%E6%80%A7%EF%BC%8C%E4%BD%86%E5%9C%A8%E5%AD%97%E9%9D%A2%E7%9B%B8%E5%B7%AE%E8%BE%83%E5%A4%A7%E6%97%B6%EF%BC%8C%E5%88%99%E9%9A%BE%E4%BB%A5%E5%88%BB%E7%94%BB%E5%87%BA%E4%B8%A4%E8%80%85%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7))

- > 美团 AI 平台搜索与 NLP 部算法团队基于美团海量业务语料训练了 MT-BERT 模型，已经将 MT-BERT 应用到搜索意图识别、细粒度情感分析、点评推荐理由、场景化分类等业务场景中  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E7%BE%8E%E5%9B%A2%20AI%20%E5%B9%B3%E5%8F%B0%E6%90%9C%E7%B4%A2%E4%B8%8E%20NLP%20%E9%83%A8%E7%AE%97%E6%B3%95%E5%9B%A2%E9%98%9F%E5%9F%BA%E4%BA%8E%E7%BE%8E%E5%9B%A2%E6%B5%B7%E9%87%8F%E4%B8%9A%E5%8A%A1%E8%AF%AD%E6%96%99%E8%AE%AD%E7%BB%83%E4%BA%86%20MT-BERT%20%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%B7%B2%E7%BB%8F%E5%B0%86%20MT-BERT%20%E5%BA%94%E7%94%A8%E5%88%B0%E6%90%9C%E7%B4%A2%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB%E3%80%81%E7%BB%86%E7%B2%92%E5%BA%A6%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E3%80%81%E7%82%B9%E8%AF%84%E6%8E%A8%E8%8D%90%E7%90%86%E7%94%B1%E3%80%81%E5%9C%BA%E6%99%AF%E5%8C%96%E5%88%86%E7%B1%BB%E7%AD%89%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E4%B8%AD))

- > 相比 RNN 模型，Transformer 语义特征提取能力更强，具备长距离特征捕获能力，且可以并行训练  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E7%9B%B8%E6%AF%94%20RNN%20%E6%A8%A1%E5%9E%8B%EF%BC%8CTransformer%20%E8%AF%AD%E4%B9%89%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E8%83%BD%E5%8A%9B%E6%9B%B4%E5%BC%BA%EF%BC%8C%E5%85%B7%E5%A4%87%E9%95%BF%E8%B7%9D%E7%A6%BB%E7%89%B9%E5%BE%81%E6%8D%95%E8%8E%B7%E8%83%BD%E5%8A%9B%EF%BC%8C%E4%B8%94%E5%8F%AF%E4%BB%A5%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83))

- > BERT 的成功启发了大量后续工作，总结如下：

*   融合更多外部知识的百度 ERNIE[8]， 清华 ERNIE[9] 和 K-BERT[10] 等；
*   优化预训练目标的 ERNIE 2.0[11]，RoBERTa[12]，SpanBERT[13]，StructBERT[14] 等；
*   优化模型结构或者训练方式的 ALBERT[15] 和 ELECTRA[16]。关于预训练模型的各种后续工作，可以参考复旦大学邱锡鹏老师最近的综述  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=BERT%20%E7%9A%84%E6%88%90%E5%8A%9F%E5%90%AF%E5%8F%91%E4%BA%86%E5%A4%A7%E9%87%8F%E5%90%8E%E7%BB%AD%E5%B7%A5%E4%BD%9C%EF%BC%8C%E6%80%BB%E7%BB%93%E5%A6%82%E4%B8%8B%EF%BC%9A%E8%9E%8D%E5%90%88%E6%9B%B4%E5%A4%9A%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AF%86%E7%9A%84%E7%99%BE%E5%BA%A6%20ERNIE%5B8%5D%EF%BC%8C%20%E6%B8%85%E5%8D%8E%20ERNIE%5B9%5D%20%E5%92%8C%20K-BERT%5B10%5D%20%E7%AD%89%EF%BC%9B%E4%BC%98%E5%8C%96%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9B%AE%E6%A0%87%E7%9A%84%20ERNIE%202.0%5B11%5D%EF%BC%8CRoBERTa%5B12%5D%EF%BC%8CSpanBERT%5B13%5D%EF%BC%8CStructBERT%5B14%5D%20%E7%AD%89%EF%BC%9B%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E6%88%96%E8%80%85%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F%E7%9A%84%20ALBERT%5B15%5D%20%E5%92%8C%20ELECTRA%5B16%5D%E3%80%82%E5%85%B3%E4%BA%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%90%84%E7%A7%8D%E5%90%8E%E7%BB%AD%E5%B7%A5%E4%BD%9C%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%8F%82%E8%80%83%E5%A4%8D%E6%97%A6%E5%A4%A7%E5%AD%A6%E9%82%B1%E9%94%A1%E9%B9%8F%E8%80%81%E5%B8%88%E6%9C%80%E8%BF%91%E7%9A%84%E7%BB%BC%E8%BF%B0))
  - 📝 BERT 优化的几个方向。

- > ![](https://p0.meituan.net/travelcube/f7395c94afb6f47a1ffdb5827fe5ff7b305038.png)  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=https://p0.meituan.net/travelcube/f7395c94afb6f47a1ffdb5827fe5ff7b305038.png))

- > 基于预训练好的 BERT 模型可以支持多种下游 NLP 任务。BERT 在下游任务中的应用主要有两种方式：即 Feature-based 和 Finetune-based。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%9F%BA%E4%BA%8E%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%20BERT%20%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E6%94%AF%E6%8C%81%E5%A4%9A%E7%A7%8D%E4%B8%8B%E6%B8%B8%20NLP%20%E4%BB%BB%E5%8A%A1%E3%80%82BERT%20%E5%9C%A8%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%BB%E8%A6%81%E6%9C%89%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%9A%E5%8D%B3%20Feature-based%20%E5%92%8C%20Finetune-based%E3%80%82))

- > Feature-based 方法将 BERT 作为文本编码器获取文本表示向量，从而完成文本相似度计算、向量召回等任务  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Feature-based%20%E6%96%B9%E6%B3%95%E5%B0%86%20BERT%20%E4%BD%9C%E4%B8%BA%E6%96%87%E6%9C%AC%E7%BC%96%E7%A0%81%E5%99%A8%E8%8E%B7%E5%8F%96%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA%E5%90%91%E9%87%8F%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%AE%8C%E6%88%90%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E3%80%81%E5%90%91%E9%87%8F%E5%8F%AC%E5%9B%9E%E7%AD%89%E4%BB%BB%E5%8A%A1))

- > Finetune-based 方法是在预训练模型的基础上，使用具体任务的部分训练数据进行训练，从而针对性地修正预训练阶段获得的网络参数。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Finetune-based%20%E6%96%B9%E6%B3%95%E6%98%AF%E5%9C%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B8%8A%EF%BC%8C%E4%BD%BF%E7%94%A8%E5%85%B7%E4%BD%93%E4%BB%BB%E5%8A%A1%E7%9A%84%E9%83%A8%E5%88%86%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%EF%BC%8C%E4%BB%8E%E8%80%8C%E9%92%88%E5%AF%B9%E6%80%A7%E5%9C%B0%E4%BF%AE%E6%AD%A3%E9%A2%84%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E8%8E%B7%E5%BE%97%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0%E3%80%82))

- > 清华大学 Qiao 等人 [18] 详细对比了 Feature-based 和 Finetune-based 两种应用方式在段落排序（Passage Ranking）中的效果。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%20Qiao%20%E7%AD%89%E4%BA%BA%20%5B18%5D%20%E8%AF%A6%E7%BB%86%E5%AF%B9%E6%AF%94%E4%BA%86%20Feature-based%20%E5%92%8C%20Finetune-based%20%E4%B8%A4%E7%A7%8D%E5%BA%94%E7%94%A8%E6%96%B9%E5%BC%8F%E5%9C%A8%E6%AE%B5%E8%90%BD%E6%8E%92%E5%BA%8F%EF%BC%88Passage%20Ranking%EF%BC%89%E4%B8%AD%E7%9A%84%E6%95%88%E6%9E%9C%E3%80%82))

- > 滑铁卢大学 Jimmy Lin 团队 [19] 针对文档排序任务提出了基于 Pointwise 和 Pairwise 训练目标的 MonoBERT 和 DuoBERT 模型。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%BB%91%E9%93%81%E5%8D%A2%E5%A4%A7%E5%AD%A6%20Jimmy%20Lin%20%E5%9B%A2%E9%98%9F%20%5B19%5D%20%E9%92%88%E5%AF%B9%E6%96%87%E6%A1%A3%E6%8E%92%E5%BA%8F%E4%BB%BB%E5%8A%A1%E6%8F%90%E5%87%BA%E4%BA%86%E5%9F%BA%E4%BA%8E%20Pointwise%20%E5%92%8C%20Pairwise%20%E8%AE%AD%E7%BB%83%E7%9B%AE%E6%A0%87%E7%9A%84%20MonoBERT%20%E5%92%8C%20DuoBERT%20%E6%A8%A1%E5%9E%8B%E3%80%82))

- > 该团队 [20] 提出融合基于 BERT 的 Query-Doc 相关性和 Query-Sentence 相关性来优化文档排序任务的方案。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E8%AF%A5%E5%9B%A2%E9%98%9F%20%5B20%5D%20%E6%8F%90%E5%87%BA%E8%9E%8D%E5%90%88%E5%9F%BA%E4%BA%8E%20BERT%20%E7%9A%84%20Query-Doc%20%E7%9B%B8%E5%85%B3%E6%80%A7%E5%92%8C%20Query-Sentence%20%E7%9B%B8%E5%85%B3%E6%80%A7%E6%9D%A5%E4%BC%98%E5%8C%96%E6%96%87%E6%A1%A3%E6%8E%92%E5%BA%8F%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%96%B9%E6%A1%88%E3%80%82))

- > 为了优化检索性能和效果，Bing 广告团队 [21] 提出一种双塔结构的 TwinBERT 分别编码 Query 和 Doc 文本。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E4%B8%BA%E4%BA%86%E4%BC%98%E5%8C%96%E6%A3%80%E7%B4%A2%E6%80%A7%E8%83%BD%E5%92%8C%E6%95%88%E6%9E%9C%EF%BC%8CBing%20%E5%B9%BF%E5%91%8A%E5%9B%A2%E9%98%9F%20%5B21%5D%20%E6%8F%90%E5%87%BA%E4%B8%80%E7%A7%8D%E5%8F%8C%E5%A1%94%E7%BB%93%E6%9E%84%E7%9A%84%20TwinBERT%20%E5%88%86%E5%88%AB%E7%BC%96%E7%A0%81%20Query%20%E5%92%8C%20Doc%20%E6%96%87%E6%9C%AC%E3%80%82))

- > Google 在其官方博客介绍了 BERT 在 Google 搜索排序和精选摘要（Featured Snippet）场景的应用，BERT 强大的语义理解能力改善了约 10% 的 Google 搜索结果  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Google%20%E5%9C%A8%E5%85%B6%E5%AE%98%E6%96%B9%E5%8D%9A%E5%AE%A2%E4%BB%8B%E7%BB%8D%E4%BA%86%20BERT%20%E5%9C%A8%20Google%20%E6%90%9C%E7%B4%A2%E6%8E%92%E5%BA%8F%E5%92%8C%E7%B2%BE%E9%80%89%E6%91%98%E8%A6%81%EF%BC%88Featured%20Snippet%EF%BC%89%E5%9C%BA%E6%99%AF%E7%9A%84%E5%BA%94%E7%94%A8%EF%BC%8CBERT%20%E5%BC%BA%E5%A4%A7%E7%9A%84%E8%AF%AD%E4%B9%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B%E6%94%B9%E5%96%84%E4%BA%86%E7%BA%A6%2010%25%20%E7%9A%84%20Google%20%E6%90%9C%E7%B4%A2%E7%BB%93%E6%9E%9C))

- > 美团 AI 平台搜索与 NLP 部在 WSDM Cup 2020 检索排序评测任务中提出了基于 Pairwise 模式的 BERT 排序模型和基于 LightGBM 的排序模型，取得了榜单第一名的成绩[23]。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E7%BE%8E%E5%9B%A2%20AI%20%E5%B9%B3%E5%8F%B0%E6%90%9C%E7%B4%A2%E4%B8%8E%20NLP%20%E9%83%A8%E5%9C%A8%20WSDM%20Cup%202020%20%E6%A3%80%E7%B4%A2%E6%8E%92%E5%BA%8F%E8%AF%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%E4%B8%AD%E6%8F%90%E5%87%BA%E4%BA%86%E5%9F%BA%E4%BA%8E%20Pairwise%20%E6%A8%A1%E5%BC%8F%E7%9A%84%20BERT%20%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%9F%BA%E4%BA%8E%20LightGBM%20%E7%9A%84%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%8F%96%E5%BE%97%E4%BA%86%E6%A6%9C%E5%8D%95%E7%AC%AC%E4%B8%80%E5%90%8D%E7%9A%84%E6%88%90%E7%BB%A9%5B23%5D%E3%80%82))

- > 美团搜索场景下相关性任务定义如下：给定用户 Query 和候选 Doc（通常为商户或商品），判断两者之间相关性。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9B%B8%E5%85%B3%E6%80%A7%E4%BB%BB%E5%8A%A1%E5%AE%9A%E4%B9%89%E5%A6%82%E4%B8%8B%EF%BC%9A%E7%BB%99%E5%AE%9A%E7%94%A8%E6%88%B7%20Query%20%E5%92%8C%E5%80%99%E9%80%89%20Doc%EF%BC%88%E9%80%9A%E5%B8%B8%E4%B8%BA%E5%95%86%E6%88%B7%E6%88%96%E5%95%86%E5%93%81%EF%BC%89%EF%BC%8C%E5%88%A4%E6%96%AD%E4%B8%A4%E8%80%85%E4%B9%8B%E9%97%B4%E7%9B%B8%E5%85%B3%E6%80%A7%E3%80%82))

- > 早期的相关性匹配主要是根据 Term 的字面匹配度来计算相关性，如字面命中、覆盖程度、TFIDF、BM25 等。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%97%A9%E6%9C%9F%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E5%8C%B9%E9%85%8D%E4%B8%BB%E8%A6%81%E6%98%AF%E6%A0%B9%E6%8D%AE%20Term%20%E7%9A%84%E5%AD%97%E9%9D%A2%E5%8C%B9%E9%85%8D%E5%BA%A6%E6%9D%A5%E8%AE%A1%E7%AE%97%E7%9B%B8%E5%85%B3%E6%80%A7%EF%BC%8C%E5%A6%82%E5%AD%97%E9%9D%A2%E5%91%BD%E4%B8%AD%E3%80%81%E8%A6%86%E7%9B%96%E7%A8%8B%E5%BA%A6%E3%80%81TFIDF%E3%80%81BM25%20%E7%AD%89%E3%80%82))

- > 字面匹配有它的局限，主要表现在：

*   **词义局限**：字面匹配无法处理同义词和多义词问题，如在美团业务场景下 “宾馆” 和“旅店”虽然字面上不匹配，但都是搜索 “住宿服务” 的同义词；而 “COCO” 是多义词，在不同业务场景下表示的语义不同，可能是奶茶店，也可能是理发店。
*   **结构局限**：“蛋糕奶油”和 “奶油蛋糕” 虽词汇完全重合，但表达的语义完全不同。 当用户搜 “蛋糕奶油” 时，其意图往往是找 “奶油”，而搜“奶油蛋糕” 的需求基本上都是“蛋糕”。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%AD%97%E9%9D%A2%E5%8C%B9%E9%85%8D%E6%9C%89%E5%AE%83%E7%9A%84%E5%B1%80%E9%99%90%EF%BC%8C%E4%B8%BB%E8%A6%81%E8%A1%A8%E7%8E%B0%E5%9C%A8%EF%BC%9A%E8%AF%8D%E4%B9%89%E5%B1%80%E9%99%90%EF%BC%9A%E5%AD%97%E9%9D%A2%E5%8C%B9%E9%85%8D%E6%97%A0%E6%B3%95%E5%A4%84%E7%90%86%E5%90%8C%E4%B9%89%E8%AF%8D%E5%92%8C%E5%A4%9A%E4%B9%89%E8%AF%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%A6%82%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E4%B8%8B%20%E2%80%9C%E5%AE%BE%E9%A6%86%E2%80%9D%20%E5%92%8C%E2%80%9C%E6%97%85%E5%BA%97%E2%80%9D%E8%99%BD%E7%84%B6%E5%AD%97%E9%9D%A2%E4%B8%8A%E4%B8%8D%E5%8C%B9%E9%85%8D%EF%BC%8C%E4%BD%86%E9%83%BD%E6%98%AF%E6%90%9C%E7%B4%A2%20%E2%80%9C%E4%BD%8F%E5%AE%BF%E6%9C%8D%E5%8A%A1%E2%80%9D%20%E7%9A%84%E5%90%8C%E4%B9%89%E8%AF%8D%EF%BC%9B%E8%80%8C%20%E2%80%9CCOCO%E2%80%9D%20%E6%98%AF%E5%A4%9A%E4%B9%89%E8%AF%8D%EF%BC%8C%E5%9C%A8%E4%B8%8D%E5%90%8C%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E4%B8%8B%E8%A1%A8%E7%A4%BA%E7%9A%84%E8%AF%AD%E4%B9%89%E4%B8%8D%E5%90%8C%EF%BC%8C%E5%8F%AF%E8%83%BD%E6%98%AF%E5%A5%B6%E8%8C%B6%E5%BA%97%EF%BC%8C%E4%B9%9F%E5%8F%AF%E8%83%BD%E6%98%AF%E7%90%86%E5%8F%91%E5%BA%97%E3%80%82%E7%BB%93%E6%9E%84%E5%B1%80%E9%99%90%EF%BC%9A%E2%80%9C%E8%9B%8B%E7%B3%95%E5%A5%B6%E6%B2%B9%E2%80%9D%E5%92%8C%20%E2%80%9C%E5%A5%B6%E6%B2%B9%E8%9B%8B%E7%B3%95%E2%80%9D%20%E8%99%BD%E8%AF%8D%E6%B1%87%E5%AE%8C%E5%85%A8%E9%87%8D%E5%90%88%EF%BC%8C%E4%BD%86%E8%A1%A8%E8%BE%BE%E7%9A%84%E8%AF%AD%E4%B9%89%E5%AE%8C%E5%85%A8%E4%B8%8D%E5%90%8C%E3%80%82%20%E5%BD%93%E7%94%A8%E6%88%B7%E6%90%9C%20%E2%80%9C%E8%9B%8B%E7%B3%95%E5%A5%B6%E6%B2%B9%E2%80%9D%20%E6%97%B6%EF%BC%8C%E5%85%B6%E6%84%8F%E5%9B%BE%E5%BE%80%E5%BE%80%E6%98%AF%E6%89%BE%20%E2%80%9C%E5%A5%B6%E6%B2%B9%E2%80%9D%EF%BC%8C%E8%80%8C%E6%90%9C%E2%80%9C%E5%A5%B6%E6%B2%B9%E8%9B%8B%E7%B3%95%E2%80%9D%20%E7%9A%84%E9%9C%80%E6%B1%82%E5%9F%BA%E6%9C%AC%E4%B8%8A%E9%83%BD%E6%98%AF%E2%80%9C%E8%9B%8B%E7%B3%95%E2%80%9D%E3%80%82))

- > 传统语义匹配模型包括：

*   **隐式模型**：将 Query、Doc 都映射到同一个隐式向量空间，通过向量相似度来计算 Query-Doc 相关性，例如使用主题模型 LDA[24] 将 Query 和 Doc 映射到同一向量空间；
*   **翻译模型**：通过统计机器翻译方法将 Doc 进行改写后与 Query 进行匹配 [25]。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E4%BC%A0%E7%BB%9F%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%9E%8B%E5%8C%85%E6%8B%AC%EF%BC%9A%E9%9A%90%E5%BC%8F%E6%A8%A1%E5%9E%8B%EF%BC%9A%E5%B0%86%20Query%E3%80%81Doc%20%E9%83%BD%E6%98%A0%E5%B0%84%E5%88%B0%E5%90%8C%E4%B8%80%E4%B8%AA%E9%9A%90%E5%BC%8F%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4%EF%BC%8C%E9%80%9A%E8%BF%87%E5%90%91%E9%87%8F%E7%9B%B8%E4%BC%BC%E5%BA%A6%E6%9D%A5%E8%AE%A1%E7%AE%97%20Query-Doc%20%E7%9B%B8%E5%85%B3%E6%80%A7%EF%BC%8C%E4%BE%8B%E5%A6%82%E4%BD%BF%E7%94%A8%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B%20LDA%5B24%5D%20%E5%B0%86%20Query%20%E5%92%8C%20Doc%20%E6%98%A0%E5%B0%84%E5%88%B0%E5%90%8C%E4%B8%80%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4%EF%BC%9B%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B%EF%BC%9A%E9%80%9A%E8%BF%87%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%96%B9%E6%B3%95%E5%B0%86%20Doc%20%E8%BF%9B%E8%A1%8C%E6%94%B9%E5%86%99%E5%90%8E%E4%B8%8E%20Query%20%E8%BF%9B%E8%A1%8C%E5%8C%B9%E9%85%8D%20%5B25%5D%E3%80%82))

- > 基于深度学习的语义匹配方法成为研究热点，主要包括基于表示的匹配方法（Representation-based）和基于交互的匹配方法（Interaction-based）。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E6%96%B9%E6%B3%95%E6%88%90%E4%B8%BA%E7%A0%94%E7%A9%B6%E7%83%AD%E7%82%B9%EF%BC%8C%E4%B8%BB%E8%A6%81%E5%8C%85%E6%8B%AC%E5%9F%BA%E4%BA%8E%E8%A1%A8%E7%A4%BA%E7%9A%84%E5%8C%B9%E9%85%8D%E6%96%B9%E6%B3%95%EF%BC%88Representation-based%EF%BC%89%E5%92%8C%E5%9F%BA%E4%BA%8E%E4%BA%A4%E4%BA%92%E7%9A%84%E5%8C%B9%E9%85%8D%E6%96%B9%E6%B3%95%EF%BC%88Interaction-based%EF%BC%89%E3%80%82))

- > **基于表示的匹配方法**：使用深度学习模型分别表征 Query 和 Doc，通过计算向量相似度来作为语义匹配分数。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%9F%BA%E4%BA%8E%E8%A1%A8%E7%A4%BA%E7%9A%84%E5%8C%B9%E9%85%8D%E6%96%B9%E6%B3%95%EF%BC%9A%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%88%86%E5%88%AB%E8%A1%A8%E5%BE%81%20Query%20%E5%92%8C%20Doc%EF%BC%8C%E9%80%9A%E8%BF%87%E8%AE%A1%E7%AE%97%E5%90%91%E9%87%8F%E7%9B%B8%E4%BC%BC%E5%BA%A6%E6%9D%A5%E4%BD%9C%E4%B8%BA%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E5%88%86%E6%95%B0%E3%80%82))

- > 微软的 DSSM[26] 及其扩展模型属于基于表示的语义匹配方法，美团搜索借鉴 DSSM 的双塔结构思想，左边塔输入 Query 信息，右边塔输入 POI、品类信息，生成 Query 和 Doc 的高阶文本相关性、高阶品类相关性特征，应用于排序模型中取得了很好的效果。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%BE%AE%E8%BD%AF%E7%9A%84%20DSSM%5B26%5D%20%E5%8F%8A%E5%85%B6%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9E%8B%E5%B1%9E%E4%BA%8E%E5%9F%BA%E4%BA%8E%E8%A1%A8%E7%A4%BA%E7%9A%84%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E6%96%B9%E6%B3%95%EF%BC%8C%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E5%80%9F%E9%89%B4%20DSSM%20%E7%9A%84%E5%8F%8C%E5%A1%94%E7%BB%93%E6%9E%84%E6%80%9D%E6%83%B3%EF%BC%8C%E5%B7%A6%E8%BE%B9%E5%A1%94%E8%BE%93%E5%85%A5%20Query%20%E4%BF%A1%E6%81%AF%EF%BC%8C%E5%8F%B3%E8%BE%B9%E5%A1%94%E8%BE%93%E5%85%A5%20POI%E3%80%81%E5%93%81%E7%B1%BB%E4%BF%A1%E6%81%AF%EF%BC%8C%E7%94%9F%E6%88%90%20Query%20%E5%92%8C%20Doc%20%E7%9A%84%E9%AB%98%E9%98%B6%E6%96%87%E6%9C%AC%E7%9B%B8%E5%85%B3%E6%80%A7%E3%80%81%E9%AB%98%E9%98%B6%E5%93%81%E7%B1%BB%E7%9B%B8%E5%85%B3%E6%80%A7%E7%89%B9%E5%BE%81%EF%BC%8C%E5%BA%94%E7%94%A8%E4%BA%8E%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%8F%96%E5%BE%97%E4%BA%86%E5%BE%88%E5%A5%BD%E7%9A%84%E6%95%88%E6%9E%9C%E3%80%82))

- > 比较有代表性的表示匹配模型还有百度提出 SimNet[27]，中科院提出的多视角循环神经网络匹配模型（MV-LSTM）[28] 等。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%AF%94%E8%BE%83%E6%9C%89%E4%BB%A3%E8%A1%A8%E6%80%A7%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%9E%8B%E8%BF%98%E6%9C%89%E7%99%BE%E5%BA%A6%E6%8F%90%E5%87%BA%20SimNet%5B27%5D%EF%BC%8C%E4%B8%AD%E7%A7%91%E9%99%A2%E6%8F%90%E5%87%BA%E7%9A%84%E5%A4%9A%E8%A7%86%E8%A7%92%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%9E%8B%EF%BC%88MV-LSTM%EF%BC%89%5B28%5D%20%E7%AD%89%E3%80%82))

- > **基于交互的匹配方法**：这种方法不直接学习 Query 和 Doc 的语义表示向量，而是在神经网络底层就让 Query 和 Doc 提前交互，从而获得更好的文本向量表示，最后通过一个 MLP 网络获得语义匹配分数。代表性模型有华为提出的基于卷积神经网络的匹配模型 ARC-II[29]，中科院提出的基于矩阵匹配的的层次化匹配模型 MatchPyramid[30]。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%9F%BA%E4%BA%8E%E4%BA%A4%E4%BA%92%E7%9A%84%E5%8C%B9%E9%85%8D%E6%96%B9%E6%B3%95%EF%BC%9A%E8%BF%99%E7%A7%8D%E6%96%B9%E6%B3%95%E4%B8%8D%E7%9B%B4%E6%8E%A5%E5%AD%A6%E4%B9%A0%20Query%20%E5%92%8C%20Doc%20%E7%9A%84%E8%AF%AD%E4%B9%89%E8%A1%A8%E7%A4%BA%E5%90%91%E9%87%8F%EF%BC%8C%E8%80%8C%E6%98%AF%E5%9C%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%BA%95%E5%B1%82%E5%B0%B1%E8%AE%A9%20Query%20%E5%92%8C%20Doc%20%E6%8F%90%E5%89%8D%E4%BA%A4%E4%BA%92%EF%BC%8C%E4%BB%8E%E8%80%8C%E8%8E%B7%E5%BE%97%E6%9B%B4%E5%A5%BD%E7%9A%84%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%EF%BC%8C%E6%9C%80%E5%90%8E%E9%80%9A%E8%BF%87%E4%B8%80%E4%B8%AA%20MLP%20%E7%BD%91%E7%BB%9C%E8%8E%B7%E5%BE%97%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E5%88%86%E6%95%B0%E3%80%82%E4%BB%A3%E8%A1%A8%E6%80%A7%E6%A8%A1%E5%9E%8B%E6%9C%89%E5%8D%8E%E4%B8%BA%E6%8F%90%E5%87%BA%E7%9A%84%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%9E%8B%20ARC-II%5B29%5D%EF%BC%8C%E4%B8%AD%E7%A7%91%E9%99%A2%E6%8F%90%E5%87%BA%E7%9A%84%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%8C%B9%E9%85%8D%E7%9A%84%E7%9A%84%E5%B1%82%E6%AC%A1%E5%8C%96%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%9E%8B%20MatchPyramid%5B30%5D%E3%80%82))

- > 基于表示的匹配方法优势在于 Doc 的语义向量可以离线预先计算，在线预测时只需要重新计算 Query 的语义向量，缺点是模型学习时 Query 和 Doc 两者没有任何交互，不能充分利用 Query 和 Doc 的细粒度匹配信号。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%9F%BA%E4%BA%8E%E8%A1%A8%E7%A4%BA%E7%9A%84%E5%8C%B9%E9%85%8D%E6%96%B9%E6%B3%95%E4%BC%98%E5%8A%BF%E5%9C%A8%E4%BA%8E%20Doc%20%E7%9A%84%E8%AF%AD%E4%B9%89%E5%90%91%E9%87%8F%E5%8F%AF%E4%BB%A5%E7%A6%BB%E7%BA%BF%E9%A2%84%E5%85%88%E8%AE%A1%E7%AE%97%EF%BC%8C%E5%9C%A8%E7%BA%BF%E9%A2%84%E6%B5%8B%E6%97%B6%E5%8F%AA%E9%9C%80%E8%A6%81%E9%87%8D%E6%96%B0%E8%AE%A1%E7%AE%97%20Query%20%E7%9A%84%E8%AF%AD%E4%B9%89%E5%90%91%E9%87%8F%EF%BC%8C%E7%BC%BA%E7%82%B9%E6%98%AF%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E6%97%B6%20Query%20%E5%92%8C%20Doc%20%E4%B8%A4%E8%80%85%E6%B2%A1%E6%9C%89%E4%BB%BB%E4%BD%95%E4%BA%A4%E4%BA%92%EF%BC%8C%E4%B8%8D%E8%83%BD%E5%85%85%E5%88%86%E5%88%A9%E7%94%A8%20Query%20%E5%92%8C%20Doc%20%E7%9A%84%E7%BB%86%E7%B2%92%E5%BA%A6%E5%8C%B9%E9%85%8D%E4%BF%A1%E5%8F%B7%E3%80%82))

- > 基于交互的匹配方法优势在于 Query 和 Doc 在模型训练时能够进行充分的交互匹配，语义匹配效果好，缺点是部署上线成本较高。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%9F%BA%E4%BA%8E%E4%BA%A4%E4%BA%92%E7%9A%84%E5%8C%B9%E9%85%8D%E6%96%B9%E6%B3%95%E4%BC%98%E5%8A%BF%E5%9C%A8%E4%BA%8E%20Query%20%E5%92%8C%20Doc%20%E5%9C%A8%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%97%B6%E8%83%BD%E5%A4%9F%E8%BF%9B%E8%A1%8C%E5%85%85%E5%88%86%E7%9A%84%E4%BA%A4%E4%BA%92%E5%8C%B9%E9%85%8D%EF%BC%8C%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E6%95%88%E6%9E%9C%E5%A5%BD%EF%BC%8C%E7%BC%BA%E7%82%B9%E6%98%AF%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%E6%88%90%E6%9C%AC%E8%BE%83%E9%AB%98%E3%80%82))

- > 中文 BERT 基于字粒度预训练，可以减少未登录词（OOV）的影响，美团业务场景下存在大量长尾 Query（如大量数字和英文复合 Query）字粒度模型效果优于词粒度模型。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E4%B8%AD%E6%96%87%20BERT%20%E5%9F%BA%E4%BA%8E%E5%AD%97%E7%B2%92%E5%BA%A6%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%87%8F%E5%B0%91%E6%9C%AA%E7%99%BB%E5%BD%95%E8%AF%8D%EF%BC%88OOV%EF%BC%89%E7%9A%84%E5%BD%B1%E5%93%8D%EF%BC%8C%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E4%B8%8B%E5%AD%98%E5%9C%A8%E5%A4%A7%E9%87%8F%E9%95%BF%E5%B0%BE%20Query%EF%BC%88%E5%A6%82%E5%A4%A7%E9%87%8F%E6%95%B0%E5%AD%97%E5%92%8C%E8%8B%B1%E6%96%87%E5%A4%8D%E5%90%88%20Query%EF%BC%89%E5%AD%97%E7%B2%92%E5%BA%A6%E6%A8%A1%E5%9E%8B%E6%95%88%E6%9E%9C%E4%BC%98%E4%BA%8E%E8%AF%8D%E7%B2%92%E5%BA%A6%E6%A8%A1%E5%9E%8B%E3%80%82))

- > Feature-based 方式是经过 BERT 得到 Query 和 Doc 的表示向量，然后计算余弦相似度，所有业务场景下 Query-Doc 相似度都是固定的，不利于适配不同业务场景。此外，在实际场景下为海量 Doc 向量建立索引存储成本过高。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Feature-based%20%E6%96%B9%E5%BC%8F%E6%98%AF%E7%BB%8F%E8%BF%87%20BERT%20%E5%BE%97%E5%88%B0%20Query%20%E5%92%8C%20Doc%20%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%90%91%E9%87%8F%EF%BC%8C%E7%84%B6%E5%90%8E%E8%AE%A1%E7%AE%97%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%EF%BC%8C%E6%89%80%E6%9C%89%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E4%B8%8B%20Query-Doc%20%E7%9B%B8%E4%BC%BC%E5%BA%A6%E9%83%BD%E6%98%AF%E5%9B%BA%E5%AE%9A%E7%9A%84%EF%BC%8C%E4%B8%8D%E5%88%A9%E4%BA%8E%E9%80%82%E9%85%8D%E4%B8%8D%E5%90%8C%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E3%80%82%E6%AD%A4%E5%A4%96%EF%BC%8C%E5%9C%A8%E5%AE%9E%E9%99%85%E5%9C%BA%E6%99%AF%E4%B8%8B%E4%B8%BA%E6%B5%B7%E9%87%8F%20Doc%20%E5%90%91%E9%87%8F%E5%BB%BA%E7%AB%8B%E7%B4%A2%E5%BC%95%E5%AD%98%E5%82%A8%E6%88%90%E6%9C%AC%E8%BF%87%E9%AB%98%E3%80%82))

- > Finetune-based 方案，利用搜索场景中用户点击数据构造训练数据，然后通过 Fine-tuning 方式优化 Query-Doc 语义匹配任务。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Finetune-based%20%E6%96%B9%E6%A1%88%EF%BC%8C%E5%88%A9%E7%94%A8%E6%90%9C%E7%B4%A2%E5%9C%BA%E6%99%AF%E4%B8%AD%E7%94%A8%E6%88%B7%E7%82%B9%E5%87%BB%E6%95%B0%E6%8D%AE%E6%9E%84%E9%80%A0%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%EF%BC%8C%E7%84%B6%E5%90%8E%E9%80%9A%E8%BF%87%20Fine-tuning%20%E6%96%B9%E5%BC%8F%E4%BC%98%E5%8C%96%20Query-Doc%20%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E4%BB%BB%E5%8A%A1%E3%80%82))

- > **数据样本增强**：由于相关性模型的训练基于搜索用户行为标注的弱监督数据，我们结合业务经验对数据做了去噪和数据映射。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%95%B0%E6%8D%AE%E6%A0%B7%E6%9C%AC%E5%A2%9E%E5%BC%BA%EF%BC%9A%E7%94%B1%E4%BA%8E%E7%9B%B8%E5%85%B3%E6%80%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83%E5%9F%BA%E4%BA%8E%E6%90%9C%E7%B4%A2%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%A0%87%E6%B3%A8%E7%9A%84%E5%BC%B1%E7%9B%91%E7%9D%A3%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%88%91%E4%BB%AC%E7%BB%93%E5%90%88%E4%B8%9A%E5%8A%A1%E7%BB%8F%E9%AA%8C%E5%AF%B9%E6%95%B0%E6%8D%AE%E5%81%9A%E4%BA%86%E5%8E%BB%E5%99%AA%E5%92%8C%E6%95%B0%E6%8D%AE%E6%98%A0%E5%B0%84%E3%80%82))

- > **BERT 领域适配**：美团业务场景中，Query 和 Doc 以商户、商品、团购等短文本为主，除标题文本以外，还存在商户 / 商品描述、品类、地址、图谱标签等结构化信息。我们首先改进了 MT-BERT 预训练方法，将品类、标签等文本信息也加入 MT-BERT 预训练过程中。在相关性 Fine-tuning 阶段，我们对训练目标进行了优化，使得相关性任务和排序任务目标更加匹配，并进一步将两个任务结合进行联合训练。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=BERT%20%E9%A2%86%E5%9F%9F%E9%80%82%E9%85%8D%EF%BC%9A%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E4%B8%AD%EF%BC%8CQuery%20%E5%92%8C%20Doc%20%E4%BB%A5%E5%95%86%E6%88%B7%E3%80%81%E5%95%86%E5%93%81%E3%80%81%E5%9B%A2%E8%B4%AD%E7%AD%89%E7%9F%AD%E6%96%87%E6%9C%AC%E4%B8%BA%E4%B8%BB%EF%BC%8C%E9%99%A4%E6%A0%87%E9%A2%98%E6%96%87%E6%9C%AC%E4%BB%A5%E5%A4%96%EF%BC%8C%E8%BF%98%E5%AD%98%E5%9C%A8%E5%95%86%E6%88%B7%20/%20%E5%95%86%E5%93%81%E6%8F%8F%E8%BF%B0%E3%80%81%E5%93%81%E7%B1%BB%E3%80%81%E5%9C%B0%E5%9D%80%E3%80%81%E5%9B%BE%E8%B0%B1%E6%A0%87%E7%AD%BE%E7%AD%89%E7%BB%93%E6%9E%84%E5%8C%96%E4%BF%A1%E6%81%AF%E3%80%82%E6%88%91%E4%BB%AC%E9%A6%96%E5%85%88%E6%94%B9%E8%BF%9B%E4%BA%86%20MT-BERT%20%E9%A2%84%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95%EF%BC%8C%E5%B0%86%E5%93%81%E7%B1%BB%E3%80%81%E6%A0%87%E7%AD%BE%E7%AD%89%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E4%B9%9F%E5%8A%A0%E5%85%A5%20MT-BERT%20%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E3%80%82%E5%9C%A8%E7%9B%B8%E5%85%B3%E6%80%A7%20Fine-tuning%20%E9%98%B6%E6%AE%B5%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AF%B9%E8%AE%AD%E7%BB%83%E7%9B%AE%E6%A0%87%E8%BF%9B%E8%A1%8C%E4%BA%86%E4%BC%98%E5%8C%96%EF%BC%8C%E4%BD%BF%E5%BE%97%E7%9B%B8%E5%85%B3%E6%80%A7%E4%BB%BB%E5%8A%A1%E5%92%8C%E6%8E%92%E5%BA%8F%E4%BB%BB%E5%8A%A1%E7%9B%AE%E6%A0%87%E6%9B%B4%E5%8A%A0%E5%8C%B9%E9%85%8D%EF%BC%8C%E5%B9%B6%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%B0%86%E4%B8%A4%E4%B8%AA%E4%BB%BB%E5%8A%A1%E7%BB%93%E5%90%88%E8%BF%9B%E8%A1%8C%E8%81%94%E5%90%88%E8%AE%AD%E7%BB%83%E3%80%82))

- > **排序模型优化**：核心排序模型（本文记为 L2 模型）包括 LambdaDNN[31]、TransformerDNN[3]、MultiTaskDNN 等深度学习模型。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%EF%BC%88%E6%9C%AC%E6%96%87%E8%AE%B0%E4%B8%BA%20L2%20%E6%A8%A1%E5%9E%8B%EF%BC%89%E5%8C%85%E6%8B%AC%20LambdaDNN%5B31%5D%E3%80%81TransformerDNN%5B3%5D%E3%80%81MultiTaskDNN%20%E7%AD%89%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E3%80%82))

- > 使用美团搜索积累的大量用户行为数据（如浏览、点击、下单等）， 这些行为数据可以作为弱监督训练数据。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E4%BD%BF%E7%94%A8%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E7%A7%AF%E7%B4%AF%E7%9A%84%E5%A4%A7%E9%87%8F%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%EF%BC%88%E5%A6%82%E6%B5%8F%E8%A7%88%E3%80%81%E7%82%B9%E5%87%BB%E3%80%81%E4%B8%8B%E5%8D%95%E7%AD%89%EF%BC%89%EF%BC%8C%20%E8%BF%99%E4%BA%9B%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E5%8F%AF%E4%BB%A5%E4%BD%9C%E4%B8%BA%E5%BC%B1%E7%9B%91%E7%9D%A3%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E3%80%82))

- > 我们使用下单数据作为正样本，使用未点击过的数据构造负样本，然后结合业务场景对样本进一步优化。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%88%91%E4%BB%AC%E4%BD%BF%E7%94%A8%E4%B8%8B%E5%8D%95%E6%95%B0%E6%8D%AE%E4%BD%9C%E4%B8%BA%E6%AD%A3%E6%A0%B7%E6%9C%AC%EF%BC%8C%E4%BD%BF%E7%94%A8%E6%9C%AA%E7%82%B9%E5%87%BB%E8%BF%87%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9E%84%E9%80%A0%E8%B4%9F%E6%A0%B7%E6%9C%AC%EF%BC%8C%E7%84%B6%E5%90%8E%E7%BB%93%E5%90%88%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E5%AF%B9%E6%A0%B7%E6%9C%AC%E8%BF%9B%E4%B8%80%E6%AD%A5%E4%BC%98%E5%8C%96%E3%80%82))

- > 无意义单字 Query 过滤。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%97%A0%E6%84%8F%E4%B9%89%E5%8D%95%E5%AD%97%20Query%20%E8%BF%87%E6%BB%A4%E3%80%82))

- > 正样本从用户下单的 POI 中进行随机采样  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%AD%A3%E6%A0%B7%E6%9C%AC%E4%BB%8E%E7%94%A8%E6%88%B7%E4%B8%8B%E5%8D%95%E7%9A%84%20POI%20%E4%B8%AD%E8%BF%9B%E8%A1%8C%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7))

- > 负样本尝试了两种构造方法：全局随机负采样和 Skip-Above 采样。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E8%B4%9F%E6%A0%B7%E6%9C%AC%E5%B0%9D%E8%AF%95%E4%BA%86%E4%B8%A4%E7%A7%8D%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95%EF%BC%9A%E5%85%A8%E5%B1%80%E9%9A%8F%E6%9C%BA%E8%B4%9F%E9%87%87%E6%A0%B7%E5%92%8C%20Skip-Above%20%E9%87%87%E6%A0%B7%E3%80%82))

- > **全局随机负采样**：用户没有点击的 POI 进行随机采样得到负例。我们观察发现随机采样同样存在大量噪声数据，补充了两项过滤规则来过滤数据。① 大量的 POI 未被用户点击是因为不是离用户最近的分店，但 POI 和 Query 是相关的，这种类型的样例需要过滤掉，如 <蛙小侠 ，蛙小侠（新北万达店）>。② 用户 Query 里包含品牌词，并且 POI 完全等同于品牌词的，需要从负样本中过滤，如 < 德克士吃饭 ，德克士 >。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%85%A8%E5%B1%80%E9%9A%8F%E6%9C%BA%E8%B4%9F%E9%87%87%E6%A0%B7%EF%BC%9A%E7%94%A8%E6%88%B7%E6%B2%A1%E6%9C%89%E7%82%B9%E5%87%BB%E7%9A%84%20POI%20%E8%BF%9B%E8%A1%8C%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7%E5%BE%97%E5%88%B0%E8%B4%9F%E4%BE%8B%E3%80%82%E6%88%91%E4%BB%AC%E8%A7%82%E5%AF%9F%E5%8F%91%E7%8E%B0%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7%E5%90%8C%E6%A0%B7%E5%AD%98%E5%9C%A8%E5%A4%A7%E9%87%8F%E5%99%AA%E5%A3%B0%E6%95%B0%E6%8D%AE%EF%BC%8C%E8%A1%A5%E5%85%85%E4%BA%86%E4%B8%A4%E9%A1%B9%E8%BF%87%E6%BB%A4%E8%A7%84%E5%88%99%E6%9D%A5%E8%BF%87%E6%BB%A4%E6%95%B0%E6%8D%AE%E3%80%82%E2%91%A0%20%E5%A4%A7%E9%87%8F%E7%9A%84%20POI%20%E6%9C%AA%E8%A2%AB%E7%94%A8%E6%88%B7%E7%82%B9%E5%87%BB%E6%98%AF%E5%9B%A0%E4%B8%BA%E4%B8%8D%E6%98%AF%E7%A6%BB%E7%94%A8%E6%88%B7%E6%9C%80%E8%BF%91%E7%9A%84%E5%88%86%E5%BA%97%EF%BC%8C%E4%BD%86%20POI%20%E5%92%8C%20Query%20%E6%98%AF%E7%9B%B8%E5%85%B3%E7%9A%84%EF%BC%8C%E8%BF%99%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%A0%B7%E4%BE%8B%E9%9C%80%E8%A6%81%E8%BF%87%E6%BB%A4%E6%8E%89%EF%BC%8C%E5%A6%82%20%3C%E8%9B%99%E5%B0%8F%E4%BE%A0%20%EF%BC%8C%E8%9B%99%E5%B0%8F%E4%BE%A0%EF%BC%88%E6%96%B0%E5%8C%97%E4%B8%87%E8%BE%BE%E5%BA%97%EF%BC%89%3E%E3%80%82%E2%91%A1%20%E7%94%A8%E6%88%B7%20Query%20%E9%87%8C%E5%8C%85%E5%90%AB%E5%93%81%E7%89%8C%E8%AF%8D%EF%BC%8C%E5%B9%B6%E4%B8%94%20POI%20%E5%AE%8C%E5%85%A8%E7%AD%89%E5%90%8C%E4%BA%8E%E5%93%81%E7%89%8C%E8%AF%8D%E7%9A%84%EF%BC%8C%E9%9C%80%E8%A6%81%E4%BB%8E%E8%B4%9F%E6%A0%B7%E6%9C%AC%E4%B8%AD%E8%BF%87%E6%BB%A4%EF%BC%8C%E5%A6%82%20%3C%20%E5%BE%B7%E5%85%8B%E5%A3%AB%E5%90%83%E9%A5%AD%20%EF%BC%8C%E5%BE%B7%E5%85%8B%E5%A3%AB%20%3E%E3%80%82))

- > **Skip-Above 采样**：受限于 App 搜索场景的展示屏效，无法保证召回的 POI 一次性得到曝光。若直接将未被点击的 POI 作为负例，可能会将未曝光但相关的 POI 错误地采样为负例。为了保证训练数据的准确性，我们采用 Skip-Above 方法，剔除这些噪音负例，即从用户点击过的 POI 之上没有被点击过的 POI 中采样负例（假设用户是从上往下浏览的 POI）。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Skip-Above%20%E9%87%87%E6%A0%B7%EF%BC%9A%E5%8F%97%E9%99%90%E4%BA%8E%20App%20%E6%90%9C%E7%B4%A2%E5%9C%BA%E6%99%AF%E7%9A%84%E5%B1%95%E7%A4%BA%E5%B1%8F%E6%95%88%EF%BC%8C%E6%97%A0%E6%B3%95%E4%BF%9D%E8%AF%81%E5%8F%AC%E5%9B%9E%E7%9A%84%20POI%20%E4%B8%80%E6%AC%A1%E6%80%A7%E5%BE%97%E5%88%B0%E6%9B%9D%E5%85%89%E3%80%82%E8%8B%A5%E7%9B%B4%E6%8E%A5%E5%B0%86%E6%9C%AA%E8%A2%AB%E7%82%B9%E5%87%BB%E7%9A%84%20POI%20%E4%BD%9C%E4%B8%BA%E8%B4%9F%E4%BE%8B%EF%BC%8C%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%B0%86%E6%9C%AA%E6%9B%9D%E5%85%89%E4%BD%86%E7%9B%B8%E5%85%B3%E7%9A%84%20POI%20%E9%94%99%E8%AF%AF%E5%9C%B0%E9%87%87%E6%A0%B7%E4%B8%BA%E8%B4%9F%E4%BE%8B%E3%80%82%E4%B8%BA%E4%BA%86%E4%BF%9D%E8%AF%81%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7%EF%BC%8C%E6%88%91%E4%BB%AC%E9%87%87%E7%94%A8%20Skip-Above%20%E6%96%B9%E6%B3%95%EF%BC%8C%E5%89%94%E9%99%A4%E8%BF%99%E4%BA%9B%E5%99%AA%E9%9F%B3%E8%B4%9F%E4%BE%8B%EF%BC%8C%E5%8D%B3%E4%BB%8E%E7%94%A8%E6%88%B7%E7%82%B9%E5%87%BB%E8%BF%87%E7%9A%84%20POI%20%E4%B9%8B%E4%B8%8A%E6%B2%A1%E6%9C%89%E8%A2%AB%E7%82%B9%E5%87%BB%E8%BF%87%E7%9A%84%20POI%20%E4%B8%AD%E9%87%87%E6%A0%B7%E8%B4%9F%E4%BE%8B%EF%BC%88%E5%81%87%E8%AE%BE%E7%94%A8%E6%88%B7%E6%98%AF%E4%BB%8E%E4%B8%8A%E5%BE%80%E4%B8%8B%E6%B5%8F%E8%A7%88%E7%9A%84%20POI%EF%BC%89%E3%80%82))

- > 搜索品牌词有时会召回多个品牌的结果，假设用户搜索的品牌排序靠后，而其他品牌排序靠前会严重影响到用户体验，因此对 Query 和 POI 相关性建模时召回结果中其他品牌的 POI 可认为是不相关样本。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%90%9C%E7%B4%A2%E5%93%81%E7%89%8C%E8%AF%8D%E6%9C%89%E6%97%B6%E4%BC%9A%E5%8F%AC%E5%9B%9E%E5%A4%9A%E4%B8%AA%E5%93%81%E7%89%8C%E7%9A%84%E7%BB%93%E6%9E%9C%EF%BC%8C%E5%81%87%E8%AE%BE%E7%94%A8%E6%88%B7%E6%90%9C%E7%B4%A2%E7%9A%84%E5%93%81%E7%89%8C%E6%8E%92%E5%BA%8F%E9%9D%A0%E5%90%8E%EF%BC%8C%E8%80%8C%E5%85%B6%E4%BB%96%E5%93%81%E7%89%8C%E6%8E%92%E5%BA%8F%E9%9D%A0%E5%89%8D%E4%BC%9A%E4%B8%A5%E9%87%8D%E5%BD%B1%E5%93%8D%E5%88%B0%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%EF%BC%8C%E5%9B%A0%E6%AD%A4%E5%AF%B9%20Query%20%E5%92%8C%20POI%20%E7%9B%B8%E5%85%B3%E6%80%A7%E5%BB%BA%E6%A8%A1%E6%97%B6%E5%8F%AC%E5%9B%9E%E7%BB%93%E6%9E%9C%E4%B8%AD%E5%85%B6%E4%BB%96%E5%93%81%E7%89%8C%E7%9A%84%20POI%20%E5%8F%AF%E8%AE%A4%E4%B8%BA%E6%98%AF%E4%B8%8D%E7%9B%B8%E5%85%B3%E6%A0%B7%E6%9C%AC%E3%80%82))

- > **POI 名映射到品牌**：在品牌搜 Query 不包含地标词的时候，将 POI 名映射到品牌（非品牌 POI 不进行映射），从而消除品牌 POI 分店名中地标词引入的噪声。如 Query 是 “香格里拉酒店”，召回的“香格里拉大酒店” 和“北京香格里拉饭店”统一映射为品牌名 “香格里拉酒店”。Query 是“品牌 + 地标” 形式（如“香格里拉饭店 北京”）时，用户意图明确就是找某个地点的 POI，不需要进行映射  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=POI%20%E5%90%8D%E6%98%A0%E5%B0%84%E5%88%B0%E5%93%81%E7%89%8C%EF%BC%9A%E5%9C%A8%E5%93%81%E7%89%8C%E6%90%9C%20Query%20%E4%B8%8D%E5%8C%85%E5%90%AB%E5%9C%B0%E6%A0%87%E8%AF%8D%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%B0%86%20POI%20%E5%90%8D%E6%98%A0%E5%B0%84%E5%88%B0%E5%93%81%E7%89%8C%EF%BC%88%E9%9D%9E%E5%93%81%E7%89%8C%20POI%20%E4%B8%8D%E8%BF%9B%E8%A1%8C%E6%98%A0%E5%B0%84%EF%BC%89%EF%BC%8C%E4%BB%8E%E8%80%8C%E6%B6%88%E9%99%A4%E5%93%81%E7%89%8C%20POI%20%E5%88%86%E5%BA%97%E5%90%8D%E4%B8%AD%E5%9C%B0%E6%A0%87%E8%AF%8D%E5%BC%95%E5%85%A5%E7%9A%84%E5%99%AA%E5%A3%B0%E3%80%82%E5%A6%82%20Query%20%E6%98%AF%20%E2%80%9C%E9%A6%99%E6%A0%BC%E9%87%8C%E6%8B%89%E9%85%92%E5%BA%97%E2%80%9D%EF%BC%8C%E5%8F%AC%E5%9B%9E%E7%9A%84%E2%80%9C%E9%A6%99%E6%A0%BC%E9%87%8C%E6%8B%89%E5%A4%A7%E9%85%92%E5%BA%97%E2%80%9D%20%E5%92%8C%E2%80%9C%E5%8C%97%E4%BA%AC%E9%A6%99%E6%A0%BC%E9%87%8C%E6%8B%89%E9%A5%AD%E5%BA%97%E2%80%9D%E7%BB%9F%E4%B8%80%E6%98%A0%E5%B0%84%E4%B8%BA%E5%93%81%E7%89%8C%E5%90%8D%20%E2%80%9C%E9%A6%99%E6%A0%BC%E9%87%8C%E6%8B%89%E9%85%92%E5%BA%97%E2%80%9D%E3%80%82Query%20%E6%98%AF%E2%80%9C%E5%93%81%E7%89%8C%20+%20%E5%9C%B0%E6%A0%87%E2%80%9D%20%E5%BD%A2%E5%BC%8F%EF%BC%88%E5%A6%82%E2%80%9C%E9%A6%99%E6%A0%BC%E9%87%8C%E6%8B%89%E9%A5%AD%E5%BA%97%20%E5%8C%97%E4%BA%AC%E2%80%9D%EF%BC%89%E6%97%B6%EF%BC%8C%E7%94%A8%E6%88%B7%E6%84%8F%E5%9B%BE%E6%98%8E%E7%A1%AE%E5%B0%B1%E6%98%AF%E6%89%BE%E6%9F%90%E4%B8%AA%E5%9C%B0%E7%82%B9%E7%9A%84%20POI%EF%BC%8C%E4%B8%8D%E9%9C%80%E8%A6%81%E8%BF%9B%E8%A1%8C%E6%98%A0%E5%B0%84))
  - 📝 召回前映射还是召回后？召回后改写，并保留该名称至排序算法，这算是标题改写吧？

- > **负样本过滤**：如果搜索词是品牌词，在选取负样本的时候只在其他品牌的样本中选取。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E8%B4%9F%E6%A0%B7%E6%9C%AC%E8%BF%87%E6%BB%A4%EF%BC%9A%E5%A6%82%E6%9E%9C%E6%90%9C%E7%B4%A2%E8%AF%8D%E6%98%AF%E5%93%81%E7%89%8C%E8%AF%8D%EF%BC%8C%E5%9C%A8%E9%80%89%E5%8F%96%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%9A%84%E6%97%B6%E5%80%99%E5%8F%AA%E5%9C%A8%E5%85%B6%E4%BB%96%E5%93%81%E7%89%8C%E7%9A%84%E6%A0%B7%E6%9C%AC%E4%B8%AD%E9%80%89%E5%8F%96%E3%80%82))

- > 美团搜索场景中的 Query 和 Doc 都以短文本为主，我们尝试在预训练和 Fine-tuning 阶段融入图谱品类和实体信息，弥补 Query 和 Doc 文本信息的不足，强化语义匹配效果。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E5%9C%BA%E6%99%AF%E4%B8%AD%E7%9A%84%20Query%20%E5%92%8C%20Doc%20%E9%83%BD%E4%BB%A5%E7%9F%AD%E6%96%87%E6%9C%AC%E4%B8%BA%E4%B8%BB%EF%BC%8C%E6%88%91%E4%BB%AC%E5%B0%9D%E8%AF%95%E5%9C%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E5%92%8C%20Fine-tuning%20%E9%98%B6%E6%AE%B5%E8%9E%8D%E5%85%A5%E5%9B%BE%E8%B0%B1%E5%93%81%E7%B1%BB%E5%92%8C%E5%AE%9E%E4%BD%93%E4%BF%A1%E6%81%AF%EF%BC%8C%E5%BC%A5%E8%A1%A5%20Query%20%E5%92%8C%20Doc%20%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E7%9A%84%E4%B8%8D%E8%B6%B3%EF%BC%8C%E5%BC%BA%E5%8C%96%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E6%95%88%E6%9E%9C%E3%80%82))

- > 为了引入 Doc 品类信息，我们将 Doc 三级品类信息拼接到 Doc 标题之后，然后跟 Query 进行相关性判断  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E4%B8%BA%E4%BA%86%E5%BC%95%E5%85%A5%20Doc%20%E5%93%81%E7%B1%BB%E4%BF%A1%E6%81%AF%EF%BC%8C%E6%88%91%E4%BB%AC%E5%B0%86%20Doc%20%E4%B8%89%E7%BA%A7%E5%93%81%E7%B1%BB%E4%BF%A1%E6%81%AF%E6%8B%BC%E6%8E%A5%E5%88%B0%20Doc%20%E6%A0%87%E9%A2%98%E4%B9%8B%E5%90%8E%EF%BC%8C%E7%84%B6%E5%90%8E%E8%B7%9F%20Query%20%E8%BF%9B%E8%A1%8C%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%A4%E6%96%AD))

- > 引入额外片段编码的作用是防止额外信息对 Query 和 Doc 标题产生交叉干扰。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%BC%95%E5%85%A5%E9%A2%9D%E5%A4%96%E7%89%87%E6%AE%B5%E7%BC%96%E7%A0%81%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF%E9%98%B2%E6%AD%A2%E9%A2%9D%E5%A4%96%E4%BF%A1%E6%81%AF%E5%AF%B9%20Query%20%E5%92%8C%20Doc%20%E6%A0%87%E9%A2%98%E4%BA%A7%E7%94%9F%E4%BA%A4%E5%8F%89%E5%B9%B2%E6%89%B0%E3%80%82))

- > 我们对 MT-BERT 的预训练方式做了相应改进，BERT 预训练的目标之一是 NSP（Next Sentence Prediction），在搜索场景中没有上下句的概念，在给定用户的搜索关键词和商户文本信息后，判断用户是否点击来取代 NSP 任务。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%88%91%E4%BB%AC%E5%AF%B9%20MT-BERT%20%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F%E5%81%9A%E4%BA%86%E7%9B%B8%E5%BA%94%E6%94%B9%E8%BF%9B%EF%BC%8CBERT%20%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E7%9B%AE%E6%A0%87%E4%B9%8B%E4%B8%80%E6%98%AF%20NSP%EF%BC%88Next%20Sentence%20Prediction%EF%BC%89%EF%BC%8C%E5%9C%A8%E6%90%9C%E7%B4%A2%E5%9C%BA%E6%99%AF%E4%B8%AD%E6%B2%A1%E6%9C%89%E4%B8%8A%E4%B8%8B%E5%8F%A5%E7%9A%84%E6%A6%82%E5%BF%B5%EF%BC%8C%E5%9C%A8%E7%BB%99%E5%AE%9A%E7%94%A8%E6%88%B7%E7%9A%84%E6%90%9C%E7%B4%A2%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%95%86%E6%88%B7%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E5%90%8E%EF%BC%8C%E5%88%A4%E6%96%AD%E7%94%A8%E6%88%B7%E6%98%AF%E5%90%A6%E7%82%B9%E5%87%BB%E6%9D%A5%E5%8F%96%E4%BB%A3%20NSP%20%E4%BB%BB%E5%8A%A1%E3%80%82))

- > 正确的识别出 Query/Doc 中的实体成分有助于相关性的判断。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%AF%86%E5%88%AB%E5%87%BA%20Query/Doc%20%E4%B8%AD%E7%9A%84%E5%AE%9E%E4%BD%93%E6%88%90%E5%88%86%E6%9C%89%E5%8A%A9%E4%BA%8E%E7%9B%B8%E5%85%B3%E6%80%A7%E7%9A%84%E5%88%A4%E6%96%AD%E3%80%82))

- > 由于 BERT Fine-tuning 任务也支持命名实体识别（NER）任务，因而我们在 Query-Doc 相关性判断任务的基础上引入 Query 和 Doc 中实体成分识别的辅助任务，通过对两个任务的联合训练来优化最终相关性判别结果  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E7%94%B1%E4%BA%8E%20BERT%20Fine-tuning%20%E4%BB%BB%E5%8A%A1%E4%B9%9F%E6%94%AF%E6%8C%81%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%EF%BC%88NER%EF%BC%89%E4%BB%BB%E5%8A%A1%EF%BC%8C%E5%9B%A0%E8%80%8C%E6%88%91%E4%BB%AC%E5%9C%A8%20Query-Doc%20%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%A4%E6%96%AD%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B8%8A%E5%BC%95%E5%85%A5%20Query%20%E5%92%8C%20Doc%20%E4%B8%AD%E5%AE%9E%E4%BD%93%E6%88%90%E5%88%86%E8%AF%86%E5%88%AB%E7%9A%84%E8%BE%85%E5%8A%A9%E4%BB%BB%E5%8A%A1%EF%BC%8C%E9%80%9A%E8%BF%87%E5%AF%B9%E4%B8%A4%E4%B8%AA%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%81%94%E5%90%88%E8%AE%AD%E7%BB%83%E6%9D%A5%E4%BC%98%E5%8C%96%E6%9C%80%E7%BB%88%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%A4%E5%88%AB%E7%BB%93%E6%9E%9C))

- > 多任务学习模型的损失函数由两部分组成，分别是相关性判断损失函数和命名实体识别损失函数。其中相关性损失函数由 [CLS] 位的 Embedding 计算得到，而实体成分识别损失函数由每个 Token 的 Embedding 计算得到。2 种损失函数相加即为最终优化的损失函数。在训练命名实体识别任务时，每个 Token 的 Embedding 获得了和自身实体相关的信息，从而提升了相关性任务的效果。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%94%B1%E4%B8%A4%E9%83%A8%E5%88%86%E7%BB%84%E6%88%90%EF%BC%8C%E5%88%86%E5%88%AB%E6%98%AF%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%A4%E6%96%AD%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E3%80%82%E5%85%B6%E4%B8%AD%E7%9B%B8%E5%85%B3%E6%80%A7%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%94%B1%20%5BCLS%5D%20%E4%BD%8D%E7%9A%84%20Embedding%20%E8%AE%A1%E7%AE%97%E5%BE%97%E5%88%B0%EF%BC%8C%E8%80%8C%E5%AE%9E%E4%BD%93%E6%88%90%E5%88%86%E8%AF%86%E5%88%AB%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%94%B1%E6%AF%8F%E4%B8%AA%20Token%20%E7%9A%84%20Embedding%20%E8%AE%A1%E7%AE%97%E5%BE%97%E5%88%B0%E3%80%822%20%E7%A7%8D%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9B%B8%E5%8A%A0%E5%8D%B3%E4%B8%BA%E6%9C%80%E7%BB%88%E4%BC%98%E5%8C%96%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E3%80%82%E5%9C%A8%E8%AE%AD%E7%BB%83%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E4%BB%BB%E5%8A%A1%E6%97%B6%EF%BC%8C%E6%AF%8F%E4%B8%AA%20Token%20%E7%9A%84%20Embedding%20%E8%8E%B7%E5%BE%97%E4%BA%86%E5%92%8C%E8%87%AA%E8%BA%AB%E5%AE%9E%E4%BD%93%E7%9B%B8%E5%85%B3%E7%9A%84%E4%BF%A1%E6%81%AF%EF%BC%8C%E4%BB%8E%E8%80%8C%E6%8F%90%E5%8D%87%E4%BA%86%E7%9B%B8%E5%85%B3%E6%80%A7%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%95%88%E6%9E%9C%E3%80%82))

- > Query-Doc 相关性最终作为特征加入排序模型训练中  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Query-Doc%20%E7%9B%B8%E5%85%B3%E6%80%A7%E6%9C%80%E7%BB%88%E4%BD%9C%E4%B8%BA%E7%89%B9%E5%BE%81%E5%8A%A0%E5%85%A5%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%AD))
  - 📝 Query-Doc 相关性只是作为排序的一维特征而已。

- > Pointwise Fine-tuning 方法可以学习到很好的全局相关性，但忽略了不同样本之前的偏序关系。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Pointwise%20Fine-tuning%20%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E5%AD%A6%E4%B9%A0%E5%88%B0%E5%BE%88%E5%A5%BD%E7%9A%84%E5%85%A8%E5%B1%80%E7%9B%B8%E5%85%B3%E6%80%A7%EF%BC%8C%E4%BD%86%E5%BF%BD%E7%95%A5%E4%BA%86%E4%B8%8D%E5%90%8C%E6%A0%B7%E6%9C%AC%E4%B9%8B%E5%89%8D%E7%9A%84%E5%81%8F%E5%BA%8F%E5%85%B3%E7%B3%BB%E3%80%82))

- > Pairwise Fine-tuning 任务输入的单条样本为三元组，对于同一 Query 的多个候选 Doc，选择任意一个正例和一个负例组合成三元组作为输入样本。在下游任务中只需要使用少量的 Query 和 Doc 相关性的标注数据（有监督训练样本），对 BERT 模型进行相关性 Fine-tuning，产出 Query 和 Doc 的相关性特征。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Pairwise%20Fine-tuning%20%E4%BB%BB%E5%8A%A1%E8%BE%93%E5%85%A5%E7%9A%84%E5%8D%95%E6%9D%A1%E6%A0%B7%E6%9C%AC%E4%B8%BA%E4%B8%89%E5%85%83%E7%BB%84%EF%BC%8C%E5%AF%B9%E4%BA%8E%E5%90%8C%E4%B8%80%20Query%20%E7%9A%84%E5%A4%9A%E4%B8%AA%E5%80%99%E9%80%89%20Doc%EF%BC%8C%E9%80%89%E6%8B%A9%E4%BB%BB%E6%84%8F%E4%B8%80%E4%B8%AA%E6%AD%A3%E4%BE%8B%E5%92%8C%E4%B8%80%E4%B8%AA%E8%B4%9F%E4%BE%8B%E7%BB%84%E5%90%88%E6%88%90%E4%B8%89%E5%85%83%E7%BB%84%E4%BD%9C%E4%B8%BA%E8%BE%93%E5%85%A5%E6%A0%B7%E6%9C%AC%E3%80%82%E5%9C%A8%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E4%B8%AD%E5%8F%AA%E9%9C%80%E8%A6%81%E4%BD%BF%E7%94%A8%E5%B0%91%E9%87%8F%E7%9A%84%20Query%20%E5%92%8C%20Doc%20%E7%9B%B8%E5%85%B3%E6%80%A7%E7%9A%84%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE%EF%BC%88%E6%9C%89%E7%9B%91%E7%9D%A3%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%EF%BC%89%EF%BC%8C%E5%AF%B9%20BERT%20%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E7%9B%B8%E5%85%B3%E6%80%A7%20Fine-tuning%EF%BC%8C%E4%BA%A7%E5%87%BA%20Query%20%E5%92%8C%20Doc%20%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E7%89%B9%E5%BE%81%E3%80%82))
  - 📝 先双塔 fine-tuning，再单塔 fine-tuning？

- > Pairwise Fine-tuning 除了输入样本上的变化，为了考虑搜索场景下不同样本之间的偏序关系，我们参考 RankNet[34] 的方式对训练损失函数做了优化。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Pairwise%20Fine-tuning%20%E9%99%A4%E4%BA%86%E8%BE%93%E5%85%A5%E6%A0%B7%E6%9C%AC%E4%B8%8A%E7%9A%84%E5%8F%98%E5%8C%96%EF%BC%8C%E4%B8%BA%E4%BA%86%E8%80%83%E8%99%91%E6%90%9C%E7%B4%A2%E5%9C%BA%E6%99%AF%E4%B8%8B%E4%B8%8D%E5%90%8C%E6%A0%B7%E6%9C%AC%E4%B9%8B%E9%97%B4%E7%9A%84%E5%81%8F%E5%BA%8F%E5%85%B3%E7%B3%BB%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%82%E8%80%83%20RankNet%5B34%5D%20%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AF%B9%E8%AE%AD%E7%BB%83%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%81%9A%E4%BA%86%E4%BC%98%E5%8C%96%E3%80%82))

- > 前文所述各种优化属于两阶段训练方式，即先训练 BERT 相关性模型，然后训练 L2 排序模型。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%89%8D%E6%96%87%E6%89%80%E8%BF%B0%E5%90%84%E7%A7%8D%E4%BC%98%E5%8C%96%E5%B1%9E%E4%BA%8E%E4%B8%A4%E9%98%B6%E6%AE%B5%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%8D%B3%E5%85%88%E8%AE%AD%E7%BB%83%20BERT%20%E7%9B%B8%E5%85%B3%E6%80%A7%E6%A8%A1%E5%9E%8B%EF%BC%8C%E7%84%B6%E5%90%8E%E8%AE%AD%E7%BB%83%20L2%20%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E3%80%82))

- > 我们设计了基于 Partition-model 的 BERT 相关性任务和排序任务的联合训练模型，Partition-model 的思想是利用所有数据进行全场景联合训练，同时一定程度上保留每个场景特性，从而解决多业务场景的排序问题  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%88%91%E4%BB%AC%E8%AE%BE%E8%AE%A1%E4%BA%86%E5%9F%BA%E4%BA%8E%20Partition-model%20%E7%9A%84%20BERT%20%E7%9B%B8%E5%85%B3%E6%80%A7%E4%BB%BB%E5%8A%A1%E5%92%8C%E6%8E%92%E5%BA%8F%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%81%94%E5%90%88%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%EF%BC%8CPartition-model%20%E7%9A%84%E6%80%9D%E6%83%B3%E6%98%AF%E5%88%A9%E7%94%A8%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%85%A8%E5%9C%BA%E6%99%AF%E8%81%94%E5%90%88%E8%AE%AD%E7%BB%83%EF%BC%8C%E5%90%8C%E6%97%B6%E4%B8%80%E5%AE%9A%E7%A8%8B%E5%BA%A6%E4%B8%8A%E4%BF%9D%E7%95%99%E6%AF%8F%E4%B8%AA%E5%9C%BA%E6%99%AF%E7%89%B9%E6%80%A7%EF%BC%8C%E4%BB%8E%E8%80%8C%E8%A7%A3%E5%86%B3%E5%A4%9A%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E7%9A%84%E6%8E%92%E5%BA%8F%E9%97%AE%E9%A2%98))

- > ![](https://p0.meituan.net/travelcube/55041ac3629136a0876291e43545ecd072335.png)  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=https://p0.meituan.net/travelcube/55041ac3629136a0876291e43545ecd072335.png))

- > 文本特征向量使用 BERT 进行抽取，文本特征主要包括 Query 和 POI 相关的一些文本（POI 名称、品类名称、品牌名称等）。将文本特征送入预训练好的 MT-BERT 模型，取 CLS 向量作为文本特征的语义表示。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E4%BD%BF%E7%94%A8%20BERT%20%E8%BF%9B%E8%A1%8C%E6%8A%BD%E5%8F%96%EF%BC%8C%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E4%B8%BB%E8%A6%81%E5%8C%85%E6%8B%AC%20Query%20%E5%92%8C%20POI%20%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E6%96%87%E6%9C%AC%EF%BC%88POI%20%E5%90%8D%E7%A7%B0%E3%80%81%E5%93%81%E7%B1%BB%E5%90%8D%E7%A7%B0%E3%80%81%E5%93%81%E7%89%8C%E5%90%8D%E7%A7%B0%E7%AD%89%EF%BC%89%E3%80%82%E5%B0%86%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E9%80%81%E5%85%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%20MT-BERT%20%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%8F%96%20CLS%20%E5%90%91%E9%87%8F%E4%BD%9C%E4%B8%BA%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E7%9A%84%E8%AF%AD%E4%B9%89%E8%A1%A8%E7%A4%BA%E3%80%82))

- > 用户行为序列特征向量使用 Transformer 进行抽取  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E4%BD%BF%E7%94%A8%20Transformer%20%E8%BF%9B%E8%A1%8C%E6%8A%BD%E5%8F%96))

- > 其他特征主要包括：① 统计类特征，包含 Query、Doc 等维度的特征以及它们之间的交叉特征，使用这些特征主要是为了丰富 Query 和 Doc 的表示，更好地辅助相关性任务训练。② 文本特征，这部分的特征同 1 中的文本特征，但是使用方式不同，直接将文本分词后做 Embedding，端到端的学习文本语义表征。③ 传统的文本相关性特征，包括 Query 和 Doc 的字面命中、覆盖程度、BM25 等特征，虽然语义相关性具有较好的作用，但字面相关性仍然是一个不可或缺的模块，它起到信息补充的作用。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%85%B6%E4%BB%96%E7%89%B9%E5%BE%81%E4%B8%BB%E8%A6%81%E5%8C%85%E6%8B%AC%EF%BC%9A%E2%91%A0%20%E7%BB%9F%E8%AE%A1%E7%B1%BB%E7%89%B9%E5%BE%81%EF%BC%8C%E5%8C%85%E5%90%AB%20Query%E3%80%81Doc%20%E7%AD%89%E7%BB%B4%E5%BA%A6%E7%9A%84%E7%89%B9%E5%BE%81%E4%BB%A5%E5%8F%8A%E5%AE%83%E4%BB%AC%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%EF%BC%8C%E4%BD%BF%E7%94%A8%E8%BF%99%E4%BA%9B%E7%89%B9%E5%BE%81%E4%B8%BB%E8%A6%81%E6%98%AF%E4%B8%BA%E4%BA%86%E4%B8%B0%E5%AF%8C%20Query%20%E5%92%8C%20Doc%20%E7%9A%84%E8%A1%A8%E7%A4%BA%EF%BC%8C%E6%9B%B4%E5%A5%BD%E5%9C%B0%E8%BE%85%E5%8A%A9%E7%9B%B8%E5%85%B3%E6%80%A7%E4%BB%BB%E5%8A%A1%E8%AE%AD%E7%BB%83%E3%80%82%E2%91%A1%20%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%EF%BC%8C%E8%BF%99%E9%83%A8%E5%88%86%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%8C%201%20%E4%B8%AD%E7%9A%84%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%EF%BC%8C%E4%BD%86%E6%98%AF%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F%E4%B8%8D%E5%90%8C%EF%BC%8C%E7%9B%B4%E6%8E%A5%E5%B0%86%E6%96%87%E6%9C%AC%E5%88%86%E8%AF%8D%E5%90%8E%E5%81%9A%20Embedding%EF%BC%8C%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%87%E6%9C%AC%E8%AF%AD%E4%B9%89%E8%A1%A8%E5%BE%81%E3%80%82%E2%91%A2%20%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%96%87%E6%9C%AC%E7%9B%B8%E5%85%B3%E6%80%A7%E7%89%B9%E5%BE%81%EF%BC%8C%E5%8C%85%E6%8B%AC%20Query%20%E5%92%8C%20Doc%20%E7%9A%84%E5%AD%97%E9%9D%A2%E5%91%BD%E4%B8%AD%E3%80%81%E8%A6%86%E7%9B%96%E7%A8%8B%E5%BA%A6%E3%80%81BM25%20%E7%AD%89%E7%89%B9%E5%BE%81%EF%BC%8C%E8%99%BD%E7%84%B6%E8%AF%AD%E4%B9%89%E7%9B%B8%E5%85%B3%E6%80%A7%E5%85%B7%E6%9C%89%E8%BE%83%E5%A5%BD%E7%9A%84%E4%BD%9C%E7%94%A8%EF%BC%8C%E4%BD%86%E5%AD%97%E9%9D%A2%E7%9B%B8%E5%85%B3%E6%80%A7%E4%BB%8D%E7%84%B6%E6%98%AF%E4%B8%80%E4%B8%AA%E4%B8%8D%E5%8F%AF%E6%88%96%E7%BC%BA%E7%9A%84%E6%A8%A1%E5%9D%97%EF%BC%8C%E5%AE%83%E8%B5%B7%E5%88%B0%E4%BF%A1%E6%81%AF%E8%A1%A5%E5%85%85%E7%9A%84%E4%BD%9C%E7%94%A8%E3%80%82))

- > 为了解决 BERT 模型参数量过大、前向计算耗时的问题，常用轻量化方法有三种  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%20BERT%20%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E9%87%8F%E8%BF%87%E5%A4%A7%E3%80%81%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E8%80%97%E6%97%B6%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%8C%E5%B8%B8%E7%94%A8%E8%BD%BB%E9%87%8F%E5%8C%96%E6%96%B9%E6%B3%95%E6%9C%89%E4%B8%89%E7%A7%8D))
  - 📝 1. 知识蒸馏
  - 📝 2. 模型裁剪
  - 📝 3. 低精度量化

- > 在美团搜索的场景下，Query 和 Doc 拼接后整个文本序列变长，包含更复杂的语义关系，直接裁剪模型会带来更多的性能损失。因此，我们在上线 Query-Doc 相关性模型之前，采用知识蒸馏方式，在尽可能在保持模型性能的前提下对模型层数和参数做压缩。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%9C%A8%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E7%9A%84%E5%9C%BA%E6%99%AF%E4%B8%8B%EF%BC%8CQuery%20%E5%92%8C%20Doc%20%E6%8B%BC%E6%8E%A5%E5%90%8E%E6%95%B4%E4%B8%AA%E6%96%87%E6%9C%AC%E5%BA%8F%E5%88%97%E5%8F%98%E9%95%BF%EF%BC%8C%E5%8C%85%E5%90%AB%E6%9B%B4%E5%A4%8D%E6%9D%82%E7%9A%84%E8%AF%AD%E4%B9%89%E5%85%B3%E7%B3%BB%EF%BC%8C%E7%9B%B4%E6%8E%A5%E8%A3%81%E5%89%AA%E6%A8%A1%E5%9E%8B%E4%BC%9A%E5%B8%A6%E6%9D%A5%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%80%A7%E8%83%BD%E6%8D%9F%E5%A4%B1%E3%80%82%E5%9B%A0%E6%AD%A4%EF%BC%8C%E6%88%91%E4%BB%AC%E5%9C%A8%E4%B8%8A%E7%BA%BF%20Query-Doc%20%E7%9B%B8%E5%85%B3%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E5%89%8D%EF%BC%8C%E9%87%87%E7%94%A8%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%9C%A8%E5%B0%BD%E5%8F%AF%E8%83%BD%E5%9C%A8%E4%BF%9D%E6%8C%81%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E5%89%8D%E6%8F%90%E4%B8%8B%E5%AF%B9%E6%A8%A1%E5%9E%8B%E5%B1%82%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E5%81%9A%E5%8E%8B%E7%BC%A9%E3%80%82))

- > 首先我们基于 MT-BERT（12 Layers），在大规模的美团点评业务语料上进行知识蒸馏得到通用的 MT-BERT 蒸馏模型（6 Layers），蒸馏后的模型可以作为具体下游任务 Fine-tuning 时的初始化模型。在美团搜索的场景下，我们进一步基于通用的 MT-BERT 蒸馏模型（6 Layers）进行相关性任务 Fine-tuning ，得到 MT-BERT 蒸馏（2 Layers）进行上线。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E9%A6%96%E5%85%88%E6%88%91%E4%BB%AC%E5%9F%BA%E4%BA%8E%20MT-BERT%EF%BC%8812%20Layers%EF%BC%89%EF%BC%8C%E5%9C%A8%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%9A%84%E7%BE%8E%E5%9B%A2%E7%82%B9%E8%AF%84%E4%B8%9A%E5%8A%A1%E8%AF%AD%E6%96%99%E4%B8%8A%E8%BF%9B%E8%A1%8C%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E5%BE%97%E5%88%B0%E9%80%9A%E7%94%A8%E7%9A%84%20MT-BERT%20%E8%92%B8%E9%A6%8F%E6%A8%A1%E5%9E%8B%EF%BC%886%20Layers%EF%BC%89%EF%BC%8C%E8%92%B8%E9%A6%8F%E5%90%8E%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E4%BD%9C%E4%B8%BA%E5%85%B7%E4%BD%93%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%20Fine-tuning%20%E6%97%B6%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E3%80%82%E5%9C%A8%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E7%9A%84%E5%9C%BA%E6%99%AF%E4%B8%8B%EF%BC%8C%E6%88%91%E4%BB%AC%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%9F%BA%E4%BA%8E%E9%80%9A%E7%94%A8%E7%9A%84%20MT-BERT%20%E8%92%B8%E9%A6%8F%E6%A8%A1%E5%9E%8B%EF%BC%886%20Layers%EF%BC%89%E8%BF%9B%E8%A1%8C%E7%9B%B8%E5%85%B3%E6%80%A7%E4%BB%BB%E5%8A%A1%20Fine-tuning%20%EF%BC%8C%E5%BE%97%E5%88%B0%20MT-BERT%20%E8%92%B8%E9%A6%8F%EF%BC%882%20Layers%EF%BC%89%E8%BF%9B%E8%A1%8C%E4%B8%8A%E7%BA%BF%E3%80%82))

- > ![](https://p0.meituan.net/travelcube/90ab6ee13a7f5641d60dc3a6f10c2b7995331.png)  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=https://p0.meituan.net/travelcube/90ab6ee13a7f5641d60dc3a6f10c2b7995331.png))

- > **模型在线预估框架（Augur）**：支持语言化定义特征，配置化加载和卸载模型与特征，支持主流线性模型与 TF 模型的在线预估；基于 Augur 可以方便地构建功能完善的无状态、分布式的模型预估服务。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%A8%A1%E5%9E%8B%E5%9C%A8%E7%BA%BF%E9%A2%84%E4%BC%B0%E6%A1%86%E6%9E%B6%EF%BC%88Augur%EF%BC%89%EF%BC%9A%E6%94%AF%E6%8C%81%E8%AF%AD%E8%A8%80%E5%8C%96%E5%AE%9A%E4%B9%89%E7%89%B9%E5%BE%81%EF%BC%8C%E9%85%8D%E7%BD%AE%E5%8C%96%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%8D%B8%E8%BD%BD%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%89%B9%E5%BE%81%EF%BC%8C%E6%94%AF%E6%8C%81%E4%B8%BB%E6%B5%81%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%8E%20TF%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9C%A8%E7%BA%BF%E9%A2%84%E4%BC%B0%EF%BC%9B%E5%9F%BA%E4%BA%8E%20Augur%20%E5%8F%AF%E4%BB%A5%E6%96%B9%E4%BE%BF%E5%9C%B0%E6%9E%84%E5%BB%BA%E5%8A%9F%E8%83%BD%E5%AE%8C%E5%96%84%E7%9A%84%E6%97%A0%E7%8A%B6%E6%80%81%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%A2%84%E4%BC%B0%E6%9C%8D%E5%8A%A1%E3%80%82))

- > Augur 团队开发了 Model Stacking 功能，完美支持了 BERT as Feature  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=Augur%20%E5%9B%A2%E9%98%9F%E5%BC%80%E5%8F%91%E4%BA%86%20Model%20Stacking%20%E5%8A%9F%E8%83%BD%EF%BC%8C%E5%AE%8C%E7%BE%8E%E6%94%AF%E6%8C%81%E4%BA%86%20BERT%20as%20Feature))

- > **搜索模型实验平台（Poker）**：支持超大规模数据和模型的离线特征抽取、模型训练，支持 BERT 模型自助训练 / Fine-tuning 和预测；同时打通了 Augur 服务，训练好的模型可以实现一键上线，大大提升了模型的实验效率。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E6%90%9C%E7%B4%A2%E6%A8%A1%E5%9E%8B%E5%AE%9E%E9%AA%8C%E5%B9%B3%E5%8F%B0%EF%BC%88Poker%EF%BC%89%EF%BC%9A%E6%94%AF%E6%8C%81%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%92%8C%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%A6%BB%E7%BA%BF%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96%E3%80%81%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%EF%BC%8C%E6%94%AF%E6%8C%81%20BERT%20%E6%A8%A1%E5%9E%8B%E8%87%AA%E5%8A%A9%E8%AE%AD%E7%BB%83%20/%20Fine-tuning%20%E5%92%8C%E9%A2%84%E6%B5%8B%EF%BC%9B%E5%90%8C%E6%97%B6%E6%89%93%E9%80%9A%E4%BA%86%20Augur%20%E6%9C%8D%E5%8A%A1%EF%BC%8C%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E5%AE%9E%E7%8E%B0%E4%B8%80%E9%94%AE%E4%B8%8A%E7%BA%BF%EF%BC%8C%E5%A4%A7%E5%A4%A7%E6%8F%90%E5%8D%87%E4%BA%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%95%88%E7%8E%87%E3%80%82))

- > TF-Serving 在线模型服务：L2 排序模型、BERT 模型上线使用 TF-Serving 进行部署。TF-Serving 预测引擎支持 Faster Transformer[38] 加速 BERT 推理，提升了线上的预估速度。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=TF-Serving%20%E5%9C%A8%E7%BA%BF%E6%A8%A1%E5%9E%8B%E6%9C%8D%E5%8A%A1%EF%BC%9AL2%20%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E3%80%81BERT%20%E6%A8%A1%E5%9E%8B%E4%B8%8A%E7%BA%BF%E4%BD%BF%E7%94%A8%20TF-Serving%20%E8%BF%9B%E8%A1%8C%E9%83%A8%E7%BD%B2%E3%80%82TF-Serving%20%E9%A2%84%E6%B5%8B%E5%BC%95%E6%93%8E%E6%94%AF%E6%8C%81%20Faster%20Transformer%5B38%5D%20%E5%8A%A0%E9%80%9F%20BERT%20%E6%8E%A8%E7%90%86%EF%BC%8C%E6%8F%90%E5%8D%87%E4%BA%86%E7%BA%BF%E4%B8%8A%E7%9A%84%E9%A2%84%E4%BC%B0%E9%80%9F%E5%BA%A6%E3%80%82))

- > 为了进一步提升性能，我们将头部 Query 进行缓存只对长尾 Query 进行在线打分，线上预估结合缓存的方式，即节约了 GPU 资源又提升了线上预估速度。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E4%B8%BA%E4%BA%86%E8%BF%9B%E4%B8%80%E6%AD%A5%E6%8F%90%E5%8D%87%E6%80%A7%E8%83%BD%EF%BC%8C%E6%88%91%E4%BB%AC%E5%B0%86%E5%A4%B4%E9%83%A8%20Query%20%E8%BF%9B%E8%A1%8C%E7%BC%93%E5%AD%98%E5%8F%AA%E5%AF%B9%E9%95%BF%E5%B0%BE%20Query%20%E8%BF%9B%E8%A1%8C%E5%9C%A8%E7%BA%BF%E6%89%93%E5%88%86%EF%BC%8C%E7%BA%BF%E4%B8%8A%E9%A2%84%E4%BC%B0%E7%BB%93%E5%90%88%E7%BC%93%E5%AD%98%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%8D%B3%E8%8A%82%E7%BA%A6%E4%BA%86%20GPU%20%E8%B5%84%E6%BA%90%E5%8F%88%E6%8F%90%E5%8D%87%E4%BA%86%E7%BA%BF%E4%B8%8A%E9%A2%84%E4%BC%B0%E9%80%9F%E5%BA%A6%E3%80%82))

- > 在样本数据上，我们结合了美团搜索业务领域知识，基于弱监督点击日志构建了高质量的训练样本；针对美团搜索多模态特点，在预训练和 Fine-tuning 阶段融合图谱品类和标签等信息，弥补 Query 和 Doc 文本较短的不足，强化文本匹配效果。  ([🌐 摘要链接](https://tech.meituan.com/2020/07/09/bert-in-meituan-search.html#js_content:~:text=%E5%9C%A8%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E4%B8%8A%EF%BC%8C%E6%88%91%E4%BB%AC%E7%BB%93%E5%90%88%E4%BA%86%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E4%B8%9A%E5%8A%A1%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%EF%BC%8C%E5%9F%BA%E4%BA%8E%E5%BC%B1%E7%9B%91%E7%9D%A3%E7%82%B9%E5%87%BB%E6%97%A5%E5%BF%97%E6%9E%84%E5%BB%BA%E4%BA%86%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%EF%BC%9B%E9%92%88%E5%AF%B9%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E5%A4%9A%E6%A8%A1%E6%80%81%E7%89%B9%E7%82%B9%EF%BC%8C%E5%9C%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E5%92%8C%20Fine-tuning%20%E9%98%B6%E6%AE%B5%E8%9E%8D%E5%90%88%E5%9B%BE%E8%B0%B1%E5%93%81%E7%B1%BB%E5%92%8C%E6%A0%87%E7%AD%BE%E7%AD%89%E4%BF%A1%E6%81%AF%EF%BC%8C%E5%BC%A5%E8%A1%A5%20Query%20%E5%92%8C%20Doc%20%E6%96%87%E6%9C%AC%E8%BE%83%E7%9F%AD%E7%9A%84%E4%B8%8D%E8%B6%B3%EF%BC%8C%E5%BC%BA%E5%8C%96%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D%E6%95%88%E6%9E%9C%E3%80%82))
  - 📝 美团的 Doc 有多短呀？

