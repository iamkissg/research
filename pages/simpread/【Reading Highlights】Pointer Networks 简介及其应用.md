title:: 【Reading Highlights】Pointer Networks 简介及其应用
source:: https://zhuanlan.zhihu.com/p/48959800
summary:: 
tags:: [[简悦]]  [[reading_highlights]]
date:: 20220622  

- > 传统带有注意力机制的 seq2seq 模型输出的是针对输出词汇表的一个概率分布，而 Pointer Networks 输出的则是针对输入文本序列的概率分布。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/48959800#js_content:~:text=%E4%BC%A0%E7%BB%9F%E5%B8%A6%E6%9C%89%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%20seq2seq%20%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E7%9A%84%E6%98%AF%E9%92%88%E5%AF%B9%E8%BE%93%E5%87%BA%E8%AF%8D%E6%B1%87%E8%A1%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%EF%BC%8C%E8%80%8C%20Pointer%20Networks%20%E8%BE%93%E5%87%BA%E7%9A%84%E5%88%99%E6%98%AF%E9%92%88%E5%AF%B9%E8%BE%93%E5%85%A5%E6%96%87%E6%9C%AC%E5%BA%8F%E5%88%97%E7%9A%84%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E3%80%82))

- > Get To The Point: Summarization with Pointer-Generator Networks。

在这篇文章中，作者认为，用于文本摘要的 seq2seq 模型往往存在两大缺陷：1、模型容易不准确地再现事实细节，也就是说模型生成的摘要不准确；2、往往会重复，也就是会重复生成一些词或者句子。而针对这两种缺陷，作者分别使用 Pointer Networks 和 Coverage 技术来解决。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/48959800#js_content:~:text=Get%20To%20The%20Point:%20Summarization%20with%20Pointer-Generator%20Networks%E3%80%82%E5%9C%A8%E8%BF%99%E7%AF%87%E6%96%87%E7%AB%A0%E4%B8%AD%EF%BC%8C%E4%BD%9C%E8%80%85%E8%AE%A4%E4%B8%BA%EF%BC%8C%E7%94%A8%E4%BA%8E%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81%E7%9A%84%20seq2seq%20%E6%A8%A1%E5%9E%8B%E5%BE%80%E5%BE%80%E5%AD%98%E5%9C%A8%E4%B8%A4%E5%A4%A7%E7%BC%BA%E9%99%B7%EF%BC%9A1%E3%80%81%E6%A8%A1%E5%9E%8B%E5%AE%B9%E6%98%93%E4%B8%8D%E5%87%86%E7%A1%AE%E5%9C%B0%E5%86%8D%E7%8E%B0%E4%BA%8B%E5%AE%9E%E7%BB%86%E8%8A%82%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%AF%B4%E6%A8%A1%E5%9E%8B%E7%94%9F%E6%88%90%E7%9A%84%E6%91%98%E8%A6%81%E4%B8%8D%E5%87%86%E7%A1%AE%EF%BC%9B2%E3%80%81%E5%BE%80%E5%BE%80%E4%BC%9A%E9%87%8D%E5%A4%8D%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E4%BC%9A%E9%87%8D%E5%A4%8D%E7%94%9F%E6%88%90%E4%B8%80%E4%BA%9B%E8%AF%8D%E6%88%96%E8%80%85%E5%8F%A5%E5%AD%90%E3%80%82%E8%80%8C%E9%92%88%E5%AF%B9%E8%BF%99%E4%B8%A4%E7%A7%8D%E7%BC%BA%E9%99%B7%EF%BC%8C%E4%BD%9C%E8%80%85%E5%88%86%E5%88%AB%E4%BD%BF%E7%94%A8%20Pointer%20Networks%20%E5%92%8C%20Coverage%20%E6%8A%80%E6%9C%AF%E6%9D%A5%E8%A7%A3%E5%86%B3%E3%80%82))
  - 📝 指针生成网络要解决 seq2seq 范式的两大问题：反事实与重复；解决之道分别是：指针网络（注意力机制）和覆盖率机制。

- > 作者又加入了一个 Pgen 来作为软选择的概率。Pgen 的作用可以这样理解：决定当前预测是直接从源文本中复制一个词过来还是从词汇表中生成一个词出来。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/48959800#js_content:~:text=%E4%BD%9C%E8%80%85%E5%8F%88%E5%8A%A0%E5%85%A5%E4%BA%86%E4%B8%80%E4%B8%AA%20Pgen%20%E6%9D%A5%E4%BD%9C%E4%B8%BA%E8%BD%AF%E9%80%89%E6%8B%A9%E7%9A%84%E6%A6%82%E7%8E%87%E3%80%82Pgen%20%E7%9A%84%E4%BD%9C%E7%94%A8%E5%8F%AF%E4%BB%A5%E8%BF%99%E6%A0%B7%E7%90%86%E8%A7%A3%EF%BC%9A%E5%86%B3%E5%AE%9A%E5%BD%93%E5%89%8D%E9%A2%84%E6%B5%8B%E6%98%AF%E7%9B%B4%E6%8E%A5%E4%BB%8E%E6%BA%90%E6%96%87%E6%9C%AC%E4%B8%AD%E5%A4%8D%E5%88%B6%E4%B8%80%E4%B8%AA%E8%AF%8D%E8%BF%87%E6%9D%A5%E8%BF%98%E6%98%AF%E4%BB%8E%E8%AF%8D%E6%B1%87%E8%A1%A8%E4%B8%AD%E7%94%9F%E6%88%90%E4%B8%80%E4%B8%AA%E8%AF%8D%E5%87%BA%E6%9D%A5%E3%80%82))

- > 如果模型在预测时总是注意相同的部分，那么就很有可能会预测出相同的单词，因此为了防止这种情况发生，我们就强迫模型多去关注之前没被注意过的角落。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/48959800#js_content:~:text=%E5%A6%82%E6%9E%9C%E6%A8%A1%E5%9E%8B%E5%9C%A8%E9%A2%84%E6%B5%8B%E6%97%B6%E6%80%BB%E6%98%AF%E6%B3%A8%E6%84%8F%E7%9B%B8%E5%90%8C%E7%9A%84%E9%83%A8%E5%88%86%EF%BC%8C%E9%82%A3%E4%B9%88%E5%B0%B1%E5%BE%88%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BC%9A%E9%A2%84%E6%B5%8B%E5%87%BA%E7%9B%B8%E5%90%8C%E7%9A%84%E5%8D%95%E8%AF%8D%EF%BC%8C%E5%9B%A0%E6%AD%A4%E4%B8%BA%E4%BA%86%E9%98%B2%E6%AD%A2%E8%BF%99%E7%A7%8D%E6%83%85%E5%86%B5%E5%8F%91%E7%94%9F%EF%BC%8C%E6%88%91%E4%BB%AC%E5%B0%B1%E5%BC%BA%E8%BF%AB%E6%A8%A1%E5%9E%8B%E5%A4%9A%E5%8E%BB%E5%85%B3%E6%B3%A8%E4%B9%8B%E5%89%8D%E6%B2%A1%E8%A2%AB%E6%B3%A8%E6%84%8F%E8%BF%87%E7%9A%84%E8%A7%92%E8%90%BD%E3%80%82))

- > 为了鼓励多把注意力转向之前不被注意的角落的行为，作者在原本的 loss function 中加入了针对 Coverage 机制的 loss 项  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/48959800#js_content:~:text=%E4%B8%BA%E4%BA%86%E9%BC%93%E5%8A%B1%E5%A4%9A%E6%8A%8A%E6%B3%A8%E6%84%8F%E5%8A%9B%E8%BD%AC%E5%90%91%E4%B9%8B%E5%89%8D%E4%B8%8D%E8%A2%AB%E6%B3%A8%E6%84%8F%E7%9A%84%E8%A7%92%E8%90%BD%E7%9A%84%E8%A1%8C%E4%B8%BA%EF%BC%8C%E4%BD%9C%E8%80%85%E5%9C%A8%E5%8E%9F%E6%9C%AC%E7%9A%84%20loss%20function%20%E4%B8%AD%E5%8A%A0%E5%85%A5%E4%BA%86%E9%92%88%E5%AF%B9%20Coverage%20%E6%9C%BA%E5%88%B6%E7%9A%84%20loss%20%E9%A1%B9))

- > 商品标题摘要这个特殊问题天然存在对模型的两个限制：（1）摘要中不能引入不相关信息；（2）摘要中必须保留源文本的关键信息（如品牌名和商品名）。作者提出的解决办法是 Multi-Source Pointer Network。

对于第一点限制，作者使用 Pointer Networks 来直接从源标题中提取词汇，保证不会引入不相关信息，针对第二点，作者提出了 knowledge encoder 技术来满足要求。 [[阿里技术]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/48959800#js_content:~:text=%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E6%91%98%E8%A6%81%E8%BF%99%E4%B8%AA%E7%89%B9%E6%AE%8A%E9%97%AE%E9%A2%98%E5%A4%A9%E7%84%B6%E5%AD%98%E5%9C%A8%E5%AF%B9%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E4%B8%AA%E9%99%90%E5%88%B6%EF%BC%9A%EF%BC%881%EF%BC%89%E6%91%98%E8%A6%81%E4%B8%AD%E4%B8%8D%E8%83%BD%E5%BC%95%E5%85%A5%E4%B8%8D%E7%9B%B8%E5%85%B3%E4%BF%A1%E6%81%AF%EF%BC%9B%EF%BC%882%EF%BC%89%E6%91%98%E8%A6%81%E4%B8%AD%E5%BF%85%E9%A1%BB%E4%BF%9D%E7%95%99%E6%BA%90%E6%96%87%E6%9C%AC%E7%9A%84%E5%85%B3%E9%94%AE%E4%BF%A1%E6%81%AF%EF%BC%88%E5%A6%82%E5%93%81%E7%89%8C%E5%90%8D%E5%92%8C%E5%95%86%E5%93%81%E5%90%8D%EF%BC%89%E3%80%82%E4%BD%9C%E8%80%85%E6%8F%90%E5%87%BA%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%E6%98%AF%20Multi-Source%20Pointer%20Network%E3%80%82%E5%AF%B9%E4%BA%8E%E7%AC%AC%E4%B8%80%E7%82%B9%E9%99%90%E5%88%B6%EF%BC%8C%E4%BD%9C%E8%80%85%E4%BD%BF%E7%94%A8%20Pointer%20Networks%20%E6%9D%A5%E7%9B%B4%E6%8E%A5%E4%BB%8E%E6%BA%90%E6%A0%87%E9%A2%98%E4%B8%AD%E6%8F%90%E5%8F%96%E8%AF%8D%E6%B1%87%EF%BC%8C%E4%BF%9D%E8%AF%81%E4%B8%8D%E4%BC%9A%E5%BC%95%E5%85%A5%E4%B8%8D%E7%9B%B8%E5%85%B3%E4%BF%A1%E6%81%AF%EF%BC%8C%E9%92%88%E5%AF%B9%E7%AC%AC%E4%BA%8C%E7%82%B9%EF%BC%8C%E4%BD%9C%E8%80%85%E6%8F%90%E5%87%BA%E4%BA%86%20knowledge%20encoder%20%E6%8A%80%E6%9C%AF%E6%9D%A5%E6%BB%A1%E8%B6%B3%E8%A6%81%E6%B1%82%E3%80%82))
  - 📝 - 商品标题摘要的两个问题：不引入不相关信息、保留关键信息；
  - 📝 - 阿里的做法是：多元指针网络，直接复制，避免引入不相关信心；外部知识

