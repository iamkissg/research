title:: 【Reading Highlights】精排模型 - 从 MLP 到行为序列：DIN、DIEN、MIMN、SIM、DSIN
source:: https://zhuanlan.zhihu.com/p/493252610
summary:: 
tags:: [[简悦]] [[阿里技术]]  [[推荐系统]]  [[精排]]   [[reading_highlights]]
date:: 20220524  

- > 传统的深度模型（如 GwEN），一般采用 Embedding&MLP 的形式，它会将用户的所有兴趣信息转化为一个定长的向量。但用户的兴趣是多样的，定长的向量可能不足以表达。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%A6%82%20GwEN%EF%BC%89%EF%BC%8C%E4%B8%80%E8%88%AC%E9%87%87%E7%94%A8%20Embedding&MLP%20%E7%9A%84%E5%BD%A2%E5%BC%8F%EF%BC%8C%E5%AE%83%E4%BC%9A%E5%B0%86%E7%94%A8%E6%88%B7%E7%9A%84%E6%89%80%E6%9C%89%E5%85%B4%E8%B6%A3%E4%BF%A1%E6%81%AF%E8%BD%AC%E5%8C%96%E4%B8%BA%E4%B8%80%E4%B8%AA%E5%AE%9A%E9%95%BF%E7%9A%84%E5%90%91%E9%87%8F%E3%80%82%E4%BD%86%E7%94%A8%E6%88%B7%E7%9A%84%E5%85%B4%E8%B6%A3%E6%98%AF%E5%A4%9A%E6%A0%B7%E7%9A%84%EF%BC%8C%E5%AE%9A%E9%95%BF%E7%9A%84%E5%90%91%E9%87%8F%E5%8F%AF%E8%83%BD%E4%B8%8D%E8%B6%B3%E4%BB%A5%E8%A1%A8%E8%BE%BE%E3%80%82))
  - 📝 最终，用户兴趣会被压缩为一个定长的向量。像 [[DIN]]、[[BST]] 这样的模型只是延迟了这一步骤，在这之前，尽可能地挖掘潜藏在用户行为序列中的信息。

- > ![](https://pic1.zhimg.com/v2-525d688e6fe7e1dc35782a3b6235af58_r.jpg)  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=https://pic1.zhimg.com/v2-525d688e6fe7e1dc35782a3b6235af58_r.jpg))
  - 📝 阿里巴巴模型的演变

- > ![](https://pic2.zhimg.com/v2-f2abe8a550415f8d069c89f7b4ee337d_r.jpg) [[模型结构]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=https://pic2.zhimg.com/v2-f2abe8a550415f8d069c89f7b4ee337d_r.jpg))
  - 📝 [[DIN]] 与 基线的对比

- > 这种行为兴趣的建模方式，在实际应用时会遇到一些问题

1、行为数据的参数量巨大（商品 ID 可能就百 / 千万），模型容易过拟合；引入 L2 正则，参数量大训练缓慢

2、针对不同的候选节点，用户的兴趣 embedding 不同，波动大会影响 MLP 部分的模型收敛

解决方案

1、提出 Mini-batch Aware Regularization。L2 正则缓慢的原因是每个 mini-batch 会对模型的所有参数做正则，但其实每个 minibatch 只使用了部分的商品 ID。因此更好的做法是，每个 mini-batch 只对使用到的商品 ID 计算 L2 正则。实验证明，通过这种方式，能有效缓解过拟合现象，同时确保训练效率

2、作者针对 MLP 部分的激活函数（PReLU）做优化，提出更具泛化性的 Dice，这种激活函数可以根据输入数据的均值和方差，动态调整函数形态。在后续的论文中，模型也延用了这种激活函数  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=%E8%BF%99%E7%A7%8D%E8%A1%8C%E4%B8%BA%E5%85%B4%E8%B6%A3%E7%9A%84%E5%BB%BA%E6%A8%A1%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%9C%A8%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E6%97%B6%E4%BC%9A%E9%81%87%E5%88%B0%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%981%E3%80%81%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8F%82%E6%95%B0%E9%87%8F%E5%B7%A8%E5%A4%A7%EF%BC%88%E5%95%86%E5%93%81%20ID%20%E5%8F%AF%E8%83%BD%E5%B0%B1%E7%99%BE%20/%20%E5%8D%83%E4%B8%87%EF%BC%89%EF%BC%8C%E6%A8%A1%E5%9E%8B%E5%AE%B9%E6%98%93%E8%BF%87%E6%8B%9F%E5%90%88%EF%BC%9B%E5%BC%95%E5%85%A5%20L2%20%E6%AD%A3%E5%88%99%EF%BC%8C%E5%8F%82%E6%95%B0%E9%87%8F%E5%A4%A7%E8%AE%AD%E7%BB%83%E7%BC%93%E6%85%A22%E3%80%81%E9%92%88%E5%AF%B9%E4%B8%8D%E5%90%8C%E7%9A%84%E5%80%99%E9%80%89%E8%8A%82%E7%82%B9%EF%BC%8C%E7%94%A8%E6%88%B7%E7%9A%84%E5%85%B4%E8%B6%A3%20embedding%20%E4%B8%8D%E5%90%8C%EF%BC%8C%E6%B3%A2%E5%8A%A8%E5%A4%A7%E4%BC%9A%E5%BD%B1%E5%93%8D%20MLP%20%E9%83%A8%E5%88%86%E7%9A%84%E6%A8%A1%E5%9E%8B%E6%94%B6%E6%95%9B%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%881%E3%80%81%E6%8F%90%E5%87%BA%20Mini-batch%20Aware%20Regularization%E3%80%82L2%20%E6%AD%A3%E5%88%99%E7%BC%93%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0%E6%98%AF%E6%AF%8F%E4%B8%AA%20mini-batch%20%E4%BC%9A%E5%AF%B9%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%89%80%E6%9C%89%E5%8F%82%E6%95%B0%E5%81%9A%E6%AD%A3%E5%88%99%EF%BC%8C%E4%BD%86%E5%85%B6%E5%AE%9E%E6%AF%8F%E4%B8%AA%20minibatch%20%E5%8F%AA%E4%BD%BF%E7%94%A8%E4%BA%86%E9%83%A8%E5%88%86%E7%9A%84%E5%95%86%E5%93%81%20ID%E3%80%82%E5%9B%A0%E6%AD%A4%E6%9B%B4%E5%A5%BD%E7%9A%84%E5%81%9A%E6%B3%95%E6%98%AF%EF%BC%8C%E6%AF%8F%E4%B8%AA%20mini-batch%20%E5%8F%AA%E5%AF%B9%E4%BD%BF%E7%94%A8%E5%88%B0%E7%9A%84%E5%95%86%E5%93%81%20ID%20%E8%AE%A1%E7%AE%97%20L2%20%E6%AD%A3%E5%88%99%E3%80%82%E5%AE%9E%E9%AA%8C%E8%AF%81%E6%98%8E%EF%BC%8C%E9%80%9A%E8%BF%87%E8%BF%99%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%8C%E8%83%BD%E6%9C%89%E6%95%88%E7%BC%93%E8%A7%A3%E8%BF%87%E6%8B%9F%E5%90%88%E7%8E%B0%E8%B1%A1%EF%BC%8C%E5%90%8C%E6%97%B6%E7%A1%AE%E4%BF%9D%E8%AE%AD%E7%BB%83%E6%95%88%E7%8E%872%E3%80%81%E4%BD%9C%E8%80%85%E9%92%88%E5%AF%B9%20MLP%20%E9%83%A8%E5%88%86%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%88PReLU%EF%BC%89%E5%81%9A%E4%BC%98%E5%8C%96%EF%BC%8C%E6%8F%90%E5%87%BA%E6%9B%B4%E5%85%B7%E6%B3%9B%E5%8C%96%E6%80%A7%E7%9A%84%20Dice%EF%BC%8C%E8%BF%99%E7%A7%8D%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%8F%AF%E4%BB%A5%E6%A0%B9%E6%8D%AE%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE%EF%BC%8C%E5%8A%A8%E6%80%81%E8%B0%83%E6%95%B4%E5%87%BD%E6%95%B0%E5%BD%A2%E6%80%81%E3%80%82%E5%9C%A8%E5%90%8E%E7%BB%AD%E7%9A%84%E8%AE%BA%E6%96%87%E4%B8%AD%EF%BC%8C%E6%A8%A1%E5%9E%8B%E4%B9%9F%E5%BB%B6%E7%94%A8%E4%BA%86%E8%BF%99%E7%A7%8D%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0))
  - 📝 [[DIN]] 的问题及解决办法

- > 1、引入 GRU 提取行为序列信息，但模型结构复杂，上线时除了做 GPU-CPU 的计算优化，作者还提到模型压缩，互殴去相对轻量级的模型上线

2、吃不下过长的行为序列，LSTM/GRU 一般能承受的行为序列长度为 30-50；实验中采用 49 天数据，每个样本行为序列为 14 天（序列长度 150 截断）  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=1%E3%80%81%E5%BC%95%E5%85%A5%20GRU%20%E6%8F%90%E5%8F%96%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E4%BF%A1%E6%81%AF%EF%BC%8C%E4%BD%86%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E5%A4%8D%E6%9D%82%EF%BC%8C%E4%B8%8A%E7%BA%BF%E6%97%B6%E9%99%A4%E4%BA%86%E5%81%9A%20GPU-CPU%20%E7%9A%84%E8%AE%A1%E7%AE%97%E4%BC%98%E5%8C%96%EF%BC%8C%E4%BD%9C%E8%80%85%E8%BF%98%E6%8F%90%E5%88%B0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%EF%BC%8C%E4%BA%92%E6%AE%B4%E5%8E%BB%E7%9B%B8%E5%AF%B9%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%B8%8A%E7%BA%BF2%E3%80%81%E5%90%83%E4%B8%8D%E4%B8%8B%E8%BF%87%E9%95%BF%E7%9A%84%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%EF%BC%8CLSTM/GRU%20%E4%B8%80%E8%88%AC%E8%83%BD%E6%89%BF%E5%8F%97%E7%9A%84%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E9%95%BF%E5%BA%A6%E4%B8%BA%2030-50%EF%BC%9B%E5%AE%9E%E9%AA%8C%E4%B8%AD%E9%87%87%E7%94%A8%2049%20%E5%A4%A9%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%AF%8F%E4%B8%AA%E6%A0%B7%E6%9C%AC%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E4%B8%BA%2014%20%E5%A4%A9%EF%BC%88%E5%BA%8F%E5%88%97%E9%95%BF%E5%BA%A6%20150%20%E6%88%AA%E6%96%AD%EF%BC%89))
  - 📝 [[DIEN]] 的缺点。
  - 📝 我个人的感觉是，推荐系统的性能要求直接就限制了基于 [[RNN]] 的模型的使用：时间步的串行执行使得计算效率低下+不得不的序列长度截断限制

- > 长的行为序列会带来两个问题

1、存储限制：天猫广告业务上，6 亿用户，14 天行为序列（最大长度 150），消耗 1TB 的存储，如果序列长度放开到 1000，预计消耗 6TB（估计也用不到，毕竟大序列的可能都属于长尾）

2、时延限制：精排一般是 10ms，DIEN 上线已经达到 14ms，如果继续拉大序列长度，预计时延会达到 30ms  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=%E9%95%BF%E7%9A%84%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E4%BC%9A%E5%B8%A6%E6%9D%A5%E4%B8%A4%E4%B8%AA%E9%97%AE%E9%A2%981%E3%80%81%E5%AD%98%E5%82%A8%E9%99%90%E5%88%B6%EF%BC%9A%E5%A4%A9%E7%8C%AB%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E4%B8%8A%EF%BC%8C6%20%E4%BA%BF%E7%94%A8%E6%88%B7%EF%BC%8C14%20%E5%A4%A9%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%EF%BC%88%E6%9C%80%E5%A4%A7%E9%95%BF%E5%BA%A6%20150%EF%BC%89%EF%BC%8C%E6%B6%88%E8%80%97%201TB%20%E7%9A%84%E5%AD%98%E5%82%A8%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%BA%8F%E5%88%97%E9%95%BF%E5%BA%A6%E6%94%BE%E5%BC%80%E5%88%B0%201000%EF%BC%8C%E9%A2%84%E8%AE%A1%E6%B6%88%E8%80%97%206TB%EF%BC%88%E4%BC%B0%E8%AE%A1%E4%B9%9F%E7%94%A8%E4%B8%8D%E5%88%B0%EF%BC%8C%E6%AF%95%E7%AB%9F%E5%A4%A7%E5%BA%8F%E5%88%97%E7%9A%84%E5%8F%AF%E8%83%BD%E9%83%BD%E5%B1%9E%E4%BA%8E%E9%95%BF%E5%B0%BE%EF%BC%892%E3%80%81%E6%97%B6%E5%BB%B6%E9%99%90%E5%88%B6%EF%BC%9A%E7%B2%BE%E6%8E%92%E4%B8%80%E8%88%AC%E6%98%AF%2010ms%EF%BC%8CDIEN%20%E4%B8%8A%E7%BA%BF%E5%B7%B2%E7%BB%8F%E8%BE%BE%E5%88%B0%2014ms%EF%BC%8C%E5%A6%82%E6%9E%9C%E7%BB%A7%E7%BB%AD%E6%8B%89%E5%A4%A7%E5%BA%8F%E5%88%97%E9%95%BF%E5%BA%A6%EF%BC%8C%E9%A2%84%E8%AE%A1%E6%97%B6%E5%BB%B6%E4%BC%9A%E8%BE%BE%E5%88%B0%2030ms))
  - 📝 长度列带来的问题：
  - 📝 1. 存储问题，这是离线训练数据存储的问题
  - 📝 2. 时延限制，这对离线训练和线上预估都提出了更高的挑战，由于是线上性能问题

- > 维护一个离线的用户兴趣中心，存储当前时刻的兴趣 embedding 结果（存储序列消耗资源大，存不下），每次有新的用户行为进来时更新 embedding。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=%E7%BB%B4%E6%8A%A4%E4%B8%80%E4%B8%AA%E7%A6%BB%E7%BA%BF%E7%9A%84%E7%94%A8%E6%88%B7%E5%85%B4%E8%B6%A3%E4%B8%AD%E5%BF%83%EF%BC%8C%E5%AD%98%E5%82%A8%E5%BD%93%E5%89%8D%E6%97%B6%E5%88%BB%E7%9A%84%E5%85%B4%E8%B6%A3%20embedding%20%E7%BB%93%E6%9E%9C%EF%BC%88%E5%AD%98%E5%82%A8%E5%BA%8F%E5%88%97%E6%B6%88%E8%80%97%E8%B5%84%E6%BA%90%E5%A4%A7%EF%BC%8C%E5%AD%98%E4%B8%8D%E4%B8%8B%EF%BC%89%EF%BC%8C%E6%AF%8F%E6%AC%A1%E6%9C%89%E6%96%B0%E7%9A%84%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E8%BF%9B%E6%9D%A5%E6%97%B6%E6%9B%B4%E6%96%B0%20embedding%E3%80%82))
  - 📝 就像[[双塔模型]]提前维护好一座塔，它的问题是：又回到了文章开头抛出的定长向量的问题。

- > ![](https://pic3.zhimg.com/v2-e4037c9ab028710095512a4623981a4e_r.jpg) [[模型结构]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=https://pic3.zhimg.com/v2-e4037c9ab028710095512a4623981a4e_r.jpg))
  - 📝 [[MIMN]] 使用 UIC 来维护用户行为序列的向量查询
  - 📝 看图的话，就是[[双塔模型]]变[[三塔模型]]，用户行为序列在用户画像之外单独建塔，实时更新用户行为序列的表征。

- > ![](https://pic1.zhimg.com/v2-e08572db98d780098682b30b32e67840_r.jpg) [[模型结构]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=https://pic1.zhimg.com/v2-e08572db98d780098682b30b32e67840_r.jpg))
  - 📝 [[MIMN]] 的模型结构图

- > 1、时延：提出计算分离的模式，使得模型处理长序列（序列长度为 1000）都不存在时延的压力，如下图

2、存储：提出 NTM 的结构，存储系统只需要为每个用户维护存储矩阵 Mt 和序列矩阵 S，不需要单独保存行为序列，存储量从 6T 转为 2.7T

3、效果：计算分离后，兴趣的提取无法很好的和候选 AD / 商品交互（仅通过存储矩阵实现交互），可能会对效果有损

4、同步：时序模块的结果和 ctr 模型是异步更新的，行为序列频繁更新可能导致模型效果波动，需要有一定的回滚机制

5、适用性：**当用户行为丰富且行为更新频率没有远高于请求时，可以使用该模型。这是因为该模型时针对长序列行为建模的，行为数据不丰富当然不必使用。而如果用户行为更新频繁，ctr 模型都来不及更新，可能会使预测结果产生波动**

6、其他：**作者提到双 11 时虽然行为数据丰富，但用户行为特殊，提取出来做特征效果反而下降**  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=1%E3%80%81%E6%97%B6%E5%BB%B6%EF%BC%9A%E6%8F%90%E5%87%BA%E8%AE%A1%E7%AE%97%E5%88%86%E7%A6%BB%E7%9A%84%E6%A8%A1%E5%BC%8F%EF%BC%8C%E4%BD%BF%E5%BE%97%E6%A8%A1%E5%9E%8B%E5%A4%84%E7%90%86%E9%95%BF%E5%BA%8F%E5%88%97%EF%BC%88%E5%BA%8F%E5%88%97%E9%95%BF%E5%BA%A6%E4%B8%BA%201000%EF%BC%89%E9%83%BD%E4%B8%8D%E5%AD%98%E5%9C%A8%E6%97%B6%E5%BB%B6%E7%9A%84%E5%8E%8B%E5%8A%9B%EF%BC%8C%E5%A6%82%E4%B8%8B%E5%9B%BE2%E3%80%81%E5%AD%98%E5%82%A8%EF%BC%9A%E6%8F%90%E5%87%BA%20NTM%20%E7%9A%84%E7%BB%93%E6%9E%84%EF%BC%8C%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E5%8F%AA%E9%9C%80%E8%A6%81%E4%B8%BA%E6%AF%8F%E4%B8%AA%E7%94%A8%E6%88%B7%E7%BB%B4%E6%8A%A4%E5%AD%98%E5%82%A8%E7%9F%A9%E9%98%B5%20Mt%20%E5%92%8C%E5%BA%8F%E5%88%97%E7%9F%A9%E9%98%B5%20S%EF%BC%8C%E4%B8%8D%E9%9C%80%E8%A6%81%E5%8D%95%E7%8B%AC%E4%BF%9D%E5%AD%98%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%EF%BC%8C%E5%AD%98%E5%82%A8%E9%87%8F%E4%BB%8E%206T%20%E8%BD%AC%E4%B8%BA%202.7T3%E3%80%81%E6%95%88%E6%9E%9C%EF%BC%9A%E8%AE%A1%E7%AE%97%E5%88%86%E7%A6%BB%E5%90%8E%EF%BC%8C%E5%85%B4%E8%B6%A3%E7%9A%84%E6%8F%90%E5%8F%96%E6%97%A0%E6%B3%95%E5%BE%88%E5%A5%BD%E7%9A%84%E5%92%8C%E5%80%99%E9%80%89%20AD%20/%20%E5%95%86%E5%93%81%E4%BA%A4%E4%BA%92%EF%BC%88%E4%BB%85%E9%80%9A%E8%BF%87%E5%AD%98%E5%82%A8%E7%9F%A9%E9%98%B5%E5%AE%9E%E7%8E%B0%E4%BA%A4%E4%BA%92%EF%BC%89%EF%BC%8C%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%AF%B9%E6%95%88%E6%9E%9C%E6%9C%89%E6%8D%9F4%E3%80%81%E5%90%8C%E6%AD%A5%EF%BC%9A%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9D%97%E7%9A%84%E7%BB%93%E6%9E%9C%E5%92%8C%20ctr%20%E6%A8%A1%E5%9E%8B%E6%98%AF%E5%BC%82%E6%AD%A5%E6%9B%B4%E6%96%B0%E7%9A%84%EF%BC%8C%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E9%A2%91%E7%B9%81%E6%9B%B4%E6%96%B0%E5%8F%AF%E8%83%BD%E5%AF%BC%E8%87%B4%E6%A8%A1%E5%9E%8B%E6%95%88%E6%9E%9C%E6%B3%A2%E5%8A%A8%EF%BC%8C%E9%9C%80%E8%A6%81%E6%9C%89%E4%B8%80%E5%AE%9A%E7%9A%84%E5%9B%9E%E6%BB%9A%E6%9C%BA%E5%88%B6%E5%BD%93%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E4%B8%B0%E5%AF%8C%E4%B8%94%E8%A1%8C%E4%B8%BA%E6%9B%B4%E6%96%B0%E9%A2%91%E7%8E%87%E6%B2%A1%E6%9C%89%E8%BF%9C%E9%AB%98%E4%BA%8E%E8%AF%B7%E6%B1%82%E6%97%B6%EF%BC%8C%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E8%AF%A5%E6%A8%A1%E5%9E%8B%E3%80%82%E8%BF%99%E6%98%AF%E5%9B%A0%E4%B8%BA%E8%AF%A5%E6%A8%A1%E5%9E%8B%E6%97%B6%E9%92%88%E5%AF%B9%E9%95%BF%E5%BA%8F%E5%88%97%E8%A1%8C%E4%B8%BA%E5%BB%BA%E6%A8%A1%E7%9A%84%EF%BC%8C%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%B0%E5%AF%8C%E5%BD%93%E7%84%B6%E4%B8%8D%E5%BF%85%E4%BD%BF%E7%94%A8%E3%80%82%E8%80%8C%E5%A6%82%E6%9E%9C%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%9B%B4%E6%96%B0%E9%A2%91%E7%B9%81%EF%BC%8Cctr%20%E6%A8%A1%E5%9E%8B%E9%83%BD%E6%9D%A5%E4%B8%8D%E5%8F%8A%E6%9B%B4%E6%96%B0%EF%BC%8C%E5%8F%AF%E8%83%BD%E4%BC%9A%E4%BD%BF%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E4%BA%A7%E7%94%9F%E6%B3%A2%E5%8A%A85%E3%80%81%E9%80%82%E7%94%A8%E6%80%A7%EF%BC%9A%E4%BD%9C%E8%80%85%E6%8F%90%E5%88%B0%E5%8F%8C%2011%20%E6%97%B6%E8%99%BD%E7%84%B6%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%B8%B0%E5%AF%8C%EF%BC%8C%E4%BD%86%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E7%89%B9%E6%AE%8A%EF%BC%8C%E6%8F%90%E5%8F%96%E5%87%BA%E6%9D%A5%E5%81%9A%E7%89%B9%E5%BE%81%E6%95%88%E6%9E%9C%E5%8F%8D%E8%80%8C%E4%B8%8B%E9%99%8D6%E3%80%81%E5%85%B6%E4%BB%96%EF%BC%9A))
  - 📝 [[MIMN]] 的优缺点。
  - 📝 成也提前存储特征矩阵，败也提前存储特征矩阵。

- > ![](https://pic1.zhimg.com/v2-bb14915dc36a7b175b4c4be7d8f9900c_r.jpg) [[模型结构]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=https://pic1.zhimg.com/v2-bb14915dc36a7b175b4c4be7d8f9900c_r.jpg))
  - 📝 [[SIM]] 的示意图

- > 短期的默认全取，论文的工业数据集中短期指 14 天内的行为  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=%E7%9F%AD%E6%9C%9F%E7%9A%84%E9%BB%98%E8%AE%A4%E5%85%A8%E5%8F%96%EF%BC%8C%E8%AE%BA%E6%96%87%E7%9A%84%E5%B7%A5%E4%B8%9A%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E7%9F%AD%E6%9C%9F%E6%8C%87%2014%20%E5%A4%A9%E5%86%85%E7%9A%84%E8%A1%8C%E4%B8%BA))
  - 📝 阿里将 14 天作为中短期和长期用户行为序列的分界点。

- > 1、Hard Search：核心思想是只提取和候选商品相同类目的行为信息。具体的，在线维护一个 “用户 ID - 商品类目 ID - 行为商品 ID” 的双层索引数据。请求到来时，直接检索对应类目的行为商品序列  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=1%E3%80%81Hard%20Search%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%E6%98%AF%E5%8F%AA%E6%8F%90%E5%8F%96%E5%92%8C%E5%80%99%E9%80%89%E5%95%86%E5%93%81%E7%9B%B8%E5%90%8C%E7%B1%BB%E7%9B%AE%E7%9A%84%E8%A1%8C%E4%B8%BA%E4%BF%A1%E6%81%AF%E3%80%82%E5%85%B7%E4%BD%93%E7%9A%84%EF%BC%8C%E5%9C%A8%E7%BA%BF%E7%BB%B4%E6%8A%A4%E4%B8%80%E4%B8%AA%20%E2%80%9C%E7%94%A8%E6%88%B7%20ID%20-%20%E5%95%86%E5%93%81%E7%B1%BB%E7%9B%AE%20ID%20-%20%E8%A1%8C%E4%B8%BA%E5%95%86%E5%93%81%20ID%E2%80%9D%20%E7%9A%84%E5%8F%8C%E5%B1%82%E7%B4%A2%E5%BC%95%E6%95%B0%E6%8D%AE%E3%80%82%E8%AF%B7%E6%B1%82%E5%88%B0%E6%9D%A5%E6%97%B6%EF%BC%8C%E7%9B%B4%E6%8E%A5%E6%A3%80%E7%B4%A2%E5%AF%B9%E5%BA%94%E7%B1%BB%E7%9B%AE%E7%9A%84%E8%A1%8C%E4%B8%BA%E5%95%86%E5%93%81%E5%BA%8F%E5%88%97))
  - 📝 相同的思想还用在了 [[BST]]的 hard sequence modeling (HSM)

- > ![](https://pic1.zhimg.com/v2-22938c30f539e56b5d81dd269367a314_r.jpg) [[模型结构]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=https://pic1.zhimg.com/v2-22938c30f539e56b5d81dd269367a314_r.jpg))
  - 📝 [[SIM]] 的 ctr 预估系统示意图

- > 2、时延方面，SIM 因为要处理 1w + 的序列信息，性能比 MIMN 要弱一些，但 18ms 的时延也基本满足实时性的要求

3、SIM 号称能够处理的序列长度是 54000，对于阿里广告业务而言，相当于 180 天的广告行为，已基本覆盖用户长期兴趣建模所需的时间长度  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=2%E3%80%81%E6%97%B6%E5%BB%B6%E6%96%B9%E9%9D%A2%EF%BC%8CSIM%20%E5%9B%A0%E4%B8%BA%E8%A6%81%E5%A4%84%E7%90%86%201w%20+%20%E7%9A%84%E5%BA%8F%E5%88%97%E4%BF%A1%E6%81%AF%EF%BC%8C%E6%80%A7%E8%83%BD%E6%AF%94%20MIMN%20%E8%A6%81%E5%BC%B1%E4%B8%80%E4%BA%9B%EF%BC%8C%E4%BD%86%2018ms%20%E7%9A%84%E6%97%B6%E5%BB%B6%E4%B9%9F%E5%9F%BA%E6%9C%AC%E6%BB%A1%E8%B6%B3%E5%AE%9E%E6%97%B6%E6%80%A7%E7%9A%84%E8%A6%81%E6%B1%823%E3%80%81SIM%20%E5%8F%B7%E7%A7%B0%E8%83%BD%E5%A4%9F%E5%A4%84%E7%90%86%E7%9A%84%E5%BA%8F%E5%88%97%E9%95%BF%E5%BA%A6%E6%98%AF%2054000%EF%BC%8C%E5%AF%B9%E4%BA%8E%E9%98%BF%E9%87%8C%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E8%80%8C%E8%A8%80%EF%BC%8C%E7%9B%B8%E5%BD%93%E4%BA%8E%20180%20%E5%A4%A9%E7%9A%84%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%BA%EF%BC%8C%E5%B7%B2%E5%9F%BA%E6%9C%AC%E8%A6%86%E7%9B%96%E7%94%A8%E6%88%B7%E9%95%BF%E6%9C%9F%E5%85%B4%E8%B6%A3%E5%BB%BA%E6%A8%A1%E6%89%80%E9%9C%80%E7%9A%84%E6%97%B6%E9%97%B4%E9%95%BF%E5%BA%A6))
  - 📝 太强了！
  - 📝 滚动存储的单用户 54000，这个存储量太大了！

- > 作者将行为间隔不超过 30min 的部分归纳为一个 session，发现，同一个 session 内，用户点击的商品具有明显的指向性，而不同 session 间，用户的点击行为有明显差异  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=%E4%BD%9C%E8%80%85%E5%B0%86%E8%A1%8C%E4%B8%BA%E9%97%B4%E9%9A%94%E4%B8%8D%E8%B6%85%E8%BF%87%2030min%20%E7%9A%84%E9%83%A8%E5%88%86%E5%BD%92%E7%BA%B3%E4%B8%BA%E4%B8%80%E4%B8%AA%20session%EF%BC%8C%E5%8F%91%E7%8E%B0%EF%BC%8C%E5%90%8C%E4%B8%80%E4%B8%AA%20session%20%E5%86%85%EF%BC%8C%E7%94%A8%E6%88%B7%E7%82%B9%E5%87%BB%E7%9A%84%E5%95%86%E5%93%81%E5%85%B7%E6%9C%89%E6%98%8E%E6%98%BE%E7%9A%84%E6%8C%87%E5%90%91%E6%80%A7%EF%BC%8C%E8%80%8C%E4%B8%8D%E5%90%8C%20session%20%E9%97%B4%EF%BC%8C%E7%94%A8%E6%88%B7%E7%9A%84%E7%82%B9%E5%87%BB%E8%A1%8C%E4%B8%BA%E6%9C%89%E6%98%8E%E6%98%BE%E5%B7%AE%E5%BC%82))
  - 📝 [[DSIN]] 将 30min 设定为一个 session
  - 📝 相当于用户行为序列分成了两层：基于 session 的一层，session 内又是一层

- > ![](https://pic1.zhimg.com/v2-0fadd6993edcba86d59a82641d86ea3c_r.jpg) [[模型结构]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=https://pic1.zhimg.com/v2-0fadd6993edcba86d59a82641d86ea3c_r.jpg))
  - 📝 [[DSIN]] 的示意图

- > 该部分作者使用 transformer 的结果，首先引入了 bias-encoding（会对每个 session，每个行为节点的位置，每个 embedding-bit 位构建全局共享的 embedding），即

![](https://www.zhihu.com/equation?tex=BE_%7B%28k%2Ct%2Cc%29%7D%3Dw_%7Bk%7D%5E%7BK%7D%2Bw_%7Bt%7D%5E%7BT%7D%2Bw_%7Bc%7D%5E%7BC%7D)

其中，K 是 session 的个数，T 是每个 session 内行为节点的个数，C 是每个行为节点的 embedding 大小

则 transformer 的输入为行为序列与 bias-encoding 的相加结果，即

![](https://www.zhihu.com/equation?tex=Q+%3D+Q+%2B+BE)  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/493252610#js_content:~:text=%E8%AF%A5%E9%83%A8%E5%88%86%E4%BD%9C%E8%80%85%E4%BD%BF%E7%94%A8%20transformer%20%E7%9A%84%E7%BB%93%E6%9E%9C%EF%BC%8C%E9%A6%96%E5%85%88%E5%BC%95%E5%85%A5%E4%BA%86%20bias-encoding%EF%BC%88%E4%BC%9A%E5%AF%B9%E6%AF%8F%E4%B8%AA%20session%EF%BC%8C%E6%AF%8F%E4%B8%AA%E8%A1%8C%E4%B8%BA%E8%8A%82%E7%82%B9%E7%9A%84%E4%BD%8D%E7%BD%AE%EF%BC%8C%E6%AF%8F%E4%B8%AA%20embedding-bit%20%E4%BD%8D%E6%9E%84%E5%BB%BA%E5%85%A8%E5%B1%80%E5%85%B1%E4%BA%AB%E7%9A%84%20embedding%EF%BC%89%EF%BC%8C%E5%8D%B3%E5%85%B6%E4%B8%AD%EF%BC%8CK%20%E6%98%AF%20session%20%E7%9A%84%E4%B8%AA%E6%95%B0%EF%BC%8CT%20%E6%98%AF%E6%AF%8F%E4%B8%AA%20session%20%E5%86%85%E8%A1%8C%E4%B8%BA%E8%8A%82%E7%82%B9%E7%9A%84%E4%B8%AA%E6%95%B0%EF%BC%8CC%20%E6%98%AF%E6%AF%8F%E4%B8%AA%E8%A1%8C%E4%B8%BA%E8%8A%82%E7%82%B9%E7%9A%84%20embedding%20%E5%A4%A7%E5%B0%8F%E5%88%99%20transformer%20%E7%9A%84%E8%BE%93%E5%85%A5%E4%B8%BA%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E4%B8%8E%20bias-encoding%20%E7%9A%84%E7%9B%B8%E5%8A%A0%E7%BB%93%E6%9E%9C%EF%BC%8C%E5%8D%B3%20))
  - 📝 看不懂本文作者的描述，看论文之前，猜测是类似 BERT 的，将不同 session 作为不同的 segment，赋不同的 session embedding。

