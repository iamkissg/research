title:: 【Reading Highlights】美团 “猜你喜欢” 深度学习排序模型实践
source:: https://zhuanlan.zhihu.com/p/35090791
summary:: 
tags:: [[简悦]] [[美团技术]]  [[推荐系统]]   [[reading_highlights]]
date:: 20220609  

- > 为处理大规模的训练样本和提高训练效率，我们基于 PS-Lite 研发了分布式训练的 DNN 模型，并基于该框架进行了很多的优化尝试，在排序场景下取得了显著的效果提升。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E4%B8%BA%E5%A4%84%E7%90%86%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%9A%84%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E5%92%8C%E6%8F%90%E9%AB%98%E8%AE%AD%E7%BB%83%E6%95%88%E7%8E%87%EF%BC%8C%E6%88%91%E4%BB%AC%E5%9F%BA%E4%BA%8E%20PS-Lite%20%E7%A0%94%E5%8F%91%E4%BA%86%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E7%9A%84%20DNN%20%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%B9%B6%E5%9F%BA%E4%BA%8E%E8%AF%A5%E6%A1%86%E6%9E%B6%E8%BF%9B%E8%A1%8C%E4%BA%86%E5%BE%88%E5%A4%9A%E7%9A%84%E4%BC%98%E5%8C%96%E5%B0%9D%E8%AF%95%EF%BC%8C%E5%9C%A8%E6%8E%92%E5%BA%8F%E5%9C%BA%E6%99%AF%E4%B8%8B%E5%8F%96%E5%BE%97%E4%BA%86%E6%98%BE%E8%91%97%E7%9A%84%E6%95%88%E6%9E%9C%E6%8F%90%E5%8D%87%E3%80%82))

- > **特征种类**

*   User 特征：用户年龄，性别，婚否，有无孩子等
*   Item 特征：价格，折扣，品类和品牌相关特征，短期和长期统计类特征等
*   Context 特征：天气，时间，地理位置，温度等
*   用户行为：用户点击 Item 序列，下单 Item 序列等  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E7%89%B9%E5%BE%81%E7%A7%8D%E7%B1%BBUser%20%E7%89%B9%E5%BE%81%EF%BC%9A%E7%94%A8%E6%88%B7%E5%B9%B4%E9%BE%84%EF%BC%8C%E6%80%A7%E5%88%AB%EF%BC%8C%E5%A9%9A%E5%90%A6%EF%BC%8C%E6%9C%89%E6%97%A0%E5%AD%A9%E5%AD%90%E7%AD%89Item%20%E7%89%B9%E5%BE%81%EF%BC%9A%E4%BB%B7%E6%A0%BC%EF%BC%8C%E6%8A%98%E6%89%A3%EF%BC%8C%E5%93%81%E7%B1%BB%E5%92%8C%E5%93%81%E7%89%8C%E7%9B%B8%E5%85%B3%E7%89%B9%E5%BE%81%EF%BC%8C%E7%9F%AD%E6%9C%9F%E5%92%8C%E9%95%BF%E6%9C%9F%E7%BB%9F%E8%AE%A1%E7%B1%BB%E7%89%B9%E5%BE%81%E7%AD%89Context%20%E7%89%B9%E5%BE%81%EF%BC%9A%E5%A4%A9%E6%B0%94%EF%BC%8C%E6%97%B6%E9%97%B4%EF%BC%8C%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%EF%BC%8C%E6%B8%A9%E5%BA%A6%E7%AD%89%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%EF%BC%9A%E7%94%A8%E6%88%B7%E7%82%B9%E5%87%BB%20Item%20%E5%BA%8F%E5%88%97%EF%BC%8C%E4%B8%8B%E5%8D%95%20Item%20%E5%BA%8F%E5%88%97%E7%AD%89))

- > ![](https://pic2.zhimg.com/v2-ca2d91808d78762aeb9e5941326719fd_r.jpg)  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=https://pic2.zhimg.com/v2-ca2d91808d78762aeb9e5941326719fd_r.jpg))
  - 📝 连续特征等频归一化（非分桶），离散特征低频过滤

- > 在实践中，我们参考了 Google 的 Wide & Deep Model[6] 中对于连续特征的处理方式，根据特征值在累计分布函数中的位置进行归一化。即将特征进行等频分桶，保证每个桶里的样本量基本相等，假设总共分了 **n** 个桶，而特征 **xi** 属于其中的第 **bi(bi ∈ {0, …, n - 1})** 个桶，则特征 **xi** 最终会归一化成 **bi/n**。这种方法保证对于不同分布的特征都可以映射到近似均匀分布，从而保证样本间特征的区分度和数值的稳定性。 [[特征工程]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E5%9C%A8%E5%AE%9E%E8%B7%B5%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%82%E8%80%83%E4%BA%86%20Google%20%E7%9A%84%20Wide%20&%20Deep%20Model%5B6%5D%20%E4%B8%AD%E5%AF%B9%E4%BA%8E%E8%BF%9E%E7%BB%AD%E7%89%B9%E5%BE%81%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F%EF%BC%8C%E6%A0%B9%E6%8D%AE%E7%89%B9%E5%BE%81%E5%80%BC%E5%9C%A8%E7%B4%AF%E8%AE%A1%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0%E4%B8%AD%E7%9A%84%E4%BD%8D%E7%BD%AE%E8%BF%9B%E8%A1%8C%E5%BD%92%E4%B8%80%E5%8C%96%E3%80%82%E5%8D%B3%E5%B0%86%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8C%E7%AD%89%E9%A2%91%E5%88%86%E6%A1%B6%EF%BC%8C%E4%BF%9D%E8%AF%81%E6%AF%8F%E4%B8%AA%E6%A1%B6%E9%87%8C%E7%9A%84%E6%A0%B7%E6%9C%AC%E9%87%8F%E5%9F%BA%E6%9C%AC%E7%9B%B8%E7%AD%89%EF%BC%8C%E5%81%87%E8%AE%BE%E6%80%BB%E5%85%B1%E5%88%86%E4%BA%86%20n%20%E4%B8%AA%E6%A1%B6%EF%BC%8C%E8%80%8C%E7%89%B9%E5%BE%81%20xi%20bi(bi%20%E2%88%88%20%7B0,%20%E2%80%A6,%20n%20-%201%7D)%20xi%20%E5%B1%9E%E4%BA%8E%E5%85%B6%E4%B8%AD%E7%9A%84%E7%AC%AC%20%E4%B8%AA%E6%A1%B6%EF%BC%8C%E5%88%99%E7%89%B9%E5%BE%81%20%E6%9C%80%E7%BB%88%E4%BC%9A%E5%BD%92%E4%B8%80%E5%8C%96%E6%88%90%20bi/n%E3%80%82%E8%BF%99%E7%A7%8D%E6%96%B9%E6%B3%95%E4%BF%9D%E8%AF%81%E5%AF%B9%E4%BA%8E%E4%B8%8D%E5%90%8C%E5%88%86%E5%B8%83%E7%9A%84%E7%89%B9%E5%BE%81%E9%83%BD%E5%8F%AF%E4%BB%A5%E6%98%A0%E5%B0%84%E5%88%B0%E8%BF%91%E4%BC%BC%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83%EF%BC%8C%E4%BB%8E%E8%80%8C%E4%BF%9D%E8%AF%81%E6%A0%B7%E6%9C%AC%E9%97%B4%E7%89%B9%E5%BE%81%E7%9A%84%E5%8C%BA%E5%88%86%E5%BA%A6%E5%92%8C%E6%95%B0%E5%80%BC%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7%E3%80%82))
  - 📝 连续特征等频归一化

- > 过多的极为稀疏的离散特征会在训练过程中造成过拟合问题，同时增加参数的储存数量。为避免该问题，我们对离散特征进行了低频过滤处理，丢掉小于出现频次阈值的特征。 [[特征工程]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E8%BF%87%E5%A4%9A%E7%9A%84%E6%9E%81%E4%B8%BA%E7%A8%80%E7%96%8F%E7%9A%84%E7%A6%BB%E6%95%A3%E7%89%B9%E5%BE%81%E4%BC%9A%E5%9C%A8%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%80%A0%E6%88%90%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98%EF%BC%8C%E5%90%8C%E6%97%B6%E5%A2%9E%E5%8A%A0%E5%8F%82%E6%95%B0%E7%9A%84%E5%82%A8%E5%AD%98%E6%95%B0%E9%87%8F%E3%80%82%E4%B8%BA%E9%81%BF%E5%85%8D%E8%AF%A5%E9%97%AE%E9%A2%98%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AF%B9%E7%A6%BB%E6%95%A3%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8C%E4%BA%86%E4%BD%8E%E9%A2%91%E8%BF%87%E6%BB%A4%E5%A4%84%E7%90%86%EF%BC%8C%E4%B8%A2%E6%8E%89%E5%B0%8F%E4%BA%8E%E5%87%BA%E7%8E%B0%E9%A2%91%E6%AC%A1%E9%98%88%E5%80%BC%E7%9A%84%E7%89%B9%E5%BE%81%E3%80%82))
  - 📝 离散特征低频过滤。
  - 📝 没有讲清楚是过滤特征值呢，还是特征本身呢。

- > 经过上述特征抽取、标签匹配、特征处理后，我们会给特征分配对应的域，并对离散特征进行 Hash 处理，最终生成 LIBFFM 格式的数据，作为 Multi-task DNN 的训练样本。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E7%BB%8F%E8%BF%87%E4%B8%8A%E8%BF%B0%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96%E3%80%81%E6%A0%87%E7%AD%BE%E5%8C%B9%E9%85%8D%E3%80%81%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86%E5%90%8E%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BC%9A%E7%BB%99%E7%89%B9%E5%BE%81%E5%88%86%E9%85%8D%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9F%9F%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%A6%BB%E6%95%A3%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8C%20Hash%20%E5%A4%84%E7%90%86%EF%BC%8C%E6%9C%80%E7%BB%88%E7%94%9F%E6%88%90%20LIBFFM%20%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%8C%E4%BD%9C%E4%B8%BA%20Multi-task%20DNN%20%E7%9A%84%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E3%80%82))

- > ![](https://pic2.zhimg.com/v2-803455f28ea5a5221217089ff519e929_r.jpg) [[模型结构]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=https://pic2.zhimg.com/v2-803455f28ea5a5221217089ff519e929_r.jpg))

- > NFM 的输出结果为向量形式，很方便和 DNN 的隐层进行融合。而且从调研的过程中发现，NFM 能够加快训练的收敛速度，从而更有利于 Embedding 层的学习。因为 DNN 部分的层数较多，在训练的 BP 阶段，当梯度传到最底层的 Embedding 层时很容易出现梯度消失的问题，但 NFM 与 DNN 相比层数较浅，有利于梯度的传递，从而加快 Embedding 层的学习。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=NFM%20%E7%9A%84%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C%E4%B8%BA%E5%90%91%E9%87%8F%E5%BD%A2%E5%BC%8F%EF%BC%8C%E5%BE%88%E6%96%B9%E4%BE%BF%E5%92%8C%20DNN%20%E7%9A%84%E9%9A%90%E5%B1%82%E8%BF%9B%E8%A1%8C%E8%9E%8D%E5%90%88%E3%80%82%E8%80%8C%E4%B8%94%E4%BB%8E%E8%B0%83%E7%A0%94%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%8F%91%E7%8E%B0%EF%BC%8CNFM%20%E8%83%BD%E5%A4%9F%E5%8A%A0%E5%BF%AB%E8%AE%AD%E7%BB%83%E7%9A%84%E6%94%B6%E6%95%9B%E9%80%9F%E5%BA%A6%EF%BC%8C%E4%BB%8E%E8%80%8C%E6%9B%B4%E6%9C%89%E5%88%A9%E4%BA%8E%20Embedding%20%E5%B1%82%E7%9A%84%E5%AD%A6%E4%B9%A0%E3%80%82%E5%9B%A0%E4%B8%BA%20DNN%20%E9%83%A8%E5%88%86%E7%9A%84%E5%B1%82%E6%95%B0%E8%BE%83%E5%A4%9A%EF%BC%8C%E5%9C%A8%E8%AE%AD%E7%BB%83%E7%9A%84%20BP%20%E9%98%B6%E6%AE%B5%EF%BC%8C%E5%BD%93%E6%A2%AF%E5%BA%A6%E4%BC%A0%E5%88%B0%E6%9C%80%E5%BA%95%E5%B1%82%E7%9A%84%20Embedding%20%E5%B1%82%E6%97%B6%E5%BE%88%E5%AE%B9%E6%98%93%E5%87%BA%E7%8E%B0%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%8C%E4%BD%86%20NFM%20%E4%B8%8E%20DNN%20%E7%9B%B8%E6%AF%94%E5%B1%82%E6%95%B0%E8%BE%83%E6%B5%85%EF%BC%8C%E6%9C%89%E5%88%A9%E4%BA%8E%E6%A2%AF%E5%BA%A6%E7%9A%84%E4%BC%A0%E9%80%92%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%8A%A0%E5%BF%AB%20Embedding%20%E5%B1%82%E7%9A%84%E5%AD%A6%E4%B9%A0%E3%80%82))

- > 最初我们尝试通过随机初始化 Item  
Embedding 向量，并在训练过程中更新其参数的方式进行学习。但由于 Item  
ID 的稀疏性，上述随机初始化的方式很容易出现过拟合。后来采用先生成 item  
Embedding 向量，用该向量进行初始化，并在训练过程中进行 fine tuning 的方式进行训练。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E6%9C%80%E5%88%9D%E6%88%91%E4%BB%AC%E5%B0%9D%E8%AF%95%E9%80%9A%E8%BF%87%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96%20ItemEmbedding%20%E5%90%91%E9%87%8F%EF%BC%8C%E5%B9%B6%E5%9C%A8%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E6%9B%B4%E6%96%B0%E5%85%B6%E5%8F%82%E6%95%B0%E7%9A%84%E6%96%B9%E5%BC%8F%E8%BF%9B%E8%A1%8C%E5%AD%A6%E4%B9%A0%E3%80%82%E4%BD%86%E7%94%B1%E4%BA%8E%20ItemID%20%E7%9A%84%E7%A8%80%E7%96%8F%E6%80%A7%EF%BC%8C%E4%B8%8A%E8%BF%B0%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E6%96%B9%E5%BC%8F%E5%BE%88%E5%AE%B9%E6%98%93%E5%87%BA%E7%8E%B0%E8%BF%87%E6%8B%9F%E5%90%88%E3%80%82%E5%90%8E%E6%9D%A5%E9%87%87%E7%94%A8%E5%85%88%E7%94%9F%E6%88%90%20itemEmbedding%20%E5%90%91%E9%87%8F%EF%BC%8C%E7%94%A8%E8%AF%A5%E5%90%91%E9%87%8F%E8%BF%9B%E8%A1%8C%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%8C%E5%B9%B6%E5%9C%A8%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E8%BF%9B%E8%A1%8C%20fine%20tuning%20%E7%9A%84%E6%96%B9%E5%BC%8F%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E3%80%82))

- > 为生成用户兴趣向量，我们对用户行为序列中的 Item 向量进行了包括 Average  
Pooling、 Max Pooling 与 Weighted Pooling 三种方式的融合。其中 Weighted  
Pooling 参考了 DIN 的实现  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E4%B8%BA%E7%94%9F%E6%88%90%E7%94%A8%E6%88%B7%E5%85%B4%E8%B6%A3%E5%90%91%E9%87%8F%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AF%B9%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E4%B8%AD%E7%9A%84%20Item%20%E5%90%91%E9%87%8F%E8%BF%9B%E8%A1%8C%E4%BA%86%E5%8C%85%E6%8B%AC%20AveragePooling%E3%80%81%20Max%20Pooling%20%E4%B8%8E%20Weighted%20Pooling%20%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%9A%84%E8%9E%8D%E5%90%88%E3%80%82%E5%85%B6%E4%B8%AD%20WeightedPooling%20%E5%8F%82%E8%80%83%E4%BA%86%20DIN%20%E7%9A%84%E5%AE%9E%E7%8E%B0))

- > 通过离线 AUC 对比，针对目前的训练数据，Average Pooling 的效果为最优的。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E9%80%9A%E8%BF%87%E7%A6%BB%E7%BA%BF%20AUC%20%E5%AF%B9%E6%AF%94%EF%BC%8C%E9%92%88%E5%AF%B9%E7%9B%AE%E5%89%8D%E7%9A%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%EF%BC%8CAverage%20Pooling%20%E7%9A%84%E6%95%88%E6%9E%9C%E4%B8%BA%E6%9C%80%E4%BC%98%E7%9A%84%E3%80%82))
  - 📝 啪啪啪地打 [[DIN]] 的脸，😂

- > 经过对开源框架的广泛调研和选型，我们选择了 PS-Lite 作为 DNN 模型的训练框架。PS-Lite 是 DMLC 开源的 Parameter  
  
Server 实现，主要包含 Server 和 Worker 两种角色，其中 Server 端负责模型参数的存储与更新，Worker 端负责读取训练数据、构建网络结构和进行梯度计算。相较于其他开源框架，其显著优点在于：

*   PS 框架：PS-Lite 的设计中可以更好的利用特征的稀疏性，适用于推荐这种有大量离散特征的场景。
*   封装合理：通信框架和算法解耦，API 强大且清晰，集成比较方便。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E7%BB%8F%E8%BF%87%E5%AF%B9%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%E7%9A%84%E5%B9%BF%E6%B3%9B%E8%B0%83%E7%A0%94%E5%92%8C%E9%80%89%E5%9E%8B%EF%BC%8C%E6%88%91%E4%BB%AC%E9%80%89%E6%8B%A9%E4%BA%86%20PS-Lite%20%E4%BD%9C%E4%B8%BA%20DNN%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E3%80%82PS-Lite%20%E6%98%AF%20DMLC%20%E5%BC%80%E6%BA%90%E7%9A%84%20ParameterServer%20%E5%AE%9E%E7%8E%B0%EF%BC%8C%E4%B8%BB%E8%A6%81%E5%8C%85%E5%90%AB%20Server%20%E5%92%8C%20Worker%20%E4%B8%A4%E7%A7%8D%E8%A7%92%E8%89%B2%EF%BC%8C%E5%85%B6%E4%B8%AD%20Server%20%E7%AB%AF%E8%B4%9F%E8%B4%A3%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E6%9B%B4%E6%96%B0%EF%BC%8CWorker%20%E7%AB%AF%E8%B4%9F%E8%B4%A3%E8%AF%BB%E5%8F%96%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E3%80%81%E6%9E%84%E5%BB%BA%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%92%8C%E8%BF%9B%E8%A1%8C%E6%A2%AF%E5%BA%A6%E8%AE%A1%E7%AE%97%E3%80%82%E7%9B%B8%E8%BE%83%E4%BA%8E%E5%85%B6%E4%BB%96%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%EF%BC%8C%E5%85%B6%E6%98%BE%E8%91%97%E4%BC%98%E7%82%B9%E5%9C%A8%E4%BA%8E%EF%BC%9APS%20%E6%A1%86%E6%9E%B6%EF%BC%9APS-Lite%20%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%AD%E5%8F%AF%E4%BB%A5%E6%9B%B4%E5%A5%BD%E7%9A%84%E5%88%A9%E7%94%A8%E7%89%B9%E5%BE%81%E7%9A%84%E7%A8%80%E7%96%8F%E6%80%A7%EF%BC%8C%E9%80%82%E7%94%A8%E4%BA%8E%E6%8E%A8%E8%8D%90%E8%BF%99%E7%A7%8D%E6%9C%89%E5%A4%A7%E9%87%8F%E7%A6%BB%E6%95%A3%E7%89%B9%E5%BE%81%E7%9A%84%E5%9C%BA%E6%99%AF%E3%80%82%E5%B0%81%E8%A3%85%E5%90%88%E7%90%86%EF%BC%9A%E9%80%9A%E4%BF%A1%E6%A1%86%E6%9E%B6%E5%92%8C%E7%AE%97%E6%B3%95%E8%A7%A3%E8%80%A6%EF%BC%8CAPI%20%E5%BC%BA%E5%A4%A7%E4%B8%94%E6%B8%85%E6%99%B0%EF%BC%8C%E9%9B%86%E6%88%90%E6%AF%94%E8%BE%83%E6%96%B9%E4%BE%BF%E3%80%82))

- > ![](https://pic4.zhimg.com/v2-ef132f536d5215cee0039d42c0cd25cb_r.jpg)  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=https://pic4.zhimg.com/v2-ef132f536d5215cee0039d42c0cd25cb_r.jpg))
  - 📝 PS 架构的工作流程

- > 考虑到 Worker 的执行效率是大致服从高斯分布的，只有小部分的 Worker 是效率极低的，因此我们在训练流程中添加了一个中断机制：当大部分的机器已经执行完当前 Epoch 的时候，剩余的 Worker 进行中断，牺牲少量 Worker 上的部分训练数据来防止训练流程长时间的阻塞。而中断的 Worker 在下个 Epoch 开始时，会从中断时的 Batch 开始继续训练，保证慢节点也能利用所有的训练数据。 [[工程优化]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/35090791#js_content:~:text=%E8%80%83%E8%99%91%E5%88%B0%20Worker%20%E7%9A%84%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87%E6%98%AF%E5%A4%A7%E8%87%B4%E6%9C%8D%E4%BB%8E%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E7%9A%84%EF%BC%8C%E5%8F%AA%E6%9C%89%E5%B0%8F%E9%83%A8%E5%88%86%E7%9A%84%20Worker%20%E6%98%AF%E6%95%88%E7%8E%87%E6%9E%81%E4%BD%8E%E7%9A%84%EF%BC%8C%E5%9B%A0%E6%AD%A4%E6%88%91%E4%BB%AC%E5%9C%A8%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E4%B8%AD%E6%B7%BB%E5%8A%A0%E4%BA%86%E4%B8%80%E4%B8%AA%E4%B8%AD%E6%96%AD%E6%9C%BA%E5%88%B6%EF%BC%9A%E5%BD%93%E5%A4%A7%E9%83%A8%E5%88%86%E7%9A%84%E6%9C%BA%E5%99%A8%E5%B7%B2%E7%BB%8F%E6%89%A7%E8%A1%8C%E5%AE%8C%E5%BD%93%E5%89%8D%20Epoch%20%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%89%A9%E4%BD%99%E7%9A%84%20Worker%20%E8%BF%9B%E8%A1%8C%E4%B8%AD%E6%96%AD%EF%BC%8C%E7%89%BA%E7%89%B2%E5%B0%91%E9%87%8F%20Worker%20%E4%B8%8A%E7%9A%84%E9%83%A8%E5%88%86%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E6%9D%A5%E9%98%B2%E6%AD%A2%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E9%95%BF%E6%97%B6%E9%97%B4%E7%9A%84%E9%98%BB%E5%A1%9E%E3%80%82%E8%80%8C%E4%B8%AD%E6%96%AD%E7%9A%84%20Worker%20%E5%9C%A8%E4%B8%8B%E4%B8%AA%20Epoch%20%E5%BC%80%E5%A7%8B%E6%97%B6%EF%BC%8C%E4%BC%9A%E4%BB%8E%E4%B8%AD%E6%96%AD%E6%97%B6%E7%9A%84%20Batch%20%E5%BC%80%E5%A7%8B%E7%BB%A7%E7%BB%AD%E8%AE%AD%E7%BB%83%EF%BC%8C%E4%BF%9D%E8%AF%81%E6%85%A2%E8%8A%82%E7%82%B9%E4%B9%9F%E8%83%BD%E5%88%A9%E7%94%A8%E6%89%80%E6%9C%89%E7%9A%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E3%80%82))

