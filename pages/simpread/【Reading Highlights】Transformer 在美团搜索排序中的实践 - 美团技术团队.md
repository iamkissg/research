title:: 【Reading Highlights】Transformer 在美团搜索排序中的实践 - 美团技术团队
source:: https://tech.meituan.com/2020/04/16/transformer-in-meituan.html
summary:: 
tags:: [[简悦]] [[美团技术]]  [[transformer]]  [[特征工程]]   [[reading_highlights]]
date:: 20220705  

- > 我们借鉴 AutoInt[3] 的方法，采用 Transformer Layer 进行特征的高阶组合。  ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E6%88%91%E4%BB%AC%E5%80%9F%E9%89%B4%20AutoInt%5B3%5D%20%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%8C%E9%87%87%E7%94%A8%20Transformer%20Layer%20%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E7%9A%84%E9%AB%98%E9%98%B6%E7%BB%84%E5%90%88%E3%80%82))

- > ![](https://p1.meituan.net/travelcube/70aca46c2c8bfd7968655eb4cf372a1885787.png) [[模型结构]]  [[美团技术]]   ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=https://p1.meituan.net/travelcube/70aca46c2c8bfd7968655eb4cf372a1885787.png))
  - 📝 Transformer and Deep

- > 该结构有以下不同：

*   保留将稠密特征和离散特征的 Embedding 送入到 MLP 网络，以隐式的方式学习其非线性表达。
*   Transformer Layer 部分，不是送入所有特征的 Embedding，而是基于人工经验选择了部分特征的 Embedding，第一点是因为美团搜索场景特征的维度高，全输入进去会提高模型的复杂度，导致训练和预测都很慢；第二点是，所有特征的 Embedding 维度不完全相同，也不适合一起输入到 Transformer Layer 。  ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E8%AF%A5%E7%BB%93%E6%9E%84%E6%9C%89%E4%BB%A5%E4%B8%8B%E4%B8%8D%E5%90%8C%EF%BC%9A%E4%BF%9D%E7%95%99%E5%B0%86%E7%A8%A0%E5%AF%86%E7%89%B9%E5%BE%81%E5%92%8C%E7%A6%BB%E6%95%A3%E7%89%B9%E5%BE%81%E7%9A%84%20Embedding%20%E9%80%81%E5%85%A5%E5%88%B0%20MLP%20%E7%BD%91%E7%BB%9C%EF%BC%8C%E4%BB%A5%E9%9A%90%E5%BC%8F%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AD%A6%E4%B9%A0%E5%85%B6%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%A1%A8%E8%BE%BE%E3%80%82Transformer%20Layer%20%E9%83%A8%E5%88%86%EF%BC%8C%E4%B8%8D%E6%98%AF%E9%80%81%E5%85%A5%E6%89%80%E6%9C%89%E7%89%B9%E5%BE%81%E7%9A%84%20Embedding%EF%BC%8C%E8%80%8C%E6%98%AF%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%B7%A5%E7%BB%8F%E9%AA%8C%E9%80%89%E6%8B%A9%E4%BA%86%E9%83%A8%E5%88%86%E7%89%B9%E5%BE%81%E7%9A%84%20Embedding%EF%BC%8C%E7%AC%AC%E4%B8%80%E7%82%B9%E6%98%AF%E5%9B%A0%E4%B8%BA%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E5%9C%BA%E6%99%AF%E7%89%B9%E5%BE%81%E7%9A%84%E7%BB%B4%E5%BA%A6%E9%AB%98%EF%BC%8C%E5%85%A8%E8%BE%93%E5%85%A5%E8%BF%9B%E5%8E%BB%E4%BC%9A%E6%8F%90%E9%AB%98%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%8C%E5%AF%BC%E8%87%B4%E8%AE%AD%E7%BB%83%E5%92%8C%E9%A2%84%E6%B5%8B%E9%83%BD%E5%BE%88%E6%85%A2%EF%BC%9B%E7%AC%AC%E4%BA%8C%E7%82%B9%E6%98%AF%EF%BC%8C%E6%89%80%E6%9C%89%E7%89%B9%E5%BE%81%E7%9A%84%20Embedding%20%E7%BB%B4%E5%BA%A6%E4%B8%8D%E5%AE%8C%E5%85%A8%E7%9B%B8%E5%90%8C%EF%BC%8C%E4%B9%9F%E4%B8%8D%E9%80%82%E5%90%88%E4%B8%80%E8%B5%B7%E8%BE%93%E5%85%A5%E5%88%B0%20Transformer%20Layer%20%E3%80%82))
  - 📝 对于维度不同的特征：
  - 📝 1. 有选择地使用同一维度的特征，输入 transformer
  - 📝 2. 将所有特征映射为相同维度，再输入 transformer

- > **Embedding Layer 部分**：众所周知在 CTR 预估中，除了大规模稀疏 ID 特征，稠密类型的统计特征也是非常有用的特征，所以这部分将所有的稠密特征和稀疏 ID 特征都转换成 Embedding 表示。

**Transformer 部分**：针对用户行为序列、商户 、品类 、地理位置等 Embedding 表示，使用 Transformer Layer 来显示学习这些特征的交叉关系。

**MLP 部分**：考虑到 MLP 具有很强的隐式交叉能力，将所有特征的 Embedding 表示 concat 一起输入到 MLP。  ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=Embedding%20Layer%20%E9%83%A8%E5%88%86%EF%BC%9A%E4%BC%97%E6%89%80%E5%91%A8%E7%9F%A5%E5%9C%A8%20CTR%20%E9%A2%84%E4%BC%B0%E4%B8%AD%EF%BC%8C%E9%99%A4%E4%BA%86%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%A8%80%E7%96%8F%20ID%20%E7%89%B9%E5%BE%81%EF%BC%8C%E7%A8%A0%E5%AF%86%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81%E4%B9%9F%E6%98%AF%E9%9D%9E%E5%B8%B8%E6%9C%89%E7%94%A8%E7%9A%84%E7%89%B9%E5%BE%81%EF%BC%8C%E6%89%80%E4%BB%A5%E8%BF%99%E9%83%A8%E5%88%86%E5%B0%86%E6%89%80%E6%9C%89%E7%9A%84%E7%A8%A0%E5%AF%86%E7%89%B9%E5%BE%81%E5%92%8C%E7%A8%80%E7%96%8F%20ID%20%E7%89%B9%E5%BE%81%E9%83%BD%E8%BD%AC%E6%8D%A2%E6%88%90%20Embedding%20%E8%A1%A8%E7%A4%BA%E3%80%82Transformer%20%E9%83%A8%E5%88%86%EF%BC%9A%E9%92%88%E5%AF%B9%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E3%80%81%E5%95%86%E6%88%B7%20%E3%80%81%E5%93%81%E7%B1%BB%20%E3%80%81%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E7%AD%89%20Embedding%20%E8%A1%A8%E7%A4%BA%EF%BC%8C%E4%BD%BF%E7%94%A8%20Transformer%20Layer%20%E6%9D%A5%E6%98%BE%E7%A4%BA%E5%AD%A6%E4%B9%A0%E8%BF%99%E4%BA%9B%E7%89%B9%E5%BE%81%E7%9A%84%E4%BA%A4%E5%8F%89%E5%85%B3%E7%B3%BB%E3%80%82MLP%20%E9%83%A8%E5%88%86%EF%BC%9A%E8%80%83%E8%99%91%E5%88%B0%20MLP%20%E5%85%B7%E6%9C%89%E5%BE%88%E5%BC%BA%E7%9A%84%E9%9A%90%E5%BC%8F%E4%BA%A4%E5%8F%89%E8%83%BD%E5%8A%9B%EF%BC%8C%E5%B0%86%E6%89%80%E6%9C%89%E7%89%B9%E5%BE%81%E7%9A%84%20Embedding%20%E8%A1%A8%E7%A4%BA%20concat%20%E4%B8%80%E8%B5%B7%E8%BE%93%E5%85%A5%E5%88%B0%20MLP%E3%80%82))

- > **经验：**

*   三层 Transformer 编码层效果比较好。
*   调节多头注意力的 “头” 数对效果影响不大 。
*   Transformer 编码层输出的 Embedding 大小对结果影响不大。
*   Transformer 和 MLP 融合的时候，最后结果融合和先 concat 再接一个全连接层效果差不多。 [[实践经验]]  [[美团技术]]   ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E7%BB%8F%E9%AA%8C%EF%BC%9A%E4%B8%89%E5%B1%82%20Transformer%20%E7%BC%96%E7%A0%81%E5%B1%82%E6%95%88%E6%9E%9C%E6%AF%94%E8%BE%83%E5%A5%BD%E3%80%82%E8%B0%83%E8%8A%82%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%20%E2%80%9C%E5%A4%B4%E2%80%9D%20%E6%95%B0%E5%AF%B9%E6%95%88%E6%9E%9C%E5%BD%B1%E5%93%8D%E4%B8%8D%E5%A4%A7%20%E3%80%82Transformer%20%E7%BC%96%E7%A0%81%E5%B1%82%E8%BE%93%E5%87%BA%E7%9A%84%20Embedding%20%E5%A4%A7%E5%B0%8F%E5%AF%B9%E7%BB%93%E6%9E%9C%E5%BD%B1%E5%93%8D%E4%B8%8D%E5%A4%A7%E3%80%82Transformer%20%E5%92%8C%20MLP%20%E8%9E%8D%E5%90%88%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E6%9C%80%E5%90%8E%E7%BB%93%E6%9E%9C%E8%9E%8D%E5%90%88%E5%92%8C%E5%85%88%20concat%20%E5%86%8D%E6%8E%A5%E4%B8%80%E4%B8%AA%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E6%95%88%E6%9E%9C%E5%B7%AE%E4%B8%8D%E5%A4%9A%E3%80%82))

- > 过去，我们对训练数据研究发现，在训练数据量很大的情况下，item 的大部分信息都可以被 ID 的 Embedding 向量进行表示，但是用户 ID 在训练数据中是十分稀疏的，用户 ID 很容易导致模型过拟合，所以需要大量的泛化特征来较好的表达用户。 [[实践经验]]  [[过拟合]]   ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E8%BF%87%E5%8E%BB%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AF%B9%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E7%A0%94%E7%A9%B6%E5%8F%91%E7%8E%B0%EF%BC%8C%E5%9C%A8%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%87%8F%E5%BE%88%E5%A4%A7%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8Citem%20%E7%9A%84%E5%A4%A7%E9%83%A8%E5%88%86%E4%BF%A1%E6%81%AF%E9%83%BD%E5%8F%AF%E4%BB%A5%E8%A2%AB%20ID%20%E7%9A%84%20Embedding%20%E5%90%91%E9%87%8F%E8%BF%9B%E8%A1%8C%E8%A1%A8%E7%A4%BA%EF%BC%8C%E4%BD%86%E6%98%AF%E7%94%A8%E6%88%B7%20ID%20%E5%9C%A8%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%AD%E6%98%AF%E5%8D%81%E5%88%86%E7%A8%80%E7%96%8F%E7%9A%84%EF%BC%8C%E7%94%A8%E6%88%B7%20ID%20%E5%BE%88%E5%AE%B9%E6%98%93%E5%AF%BC%E8%87%B4%E6%A8%A1%E5%9E%8B%E8%BF%87%E6%8B%9F%E5%90%88%EF%BC%8C%E6%89%80%E4%BB%A5%E9%9C%80%E8%A6%81%E5%A4%A7%E9%87%8F%E7%9A%84%E6%B3%9B%E5%8C%96%E7%89%B9%E5%BE%81%E6%9D%A5%E8%BE%83%E5%A5%BD%E7%9A%84%E8%A1%A8%E8%BE%BE%E7%94%A8%E6%88%B7%E3%80%82))
  - 📝 数据量够大的情况下，item id embedding 能够较好地表示物品了，但是用户更加稀疏，user id embedding 容易过拟合，需要更多的特征来支持泛化，防止过拟合（个人--->人群）

- > 泛化特征可以分为两类：一类是偏静态的特征，例如用户的基本属性（年龄、性别、职业等等）特征、长期偏好（品类、价格等等）特征；另一类是动态变化的特征，例如刻画用户兴趣的实时行为序列特征。而用户实时行为特征能够明显加强不同样本之间的区分度，所以在模型中优化用户行为序列建模是让模型更好理解用户的关键环节。  ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E6%B3%9B%E5%8C%96%E7%89%B9%E5%BE%81%E5%8F%AF%E4%BB%A5%E5%88%86%E4%B8%BA%E4%B8%A4%E7%B1%BB%EF%BC%9A%E4%B8%80%E7%B1%BB%E6%98%AF%E5%81%8F%E9%9D%99%E6%80%81%E7%9A%84%E7%89%B9%E5%BE%81%EF%BC%8C%E4%BE%8B%E5%A6%82%E7%94%A8%E6%88%B7%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%B1%9E%E6%80%A7%EF%BC%88%E5%B9%B4%E9%BE%84%E3%80%81%E6%80%A7%E5%88%AB%E3%80%81%E8%81%8C%E4%B8%9A%E7%AD%89%E7%AD%89%EF%BC%89%E7%89%B9%E5%BE%81%E3%80%81%E9%95%BF%E6%9C%9F%E5%81%8F%E5%A5%BD%EF%BC%88%E5%93%81%E7%B1%BB%E3%80%81%E4%BB%B7%E6%A0%BC%E7%AD%89%E7%AD%89%EF%BC%89%E7%89%B9%E5%BE%81%EF%BC%9B%E5%8F%A6%E4%B8%80%E7%B1%BB%E6%98%AF%E5%8A%A8%E6%80%81%E5%8F%98%E5%8C%96%E7%9A%84%E7%89%B9%E5%BE%81%EF%BC%8C%E4%BE%8B%E5%A6%82%E5%88%BB%E7%94%BB%E7%94%A8%E6%88%B7%E5%85%B4%E8%B6%A3%E7%9A%84%E5%AE%9E%E6%97%B6%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E7%89%B9%E5%BE%81%E3%80%82%E8%80%8C%E7%94%A8%E6%88%B7%E5%AE%9E%E6%97%B6%E8%A1%8C%E4%B8%BA%E7%89%B9%E5%BE%81%E8%83%BD%E5%A4%9F%E6%98%8E%E6%98%BE%E5%8A%A0%E5%BC%BA%E4%B8%8D%E5%90%8C%E6%A0%B7%E6%9C%AC%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%86%E5%BA%A6%EF%BC%8C%E6%89%80%E4%BB%A5%E5%9C%A8%E6%A8%A1%E5%9E%8B%E4%B8%AD%E4%BC%98%E5%8C%96%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1%E6%98%AF%E8%AE%A9%E6%A8%A1%E5%9E%8B%E6%9B%B4%E5%A5%BD%E7%90%86%E8%A7%A3%E7%94%A8%E6%88%B7%E7%9A%84%E5%85%B3%E9%94%AE%E7%8E%AF%E8%8A%82%E3%80%82))
  - 📝 用户的静态特征表征其长期偏好；动态特征补充了区分性，更加强调了个性。

- > 模型主要构成：所有特征（user 维度、item 维度、query 维度、上下文维度、交叉维度）经过底层 Embedding Layer 得到对应的 Embedding 表示；建模用户行为序列得到用户的 Embedding 表示；所有 Embedding concat 一起送入到三层的 MLP 网络。  ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E6%A8%A1%E5%9E%8B%E4%B8%BB%E8%A6%81%E6%9E%84%E6%88%90%EF%BC%9A%E6%89%80%E6%9C%89%E7%89%B9%E5%BE%81%EF%BC%88user%20%E7%BB%B4%E5%BA%A6%E3%80%81item%20%E7%BB%B4%E5%BA%A6%E3%80%81query%20%E7%BB%B4%E5%BA%A6%E3%80%81%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BB%B4%E5%BA%A6%E3%80%81%E4%BA%A4%E5%8F%89%E7%BB%B4%E5%BA%A6%EF%BC%89%E7%BB%8F%E8%BF%87%E5%BA%95%E5%B1%82%20Embedding%20Layer%20%E5%BE%97%E5%88%B0%E5%AF%B9%E5%BA%94%E7%9A%84%20Embedding%20%E8%A1%A8%E7%A4%BA%EF%BC%9B%E5%BB%BA%E6%A8%A1%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BE%97%E5%88%B0%E7%94%A8%E6%88%B7%E7%9A%84%20Embedding%20%E8%A1%A8%E7%A4%BA%EF%BC%9B%E6%89%80%E6%9C%89%20Embedding%20concat%20%E4%B8%80%E8%B5%B7%E9%80%81%E5%85%A5%E5%88%B0%E4%B8%89%E5%B1%82%E7%9A%84%20MLP%20%E7%BD%91%E7%BB%9C%E3%80%82))

- > ![](https://p0.meituan.net/travelcube/fc0c56560897762402bb49be3437110b133163.png) [[模型结构]]  [[美团技术]]   ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=https://p0.meituan.net/travelcube/fc0c56560897762402bb49be3437110b133163.png))
  - 📝 美团基于 transformer 的第一版行为序列建模

- > ![](https://p0.meituan.net/travelcube/a39335eadca8491666e2199a3a85e45b135740.png) [[模型结构]]  [[美团技术]]   ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=https://p0.meituan.net/travelcube/a39335eadca8491666e2199a3a85e45b135740.png))
  - 📝 美团基于 transformer 的第二版行为序列建模，加入了 target item

- > ![](https://p1.meituan.net/travelcube/e02d200cf7efda0014a00600df0af4f1143226.png) [[美团技术]]  [[模型结构]]   ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=https://p1.meituan.net/travelcube/e02d200cf7efda0014a00600df0af4f1143226.png))
  - 📝 美团基于 transformer 的第三版行为序列建模：此处才加入了 attention，也不知道第二版是怎么处理的- -。

- > **经验：**

*   Transformer 编码为什么有效？Transformer 编码层内部的自注意力机制，能够对序列内 item 的相互关系进行有效的建模来实现更好的表达，并且我们离线实验不加 Transformer 编码层的 Attention-pooling，发现离线 NDCG 下降，从实验上证明了 Transformer 编码有效。
*   Transformer 编码为什么优于 GRU ？忽略 GRU 的性能差于 Transformer；我们做过实验将行为序列长度的上限往下调，Transformer 的效果相比 GRU 的效果提升在缩小，但是整体还是行为序列的长度越大越好，所以 Transformer 相比 GRU 在长距离时，特征捕获能力更强。
*   位置编码（Pos-Encoding）的影响我们试过加 Transformer 里面原生的正余弦以及距当前预测时间的时间间隔的位置编码都无效果，分析应该是我们在处理行为序列的时候，已经将序列切割成不同时间段，一定程度上包含了时序位置信息。为了验证这个想法，我们做了仅使用一个长序列的实验（对照组不加位置编码，实验组加位置编码，离线 NDCG 有提升），这验证了我们的猜测。
*   Transformer 编码层不需要太多，层数过多导致模型过于复杂，模型收敛慢效果不好。
*   调节多头注意力的 “头” 数对效果影响不大。 [[实践经验]]   ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E7%BB%8F%E9%AA%8C%EF%BC%9ATransformer%20%E7%BC%96%E7%A0%81%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%88%EF%BC%9FTransformer%20%E7%BC%96%E7%A0%81%E5%B1%82%E5%86%85%E9%83%A8%E7%9A%84%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E8%83%BD%E5%A4%9F%E5%AF%B9%E5%BA%8F%E5%88%97%E5%86%85%20item%20%E7%9A%84%E7%9B%B8%E4%BA%92%E5%85%B3%E7%B3%BB%E8%BF%9B%E8%A1%8C%E6%9C%89%E6%95%88%E7%9A%84%E5%BB%BA%E6%A8%A1%E6%9D%A5%E5%AE%9E%E7%8E%B0%E6%9B%B4%E5%A5%BD%E7%9A%84%E8%A1%A8%E8%BE%BE%EF%BC%8C%E5%B9%B6%E4%B8%94%E6%88%91%E4%BB%AC%E7%A6%BB%E7%BA%BF%E5%AE%9E%E9%AA%8C%E4%B8%8D%E5%8A%A0%20Transformer%20%E7%BC%96%E7%A0%81%E5%B1%82%E7%9A%84%20Attention-pooling%EF%BC%8C%E5%8F%91%E7%8E%B0%E7%A6%BB%E7%BA%BF%20NDCG%20%E4%B8%8B%E9%99%8D%EF%BC%8C%E4%BB%8E%E5%AE%9E%E9%AA%8C%E4%B8%8A%E8%AF%81%E6%98%8E%E4%BA%86%20Transformer%20%E7%BC%96%E7%A0%81%E6%9C%89%E6%95%88%E3%80%82Transformer%20%E7%BC%96%E7%A0%81%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%98%E4%BA%8E%20GRU%20%EF%BC%9F%E5%BF%BD%E7%95%A5%20GRU%20%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%AE%E4%BA%8E%20Transformer%EF%BC%9B%E6%88%91%E4%BB%AC%E5%81%9A%E8%BF%87%E5%AE%9E%E9%AA%8C%E5%B0%86%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E9%95%BF%E5%BA%A6%E7%9A%84%E4%B8%8A%E9%99%90%E5%BE%80%E4%B8%8B%E8%B0%83%EF%BC%8CTransformer%20%E7%9A%84%E6%95%88%E6%9E%9C%E7%9B%B8%E6%AF%94%20GRU%20%E7%9A%84%E6%95%88%E6%9E%9C%E6%8F%90%E5%8D%87%E5%9C%A8%E7%BC%A9%E5%B0%8F%EF%BC%8C%E4%BD%86%E6%98%AF%E6%95%B4%E4%BD%93%E8%BF%98%E6%98%AF%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E7%9A%84%E9%95%BF%E5%BA%A6%E8%B6%8A%E5%A4%A7%E8%B6%8A%E5%A5%BD%EF%BC%8C%E6%89%80%E4%BB%A5%20Transformer%20%E7%9B%B8%E6%AF%94%20GRU%20%E5%9C%A8%E9%95%BF%E8%B7%9D%E7%A6%BB%E6%97%B6%EF%BC%8C%E7%89%B9%E5%BE%81%E6%8D%95%E8%8E%B7%E8%83%BD%E5%8A%9B%E6%9B%B4%E5%BC%BA%E3%80%82%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%EF%BC%88Pos-Encoding%EF%BC%89%E7%9A%84%E5%BD%B1%E5%93%8D%E6%88%91%E4%BB%AC%E8%AF%95%E8%BF%87%E5%8A%A0%20Transformer%20%E9%87%8C%E9%9D%A2%E5%8E%9F%E7%94%9F%E7%9A%84%E6%AD%A3%E4%BD%99%E5%BC%A6%E4%BB%A5%E5%8F%8A%E8%B7%9D%E5%BD%93%E5%89%8D%E9%A2%84%E6%B5%8B%E6%97%B6%E9%97%B4%E7%9A%84%E6%97%B6%E9%97%B4%E9%97%B4%E9%9A%94%E7%9A%84%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E9%83%BD%E6%97%A0%E6%95%88%E6%9E%9C%EF%BC%8C%E5%88%86%E6%9E%90%E5%BA%94%E8%AF%A5%E6%98%AF%E6%88%91%E4%BB%AC%E5%9C%A8%E5%A4%84%E7%90%86%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%B7%B2%E7%BB%8F%E5%B0%86%E5%BA%8F%E5%88%97%E5%88%87%E5%89%B2%E6%88%90%E4%B8%8D%E5%90%8C%E6%97%B6%E9%97%B4%E6%AE%B5%EF%BC%8C%E4%B8%80%E5%AE%9A%E7%A8%8B%E5%BA%A6%E4%B8%8A%E5%8C%85%E5%90%AB%E4%BA%86%E6%97%B6%E5%BA%8F%E4%BD%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E3%80%82%E4%B8%BA%E4%BA%86%E9%AA%8C%E8%AF%81%E8%BF%99%E4%B8%AA%E6%83%B3%E6%B3%95%EF%BC%8C%E6%88%91%E4%BB%AC%E5%81%9A%E4%BA%86%E4%BB%85%E4%BD%BF%E7%94%A8%E4%B8%80%E4%B8%AA%E9%95%BF%E5%BA%8F%E5%88%97%E7%9A%84%E5%AE%9E%E9%AA%8C%EF%BC%88%E5%AF%B9%E7%85%A7%E7%BB%84%E4%B8%8D%E5%8A%A0%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%EF%BC%8C%E5%AE%9E%E9%AA%8C%E7%BB%84%E5%8A%A0%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%EF%BC%8C%E7%A6%BB%E7%BA%BF%20NDCG%20%E6%9C%89%E6%8F%90%E5%8D%87%EF%BC%89%EF%BC%8C%E8%BF%99%E9%AA%8C%E8%AF%81%E4%BA%86%E6%88%91%E4%BB%AC%E7%9A%84%E7%8C%9C%E6%B5%8B%E3%80%82Transformer%20%E7%BC%96%E7%A0%81%E5%B1%82%E4%B8%8D%E9%9C%80%E8%A6%81%E5%A4%AA%E5%A4%9A%EF%BC%8C%E5%B1%82%E6%95%B0%E8%BF%87%E5%A4%9A%E5%AF%BC%E8%87%B4%E6%A8%A1%E5%9E%8B%E8%BF%87%E4%BA%8E%E5%A4%8D%E6%9D%82%EF%BC%8C%E6%A8%A1%E5%9E%8B%E6%94%B6%E6%95%9B%E6%85%A2%E6%95%88%E6%9E%9C%E4%B8%8D%E5%A5%BD%E3%80%82%E8%B0%83%E8%8A%82%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%20%E2%80%9C%E5%A4%B4%E2%80%9D%20%E6%95%B0%E5%AF%B9%E6%95%88%E6%9E%9C%E5%BD%B1%E5%93%8D%E4%B8%8D%E5%A4%A7%E3%80%82))

- > 一种直接利用上下文信息优化排序的方法是对精排的结果进行重排，这可以抽象建模成一个序列（排序序列）生成另一个序列（重排序列）的过程，自然联想到可以使用 NLP 领域常用的 Sequence to Sequence 建模方法进行重排序建模。  ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E4%B8%80%E7%A7%8D%E7%9B%B4%E6%8E%A5%E5%88%A9%E7%94%A8%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF%E4%BC%98%E5%8C%96%E6%8E%92%E5%BA%8F%E7%9A%84%E6%96%B9%E6%B3%95%E6%98%AF%E5%AF%B9%E7%B2%BE%E6%8E%92%E7%9A%84%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E9%87%8D%E6%8E%92%EF%BC%8C%E8%BF%99%E5%8F%AF%E4%BB%A5%E6%8A%BD%E8%B1%A1%E5%BB%BA%E6%A8%A1%E6%88%90%E4%B8%80%E4%B8%AA%E5%BA%8F%E5%88%97%EF%BC%88%E6%8E%92%E5%BA%8F%E5%BA%8F%E5%88%97%EF%BC%89%E7%94%9F%E6%88%90%E5%8F%A6%E4%B8%80%E4%B8%AA%E5%BA%8F%E5%88%97%EF%BC%88%E9%87%8D%E6%8E%92%E5%BA%8F%E5%88%97%EF%BC%89%E7%9A%84%E8%BF%87%E7%A8%8B%EF%BC%8C%E8%87%AA%E7%84%B6%E8%81%94%E6%83%B3%E5%88%B0%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%20NLP%20%E9%A2%86%E5%9F%9F%E5%B8%B8%E7%94%A8%E7%9A%84%20Sequence%20to%20Sequence%20%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E9%87%8D%E6%8E%92%E5%BA%8F%E5%BB%BA%E6%A8%A1%E3%80%82))
  - 📝 利用 seq2seq 来重排，有点意思的
  - 📝 +[[指针网络]]

- > ![](https://p1.meituan.net/travelcube/98276d2b966befaa78f099b34b9ba300134983.png) [[模型结构]]  [[美团技术]]   ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=https://p1.meituan.net/travelcube/98276d2b966befaa78f099b34b9ba300134983.png))
  - 📝 基于 transformer 的重排序（参考 PRM）

- > 主要由以下几个部分构成：

*   **特征向量生成**：由原始特征（user、item、交叉等维度的稠密统计特征）经过一层全连接的输出进行表示。
*   **输入层**：其中 X 表示商户的特征向量，P 表示商户的位置编码，将特征向量 X 与位置向量 P 进行 concat 作为最终输入。
*   **Transformer 编码层**：一层 Multi-Head Attention 和 FFN 的。
*   **输出层**：一层全连接网络得到打分输出 Score。  ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E4%B8%BB%E8%A6%81%E7%94%B1%E4%BB%A5%E4%B8%8B%E5%87%A0%E4%B8%AA%E9%83%A8%E5%88%86%E6%9E%84%E6%88%90%EF%BC%9A%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%94%9F%E6%88%90%EF%BC%9A%E7%94%B1%E5%8E%9F%E5%A7%8B%E7%89%B9%E5%BE%81%EF%BC%88user%E3%80%81item%E3%80%81%E4%BA%A4%E5%8F%89%E7%AD%89%E7%BB%B4%E5%BA%A6%E7%9A%84%E7%A8%A0%E5%AF%86%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81%EF%BC%89%E7%BB%8F%E8%BF%87%E4%B8%80%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%9A%84%E8%BE%93%E5%87%BA%E8%BF%9B%E8%A1%8C%E8%A1%A8%E7%A4%BA%E3%80%82%E8%BE%93%E5%85%A5%E5%B1%82%EF%BC%9A%E5%85%B6%E4%B8%AD%20X%20%E8%A1%A8%E7%A4%BA%E5%95%86%E6%88%B7%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%EF%BC%8CP%20%E8%A1%A8%E7%A4%BA%E5%95%86%E6%88%B7%E7%9A%84%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%EF%BC%8C%E5%B0%86%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%20X%20%E4%B8%8E%E4%BD%8D%E7%BD%AE%E5%90%91%E9%87%8F%20P%20%E8%BF%9B%E8%A1%8C%20concat%20%E4%BD%9C%E4%B8%BA%E6%9C%80%E7%BB%88%E8%BE%93%E5%85%A5%E3%80%82Transformer%20%E7%BC%96%E7%A0%81%E5%B1%82%EF%BC%9A%E4%B8%80%E5%B1%82%20Multi-Head%20Attention%20%E5%92%8C%20FFN%20%E7%9A%84%E3%80%82%E8%BE%93%E5%87%BA%E5%B1%82%EF%BC%9A%E4%B8%80%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C%E5%BE%97%E5%88%B0%E6%89%93%E5%88%86%E8%BE%93%E5%87%BA%20Score%E3%80%82))

- > **模型细节：**

*   特征向量生成部分和重排序模型是一个整体，联合端到端训练。
*   训练和预测阶段固定选择 TopK 进行重排，遇到某些请求曝光 item 集不够 TopK 的情况下，在末尾补零向量进行对齐。  ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E6%A8%A1%E5%9E%8B%E7%BB%86%E8%8A%82%EF%BC%9A%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%94%9F%E6%88%90%E9%83%A8%E5%88%86%E5%92%8C%E9%87%8D%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E6%98%AF%E4%B8%80%E4%B8%AA%E6%95%B4%E4%BD%93%EF%BC%8C%E8%81%94%E5%90%88%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%AE%AD%E7%BB%83%E3%80%82%E8%AE%AD%E7%BB%83%E5%92%8C%E9%A2%84%E6%B5%8B%E9%98%B6%E6%AE%B5%E5%9B%BA%E5%AE%9A%E9%80%89%E6%8B%A9%20TopK%20%E8%BF%9B%E8%A1%8C%E9%87%8D%E6%8E%92%EF%BC%8C%E9%81%87%E5%88%B0%E6%9F%90%E4%BA%9B%E8%AF%B7%E6%B1%82%E6%9B%9D%E5%85%89%20item%20%E9%9B%86%E4%B8%8D%E5%A4%9F%20TopK%20%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8C%E5%9C%A8%E6%9C%AB%E5%B0%BE%E8%A1%A5%E9%9B%B6%E5%90%91%E9%87%8F%E8%BF%9B%E8%A1%8C%E5%AF%B9%E9%BD%90%E3%80%82))

- > **经验：**

*   重排序大小如何选择？考虑到线上性能问题，重排序的候选集不能过大，我们分析数据发现 95% 的用户浏览深度不超过 10，所以我们选择对 Top10 的商户进行重排。
*   位置编码向量的重要性：这个在重排序中很重要，需要位置编码向量来刻画位置，更好的让模型学习出上下文信息，离线实验发现去掉位置向量 NDCG@10 下降明显。
*   性能优化：最初选择商户全部的精排特征作为输入，发现线上预测时间太慢；后面进行特征重要性评估，筛选出部分重要特征作为输入，使得线上预测性能满足上线要求。
*   调节多头注意力的 “头” 数对效果影响不大。 [[实践经验]]  [[美团技术]]   ([🌐 摘要链接](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html#js_content:~:text=%E7%BB%8F%E9%AA%8C%EF%BC%9A%E9%87%8D%E6%8E%92%E5%BA%8F%E5%A4%A7%E5%B0%8F%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%EF%BC%9F%E8%80%83%E8%99%91%E5%88%B0%E7%BA%BF%E4%B8%8A%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%EF%BC%8C%E9%87%8D%E6%8E%92%E5%BA%8F%E7%9A%84%E5%80%99%E9%80%89%E9%9B%86%E4%B8%8D%E8%83%BD%E8%BF%87%E5%A4%A7%EF%BC%8C%E6%88%91%E4%BB%AC%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E5%8F%91%E7%8E%B0%2095%25%20%E7%9A%84%E7%94%A8%E6%88%B7%E6%B5%8F%E8%A7%88%E6%B7%B1%E5%BA%A6%E4%B8%8D%E8%B6%85%E8%BF%87%2010%EF%BC%8C%E6%89%80%E4%BB%A5%E6%88%91%E4%BB%AC%E9%80%89%E6%8B%A9%E5%AF%B9%20Top10%20%E7%9A%84%E5%95%86%E6%88%B7%E8%BF%9B%E8%A1%8C%E9%87%8D%E6%8E%92%E3%80%82%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E5%90%91%E9%87%8F%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7%EF%BC%9A%E8%BF%99%E4%B8%AA%E5%9C%A8%E9%87%8D%E6%8E%92%E5%BA%8F%E4%B8%AD%E5%BE%88%E9%87%8D%E8%A6%81%EF%BC%8C%E9%9C%80%E8%A6%81%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E5%90%91%E9%87%8F%E6%9D%A5%E5%88%BB%E7%94%BB%E4%BD%8D%E7%BD%AE%EF%BC%8C%E6%9B%B4%E5%A5%BD%E7%9A%84%E8%AE%A9%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E5%87%BA%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF%EF%BC%8C%E7%A6%BB%E7%BA%BF%E5%AE%9E%E9%AA%8C%E5%8F%91%E7%8E%B0%E5%8E%BB%E6%8E%89%E4%BD%8D%E7%BD%AE%E5%90%91%E9%87%8F%20NDCG@10%20%E4%B8%8B%E9%99%8D%E6%98%8E%E6%98%BE%E3%80%82%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%9A%E6%9C%80%E5%88%9D%E9%80%89%E6%8B%A9%E5%95%86%E6%88%B7%E5%85%A8%E9%83%A8%E7%9A%84%E7%B2%BE%E6%8E%92%E7%89%B9%E5%BE%81%E4%BD%9C%E4%B8%BA%E8%BE%93%E5%85%A5%EF%BC%8C%E5%8F%91%E7%8E%B0%E7%BA%BF%E4%B8%8A%E9%A2%84%E6%B5%8B%E6%97%B6%E9%97%B4%E5%A4%AA%E6%85%A2%EF%BC%9B%E5%90%8E%E9%9D%A2%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E8%AF%84%E4%BC%B0%EF%BC%8C%E7%AD%9B%E9%80%89%E5%87%BA%E9%83%A8%E5%88%86%E9%87%8D%E8%A6%81%E7%89%B9%E5%BE%81%E4%BD%9C%E4%B8%BA%E8%BE%93%E5%85%A5%EF%BC%8C%E4%BD%BF%E5%BE%97%E7%BA%BF%E4%B8%8A%E9%A2%84%E6%B5%8B%E6%80%A7%E8%83%BD%E6%BB%A1%E8%B6%B3%E4%B8%8A%E7%BA%BF%E8%A6%81%E6%B1%82%E3%80%82%E8%B0%83%E8%8A%82%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%20%E2%80%9C%E5%A4%B4%E2%80%9D%20%E6%95%B0%E5%AF%B9%E6%95%88%E6%9E%9C%E5%BD%B1%E5%93%8D%E4%B8%8D%E5%A4%A7%E3%80%82))

