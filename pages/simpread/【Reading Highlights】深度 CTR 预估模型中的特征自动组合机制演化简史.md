title:: 【Reading Highlights】深度 CTR 预估模型中的特征自动组合机制演化简史
source:: https://zhuanlan.zhihu.com/p/52876883
summary:: 
tags:: [[简悦]] [[特征工程]]  [[特征组合]]   [[reading_highlights]]
date:: 20220607  

- > 本文在跟踪了最近主流的互联网业务中大量使用的排序模型的基础上，总结出了深度 CTR、CVR 预估模型发展演化的三条主线，跟大家分享。

1.  第一条主脉络是以 FM 家族为代表的深度模型，它们的共同特点是自动学习从原始特征交叉组合新的高阶特征。
2.  第二条主脉络是一类使用 attention 机制处理时序特征的深度模型，以 DIN、DIEN 等模型为代表。
3.  第三条主脉络是以迁移学习、多任务学习为基础的联合训练模型或 pre-train 机制，以 [ESMM](https://zhuanlan.zhihu.com/p/37562283) 、DUPN 等模型为代表。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=%E6%9C%AC%E6%96%87%E5%9C%A8%E8%B7%9F%E8%B8%AA%E4%BA%86%E6%9C%80%E8%BF%91%E4%B8%BB%E6%B5%81%E7%9A%84%E4%BA%92%E8%81%94%E7%BD%91%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%A4%A7%E9%87%8F%E4%BD%BF%E7%94%A8%E7%9A%84%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B8%8A%EF%BC%8C%E6%80%BB%E7%BB%93%E5%87%BA%E4%BA%86%E6%B7%B1%E5%BA%A6%20CTR%E3%80%81CVR%20%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E6%BC%94%E5%8C%96%E7%9A%84%E4%B8%89%E6%9D%A1%E4%B8%BB%E7%BA%BF%EF%BC%8C%E8%B7%9F%E5%A4%A7%E5%AE%B6%E5%88%86%E4%BA%AB%E3%80%82%E7%AC%AC%E4%B8%80%E6%9D%A1%E4%B8%BB%E8%84%89%E7%BB%9C%E6%98%AF%E4%BB%A5%20FM%20%E5%AE%B6%E6%97%8F%E4%B8%BA%E4%BB%A3%E8%A1%A8%E7%9A%84%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%AE%83%E4%BB%AC%E7%9A%84%E5%85%B1%E5%90%8C%E7%89%B9%E7%82%B9%E6%98%AF%E8%87%AA%E5%8A%A8%E5%AD%A6%E4%B9%A0%E4%BB%8E%E5%8E%9F%E5%A7%8B%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E7%BB%84%E5%90%88%E6%96%B0%E7%9A%84%E9%AB%98%E9%98%B6%E7%89%B9%E5%BE%81%E3%80%82%E7%AC%AC%E4%BA%8C%E6%9D%A1%E4%B8%BB%E8%84%89%E7%BB%9C%E6%98%AF%E4%B8%80%E7%B1%BB%E4%BD%BF%E7%94%A8%20attention%20%E6%9C%BA%E5%88%B6%E5%A4%84%E7%90%86%E6%97%B6%E5%BA%8F%E7%89%B9%E5%BE%81%E7%9A%84%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%EF%BC%8C%E4%BB%A5%20DIN%E3%80%81DIEN%20%E7%AD%89%E6%A8%A1%E5%9E%8B%E4%B8%BA%E4%BB%A3%E8%A1%A8%E3%80%82%E7%AC%AC%E4%B8%89%E6%9D%A1%E4%B8%BB%E8%84%89%E7%BB%9C%E6%98%AF%E4%BB%A5%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E3%80%81%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%81%94%E5%90%88%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%88%96%20pre-train%20%E6%9C%BA%E5%88%B6%EF%BC%8C%E4%BB%A5ESMM%20%E3%80%81DUPN%20%E7%AD%89%E6%A8%A1%E5%9E%8B%E4%B8%BA%E4%BB%A3%E8%A1%A8%E3%80%82))

- > 在深度学习之前，一些有益的尝试是把特征组合的任务交给子模型来学习，最经典的方法就是 Facebook 在 2014 年的论文中介绍的通过 GBDT（Gradient Boost Decision Tree）模型解决 LR 模型的特征组合问题。该方法思路很简单，特征工程分为两部分，一部分特征用于训练一个 GBDT 模型，把 GBDT 模型每颗树的叶子节点编号作为新的特征，加入到原始特征集中，再训练最终的 LR 模型。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=%E5%9C%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%89%8D%EF%BC%8C%E4%B8%80%E4%BA%9B%E6%9C%89%E7%9B%8A%E7%9A%84%E5%B0%9D%E8%AF%95%E6%98%AF%E6%8A%8A%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88%E7%9A%84%E4%BB%BB%E5%8A%A1%E4%BA%A4%E7%BB%99%E5%AD%90%E6%A8%A1%E5%9E%8B%E6%9D%A5%E5%AD%A6%E4%B9%A0%EF%BC%8C%E6%9C%80%E7%BB%8F%E5%85%B8%E7%9A%84%E6%96%B9%E6%B3%95%E5%B0%B1%E6%98%AF%20Facebook%20%E5%9C%A8%202014%20%E5%B9%B4%E7%9A%84%E8%AE%BA%E6%96%87%E4%B8%AD%E4%BB%8B%E7%BB%8D%E7%9A%84%E9%80%9A%E8%BF%87%20GBDT%EF%BC%88Gradient%20Boost%20Decision%20Tree%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%A7%A3%E5%86%B3%20LR%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88%E9%97%AE%E9%A2%98%E3%80%82%E8%AF%A5%E6%96%B9%E6%B3%95%E6%80%9D%E8%B7%AF%E5%BE%88%E7%AE%80%E5%8D%95%EF%BC%8C%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%88%86%E4%B8%BA%E4%B8%A4%E9%83%A8%E5%88%86%EF%BC%8C%E4%B8%80%E9%83%A8%E5%88%86%E7%89%B9%E5%BE%81%E7%94%A8%E4%BA%8E%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%20GBDT%20%E6%A8%A1%E5%9E%8B%EF%BC%8C%E6%8A%8A%20GBDT%20%E6%A8%A1%E5%9E%8B%E6%AF%8F%E9%A2%97%E6%A0%91%E7%9A%84%E5%8F%B6%E5%AD%90%E8%8A%82%E7%82%B9%E7%BC%96%E5%8F%B7%E4%BD%9C%E4%B8%BA%E6%96%B0%E7%9A%84%E7%89%B9%E5%BE%81%EF%BC%8C%E5%8A%A0%E5%85%A5%E5%88%B0%E5%8E%9F%E5%A7%8B%E7%89%B9%E5%BE%81%E9%9B%86%E4%B8%AD%EF%BC%8C%E5%86%8D%E8%AE%AD%E7%BB%83%E6%9C%80%E7%BB%88%E7%9A%84%20LR%20%E6%A8%A1%E5%9E%8B%E3%80%82))

- > 因子分解机 (Factorization Machines, FM) 模型是第一个从原始特征出发，端到端学习的例子。然而，FM 毕竟还是一个浅层模型，经典的 FM 模型只能做二阶的特征交叉，模型学习复杂组合特征的能力偏弱。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=%E5%9B%A0%E5%AD%90%E5%88%86%E8%A7%A3%E6%9C%BA%20(Factorization%20Machines,%20FM)%20%E6%A8%A1%E5%9E%8B%E6%98%AF%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%BB%8E%E5%8E%9F%E5%A7%8B%E7%89%B9%E5%BE%81%E5%87%BA%E5%8F%91%EF%BC%8C%E7%AB%AF%E5%88%B0%E7%AB%AF%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%BE%8B%E5%AD%90%E3%80%82%E7%84%B6%E8%80%8C%EF%BC%8CFM%20%E6%AF%95%E7%AB%9F%E8%BF%98%E6%98%AF%E4%B8%80%E4%B8%AA%E6%B5%85%E5%B1%82%E6%A8%A1%E5%9E%8B%EF%BC%8C%E7%BB%8F%E5%85%B8%E7%9A%84%20FM%20%E6%A8%A1%E5%9E%8B%E5%8F%AA%E8%83%BD%E5%81%9A%E4%BA%8C%E9%98%B6%E7%9A%84%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%EF%BC%8C%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E5%A4%8D%E6%9D%82%E7%BB%84%E5%90%88%E7%89%B9%E5%BE%81%E7%9A%84%E8%83%BD%E5%8A%9B%E5%81%8F%E5%BC%B1%E3%80%82))

- > FM 通过特征对之间的隐变量内积来提取特征组合  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=FM%20%E9%80%9A%E8%BF%87%E7%89%B9%E5%BE%81%E5%AF%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E9%9A%90%E5%8F%98%E9%87%8F%E5%86%85%E7%A7%AF%E6%9D%A5%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88))

- > 对于每个原始特征，FM 都会学习一个隐向量。模型通过穷举所有的特征对（pair）并逐一检测特征对的效用值的方法来自动识别出有效的特征组合。特征对的效用值通过该特征对涉及的两个原始特征的隐向量的内积来计算。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=%E5%AF%B9%E4%BA%8E%E6%AF%8F%E4%B8%AA%E5%8E%9F%E5%A7%8B%E7%89%B9%E5%BE%81%EF%BC%8CFM%20%E9%83%BD%E4%BC%9A%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%B8%AA%E9%9A%90%E5%90%91%E9%87%8F%E3%80%82%E6%A8%A1%E5%9E%8B%E9%80%9A%E8%BF%87%E7%A9%B7%E4%B8%BE%E6%89%80%E6%9C%89%E7%9A%84%E7%89%B9%E5%BE%81%E5%AF%B9%EF%BC%88pair%EF%BC%89%E5%B9%B6%E9%80%90%E4%B8%80%E6%A3%80%E6%B5%8B%E7%89%B9%E5%BE%81%E5%AF%B9%E7%9A%84%E6%95%88%E7%94%A8%E5%80%BC%E7%9A%84%E6%96%B9%E6%B3%95%E6%9D%A5%E8%87%AA%E5%8A%A8%E8%AF%86%E5%88%AB%E5%87%BA%E6%9C%89%E6%95%88%E7%9A%84%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88%E3%80%82%E7%89%B9%E5%BE%81%E5%AF%B9%E7%9A%84%E6%95%88%E7%94%A8%E5%80%BC%E9%80%9A%E8%BF%87%E8%AF%A5%E7%89%B9%E5%BE%81%E5%AF%B9%E6%B6%89%E5%8F%8A%E7%9A%84%E4%B8%A4%E4%B8%AA%E5%8E%9F%E5%A7%8B%E7%89%B9%E5%BE%81%E7%9A%84%E9%9A%90%E5%90%91%E9%87%8F%E7%9A%84%E5%86%85%E7%A7%AF%E6%9D%A5%E8%AE%A1%E7%AE%97%E3%80%82))
  - 📝 [[注意力]] 的前身应用

- > plain-DNN 以一种隐式的方式建模特征之间的交互关系，我们无法确定它学习到了多少阶的交叉关系。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=plain-DNN%20%E4%BB%A5%E4%B8%80%E7%A7%8D%E9%9A%90%E5%BC%8F%E7%9A%84%E6%96%B9%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%89%B9%E5%BE%81%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BA%A4%E4%BA%92%E5%85%B3%E7%B3%BB%EF%BC%8C%E6%88%91%E4%BB%AC%E6%97%A0%E6%B3%95%E7%A1%AE%E5%AE%9A%E5%AE%83%E5%AD%A6%E4%B9%A0%E5%88%B0%E4%BA%86%E5%A4%9A%E5%B0%91%E9%98%B6%E7%9A%84%E4%BA%A4%E5%8F%89%E5%85%B3%E7%B3%BB%E3%80%82))

- > Embedding 向量中的元素用术语 bit 表示，可以看出 plain-DNN 的高阶特征交互建模是元素级的（bit-wise），也就是说同一个域对应的 embedding 向量中的元素也会相互影响。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=Embedding%20%E5%90%91%E9%87%8F%E4%B8%AD%E7%9A%84%E5%85%83%E7%B4%A0%E7%94%A8%E6%9C%AF%E8%AF%AD%20bit%20%E8%A1%A8%E7%A4%BA%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%87%BA%20plain-DNN%20%E7%9A%84%E9%AB%98%E9%98%B6%E7%89%B9%E5%BE%81%E4%BA%A4%E4%BA%92%E5%BB%BA%E6%A8%A1%E6%98%AF%E5%85%83%E7%B4%A0%E7%BA%A7%E7%9A%84%EF%BC%88bit-wise%EF%BC%89%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%AF%B4%E5%90%8C%E4%B8%80%E4%B8%AA%E5%9F%9F%E5%AF%B9%E5%BA%94%E7%9A%84%20embedding%20%E5%90%91%E9%87%8F%E4%B8%AD%E7%9A%84%E5%85%83%E7%B4%A0%E4%B9%9F%E4%BC%9A%E7%9B%B8%E4%BA%92%E5%BD%B1%E5%93%8D%E3%80%82))

- > FM 类方法是以向量级（vector-wise）的方式来构建高阶交叉关系。经验上，vector-wise 的方式构建的特征交叉关系比 bit-wise 的方式更容易学习。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=FM%20%E7%B1%BB%E6%96%B9%E6%B3%95%E6%98%AF%E4%BB%A5%E5%90%91%E9%87%8F%E7%BA%A7%EF%BC%88vector-wise%EF%BC%89%E7%9A%84%E6%96%B9%E5%BC%8F%E6%9D%A5%E6%9E%84%E5%BB%BA%E9%AB%98%E9%98%B6%E4%BA%A4%E5%8F%89%E5%85%B3%E7%B3%BB%E3%80%82%E7%BB%8F%E9%AA%8C%E4%B8%8A%EF%BC%8Cvector-wise%20%E7%9A%84%E6%96%B9%E5%BC%8F%E6%9E%84%E5%BB%BA%E7%9A%84%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E5%85%B3%E7%B3%BB%E6%AF%94%20bit-wise%20%E7%9A%84%E6%96%B9%E5%BC%8F%E6%9B%B4%E5%AE%B9%E6%98%93%E5%AD%A6%E4%B9%A0%E3%80%82))

- > **PNN** 模型最先提出了一种融合 bit-wise 和 vector-wise 交叉特征的方法，其通过在网络的 embedding 层与全连接层之间加了一层 Product Layer 来完成特征组合。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=PNN%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%85%88%E6%8F%90%E5%87%BA%E4%BA%86%E4%B8%80%E7%A7%8D%E8%9E%8D%E5%90%88%20bit-wise%20%E5%92%8C%20vector-wise%20%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%8C%E5%85%B6%E9%80%9A%E8%BF%87%E5%9C%A8%E7%BD%91%E7%BB%9C%E7%9A%84%20embedding%20%E5%B1%82%E4%B8%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E4%B9%8B%E9%97%B4%E5%8A%A0%E4%BA%86%E4%B8%80%E5%B1%82%20Product%20Layer%20%E6%9D%A5%E5%AE%8C%E6%88%90%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88%E3%80%82))

- > **WDL（Wide & Deep Learning）** 模型混合了宽度模型与深度模型，其宽度部分保留了低价特征，偏重记忆；深度部分引入了 bit-wise 的特征交叉能力。WDL 模型的一大缺点是宽度部分的输入依旧依赖于大量的人工特征工程。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=WDL%EF%BC%88Wide%20&%20Deep%20Learning%EF%BC%89%E6%A8%A1%E5%9E%8B%E6%B7%B7%E5%90%88%E4%BA%86%E5%AE%BD%E5%BA%A6%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%85%B6%E5%AE%BD%E5%BA%A6%E9%83%A8%E5%88%86%E4%BF%9D%E7%95%99%E4%BA%86%E4%BD%8E%E4%BB%B7%E7%89%B9%E5%BE%81%EF%BC%8C%E5%81%8F%E9%87%8D%E8%AE%B0%E5%BF%86%EF%BC%9B%E6%B7%B1%E5%BA%A6%E9%83%A8%E5%88%86%E5%BC%95%E5%85%A5%E4%BA%86%20bit-wise%20%E7%9A%84%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E8%83%BD%E5%8A%9B%E3%80%82WDL%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E5%A4%A7%E7%BC%BA%E7%82%B9%E6%98%AF%E5%AE%BD%E5%BA%A6%E9%83%A8%E5%88%86%E7%9A%84%E8%BE%93%E5%85%A5%E4%BE%9D%E6%97%A7%E4%BE%9D%E8%B5%96%E4%BA%8E%E5%A4%A7%E9%87%8F%E7%9A%84%E4%BA%BA%E5%B7%A5%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E3%80%82))

- > **DeepFM** 模型融合了 FM 和 WDL 模型，其 FM 部分实现了低阶特征和 vector-wise 的二阶交叉特征建模，其 Deep 部分使模型具有了 bit-wise 的高阶交叉特征建模的能力。具体地，DeepFM 包含两部分：神经网络部分与因子分解机部分，这两部分共享同样的输入。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=DeepFM%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E4%BA%86%20FM%20%E5%92%8C%20WDL%20%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%85%B6%20FM%20%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0%E4%BA%86%E4%BD%8E%E9%98%B6%E7%89%B9%E5%BE%81%E5%92%8C%20vector-wise%20%E7%9A%84%E4%BA%8C%E9%98%B6%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%E5%BB%BA%E6%A8%A1%EF%BC%8C%E5%85%B6%20Deep%20%E9%83%A8%E5%88%86%E4%BD%BF%E6%A8%A1%E5%9E%8B%E5%85%B7%E6%9C%89%E4%BA%86%20bit-wise%20%E7%9A%84%E9%AB%98%E9%98%B6%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%E5%BB%BA%E6%A8%A1%E7%9A%84%E8%83%BD%E5%8A%9B%E3%80%82%E5%85%B7%E4%BD%93%E5%9C%B0%EF%BC%8CDeepFM%20%E5%8C%85%E5%90%AB%E4%B8%A4%E9%83%A8%E5%88%86%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%83%A8%E5%88%86%E4%B8%8E%E5%9B%A0%E5%AD%90%E5%88%86%E8%A7%A3%E6%9C%BA%E9%83%A8%E5%88%86%EF%BC%8C%E8%BF%99%E4%B8%A4%E9%83%A8%E5%88%86%E5%85%B1%E4%BA%AB%E5%90%8C%E6%A0%B7%E7%9A%84%E8%BE%93%E5%85%A5%E3%80%82))

- > FM、DeepFM 和 Inner-PNN 都是通过原始特征隐向量的内积来构建 vector-wise 的二阶交叉特征，这种方式有两个主要的缺点：

1.  必须要穷举出所有的特征对，即任意两个 field 之间都会形成特征组合关系，而过多的组合关系可能会引入无效的交叉特征，给模型引入过多的噪音，从而导致性能下降。
2.  二阶交叉特征有时候是不够的，好的特征可能需要更高阶的组合。虽然 DNN 部分可以部分弥补这个不足，但 bit-wise 的交叉关系是晦涩难懂、不确定并且不容易学习的。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=FM%E3%80%81DeepFM%20%E5%92%8C%20Inner-PNN%20%E9%83%BD%E6%98%AF%E9%80%9A%E8%BF%87%E5%8E%9F%E5%A7%8B%E7%89%B9%E5%BE%81%E9%9A%90%E5%90%91%E9%87%8F%E7%9A%84%E5%86%85%E7%A7%AF%E6%9D%A5%E6%9E%84%E5%BB%BA%20vector-wise%20%E7%9A%84%E4%BA%8C%E9%98%B6%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%EF%BC%8C%E8%BF%99%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%9C%89%E4%B8%A4%E4%B8%AA%E4%B8%BB%E8%A6%81%E7%9A%84%E7%BC%BA%E7%82%B9%EF%BC%9A%E5%BF%85%E9%A1%BB%E8%A6%81%E7%A9%B7%E4%B8%BE%E5%87%BA%E6%89%80%E6%9C%89%E7%9A%84%E7%89%B9%E5%BE%81%E5%AF%B9%EF%BC%8C%E5%8D%B3%E4%BB%BB%E6%84%8F%E4%B8%A4%E4%B8%AA%20field%20%E4%B9%8B%E9%97%B4%E9%83%BD%E4%BC%9A%E5%BD%A2%E6%88%90%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88%E5%85%B3%E7%B3%BB%EF%BC%8C%E8%80%8C%E8%BF%87%E5%A4%9A%E7%9A%84%E7%BB%84%E5%90%88%E5%85%B3%E7%B3%BB%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%BC%95%E5%85%A5%E6%97%A0%E6%95%88%E7%9A%84%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%EF%BC%8C%E7%BB%99%E6%A8%A1%E5%9E%8B%E5%BC%95%E5%85%A5%E8%BF%87%E5%A4%9A%E7%9A%84%E5%99%AA%E9%9F%B3%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%AF%BC%E8%87%B4%E6%80%A7%E8%83%BD%E4%B8%8B%E9%99%8D%E3%80%82%E4%BA%8C%E9%98%B6%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%E6%9C%89%E6%97%B6%E5%80%99%E6%98%AF%E4%B8%8D%E5%A4%9F%E7%9A%84%EF%BC%8C%E5%A5%BD%E7%9A%84%E7%89%B9%E5%BE%81%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E6%9B%B4%E9%AB%98%E9%98%B6%E7%9A%84%E7%BB%84%E5%90%88%E3%80%82%E8%99%BD%E7%84%B6%20DNN%20%E9%83%A8%E5%88%86%E5%8F%AF%E4%BB%A5%E9%83%A8%E5%88%86%E5%BC%A5%E8%A1%A5%E8%BF%99%E4%B8%AA%E4%B8%8D%E8%B6%B3%EF%BC%8C%E4%BD%86%20bit-wise%20%E7%9A%84%E4%BA%A4%E5%8F%89%E5%85%B3%E7%B3%BB%E6%98%AF%E6%99%A6%E6%B6%A9%E9%9A%BE%E6%87%82%E3%80%81%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%B9%B6%E4%B8%94%E4%B8%8D%E5%AE%B9%E6%98%93%E5%AD%A6%E4%B9%A0%E7%9A%84%E3%80%82))

- > 解决维数灾难挑战不可避免的就是要引入某种 “压缩” 机制，就是要把高阶的组合特征向量的维数降到一个合理的范围，同时在这个过程中尽量多的保留有效的交叉特征，去除无效的交叉特征。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=%E8%A7%A3%E5%86%B3%E7%BB%B4%E6%95%B0%E7%81%BE%E9%9A%BE%E6%8C%91%E6%88%98%E4%B8%8D%E5%8F%AF%E9%81%BF%E5%85%8D%E7%9A%84%E5%B0%B1%E6%98%AF%E8%A6%81%E5%BC%95%E5%85%A5%E6%9F%90%E7%A7%8D%20%E2%80%9C%E5%8E%8B%E7%BC%A9%E2%80%9D%20%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%B0%B1%E6%98%AF%E8%A6%81%E6%8A%8A%E9%AB%98%E9%98%B6%E7%9A%84%E7%BB%84%E5%90%88%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E7%BB%B4%E6%95%B0%E9%99%8D%E5%88%B0%E4%B8%80%E4%B8%AA%E5%90%88%E7%90%86%E7%9A%84%E8%8C%83%E5%9B%B4%EF%BC%8C%E5%90%8C%E6%97%B6%E5%9C%A8%E8%BF%99%E4%B8%AA%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%B0%BD%E9%87%8F%E5%A4%9A%E7%9A%84%E4%BF%9D%E7%95%99%E6%9C%89%E6%95%88%E7%9A%84%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%EF%BC%8C%E5%8E%BB%E9%99%A4%E6%97%A0%E6%95%88%E7%9A%84%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%E3%80%82))

- > **DCN** 模型以一个嵌入和堆叠层 (embedding and stacking layer) 开始，接着并列连一个 cross network 和一个 deep network，接着通过一个 combination layer 将两个 network 的输出进行组合。交叉网络（cross network）的核心思想是以有效的方式应用显式特征交叉。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=DCN%E6%A8%A1%E5%9E%8B%E4%BB%A5%E4%B8%80%E4%B8%AA%E5%B5%8C%E5%85%A5%E5%92%8C%E5%A0%86%E5%8F%A0%E5%B1%82%20(embedding%20and%20stacking%20layer)%20%E5%BC%80%E5%A7%8B%EF%BC%8C%E6%8E%A5%E7%9D%80%E5%B9%B6%E5%88%97%E8%BF%9E%E4%B8%80%E4%B8%AA%20cross%20network%20%E5%92%8C%E4%B8%80%E4%B8%AA%20deep%20network%EF%BC%8C%E6%8E%A5%E7%9D%80%E9%80%9A%E8%BF%87%E4%B8%80%E4%B8%AA%20combination%20layer%20%E5%B0%86%E4%B8%A4%E4%B8%AA%20network%20%E7%9A%84%E8%BE%93%E5%87%BA%E8%BF%9B%E8%A1%8C%E7%BB%84%E5%90%88%E3%80%82%E4%BA%A4%E5%8F%89%E7%BD%91%E7%BB%9C%EF%BC%88cross%20network%EF%BC%89%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%E6%98%AF%E4%BB%A5%E6%9C%89%E6%95%88%E7%9A%84%E6%96%B9%E5%BC%8F%E5%BA%94%E7%94%A8%E6%98%BE%E5%BC%8F%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E3%80%82))

- > ![](https://pic1.zhimg.com/v2-5dc2141a3fb667a0cdf13aa4c1c65e38_r.jpg) [[模型结构]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=https://pic1.zhimg.com/v2-5dc2141a3fb667a0cdf13aa4c1c65e38_r.jpg))
  - 📝 [[DCN]]

- > **特征的高阶交叉（high-degree interaction）** ：cross network 的独特结构使得交叉特征的阶（the degress of cross features）随着 layer 的深度而增长。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=%E7%89%B9%E5%BE%81%E7%9A%84%E9%AB%98%E9%98%B6%E4%BA%A4%E5%8F%89%EF%BC%88high-degree%20interaction%EF%BC%89%20%EF%BC%9Across%20network%20%E7%9A%84%E7%8B%AC%E7%89%B9%E7%BB%93%E6%9E%84%E4%BD%BF%E5%BE%97%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%E7%9A%84%E9%98%B6%EF%BC%88the%20degress%20of%20cross%20features%EF%BC%89%E9%9A%8F%E7%9D%80%20layer%20%E7%9A%84%E6%B7%B1%E5%BA%A6%E8%80%8C%E5%A2%9E%E9%95%BF%E3%80%82))

- > DCN 模型的两个主要的不足：

1.  CrossNet 的输出被限定在一种特殊的形式上
2.  特征交叉还是以 bit-wise 的方式构建的  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=DCN%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E4%B8%AA%E4%B8%BB%E8%A6%81%E7%9A%84%E4%B8%8D%E8%B6%B3%EF%BC%9ACrossNet%20%E7%9A%84%E8%BE%93%E5%87%BA%E8%A2%AB%E9%99%90%E5%AE%9A%E5%9C%A8%E4%B8%80%E7%A7%8D%E7%89%B9%E6%AE%8A%E7%9A%84%E5%BD%A2%E5%BC%8F%E4%B8%8A%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E8%BF%98%E6%98%AF%E4%BB%A5%20bit-wise%20%E7%9A%84%E6%96%B9%E5%BC%8F%E6%9E%84%E5%BB%BA%E7%9A%84))

- > 为了实现自动学习显式的高阶特征交互，同时使得交互发生在向量级上，xDeepFM 首先提出了一种新的名为 **压缩交互网络** （Compressed Interaction Network，简称 CIN）的模型。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=%E4%B8%BA%E4%BA%86%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%AD%A6%E4%B9%A0%E6%98%BE%E5%BC%8F%E7%9A%84%E9%AB%98%E9%98%B6%E7%89%B9%E5%BE%81%E4%BA%A4%E4%BA%92%EF%BC%8C%E5%90%8C%E6%97%B6%E4%BD%BF%E5%BE%97%E4%BA%A4%E4%BA%92%E5%8F%91%E7%94%9F%E5%9C%A8%E5%90%91%E9%87%8F%E7%BA%A7%E4%B8%8A%EF%BC%8C%E5%8E%8B%E7%BC%A9%E4%BA%A4%E4%BA%92%E7%BD%91%E7%BB%9CxDeepFM%20%E9%A6%96%E5%85%88%E6%8F%90%E5%87%BA%E4%BA%86%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84%E5%90%8D%E4%B8%BA%20%20%EF%BC%88Compressed%20Interaction%20Network%EF%BC%8C%E7%AE%80%E7%A7%B0%20CIN%EF%BC%89%E7%9A%84%E6%A8%A1%E5%9E%8B%E3%80%82))

- > CIN 的宏观框架如下图所示，它的特点是，最终学习出的特征交互的阶数是由网络的层数决定的，每一层隐层都通过一个池化操作连接到输出层，从而保证了输出单元可以见到不同阶数的特征交互模式。  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=CIN%20%E7%9A%84%E5%AE%8F%E8%A7%82%E6%A1%86%E6%9E%B6%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%EF%BC%8C%E5%AE%83%E7%9A%84%E7%89%B9%E7%82%B9%E6%98%AF%EF%BC%8C%E6%9C%80%E7%BB%88%E5%AD%A6%E4%B9%A0%E5%87%BA%E7%9A%84%E7%89%B9%E5%BE%81%E4%BA%A4%E4%BA%92%E7%9A%84%E9%98%B6%E6%95%B0%E6%98%AF%E7%94%B1%E7%BD%91%E7%BB%9C%E7%9A%84%E5%B1%82%E6%95%B0%E5%86%B3%E5%AE%9A%E7%9A%84%EF%BC%8C%E6%AF%8F%E4%B8%80%E5%B1%82%E9%9A%90%E5%B1%82%E9%83%BD%E9%80%9A%E8%BF%87%E4%B8%80%E4%B8%AA%E6%B1%A0%E5%8C%96%E6%93%8D%E4%BD%9C%E8%BF%9E%E6%8E%A5%E5%88%B0%E8%BE%93%E5%87%BA%E5%B1%82%EF%BC%8C%E4%BB%8E%E8%80%8C%E4%BF%9D%E8%AF%81%E4%BA%86%E8%BE%93%E5%87%BA%E5%8D%95%E5%85%83%E5%8F%AF%E4%BB%A5%E8%A7%81%E5%88%B0%E4%B8%8D%E5%90%8C%E9%98%B6%E6%95%B0%E7%9A%84%E7%89%B9%E5%BE%81%E4%BA%A4%E4%BA%92%E6%A8%A1%E5%BC%8F%E3%80%82))

- > ![](https://pic2.zhimg.com/v2-49116822c223432a3d8c1a0620b987c9_r.jpg) [[模型结构]]   ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=https://pic2.zhimg.com/v2-49116822c223432a3d8c1a0620b987c9_r.jpg))
  - 📝 [[xDeepFM]] 的 [[CIN]]

- > ![](https://pic3.zhimg.com/v2-77ab7376e161a89969cb8b8ffaa01d6a_r.jpg)  ([🌐 摘要链接](https://zhuanlan.zhihu.com/p/52876883#js_content:~:text=https://pic3.zhimg.com/v2-77ab7376e161a89969cb8b8ffaa01d6a_r.jpg))

